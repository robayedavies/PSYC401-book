[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psychological data analysis for graduate students: PSYC401",
    "section": "",
    "text": "Preface: Our approach\nWe can, here, explain a development in the approach we take in teaching this course. Naturally, this development in approach will require a parallel development in your approach to learning.\nWe are going to focus on working in research in context (see Figure 1).\n\n\n\n\n\n\n\n\nG\n\n  \n\nreading\n\n reading   \n\nknowledge\n\n knowledge   \n\nreading–knowledge\n\n   \n\nconventions\n\n conventions   \n\nknowledge–conventions\n\n   \n\nconcepts\n\n concepts   \n\nknowledge–concepts\n\n   \n\npractices\n\n practices   \n\nknowledge–practices\n\n  \n\n\nFigure 1: Working in research in context.\n\n\n\n\nYou have been introduced to R. We know that some of you are new to R so we will practice the skills you are learning. We will consolidate, revise, and extend these skills.\nWe will encounter — some, for the first time – the linear model also known as regression analysis. But the big change is this focus on context. The reason is that not talking about the context is risky for how you approach, do, or think about data analysis.\nIn traditional methods teaching, the schedule of classes will progress through a series of tests, one test a week, from simpler to more complex tests. In this approach, the presentation is often brief about the context: the question the researchers are investigating; the methods they use to collect data; and, critically, the assumptions they make about how your reasoning can get you from the things you measure to the things you are trying to understand.\nThis approach is understandable but it presents a misleading view. It implies that if you learn the method, and can match the textbook example to your context then all you need to do is to apply the analysis code to get the right result. This style of working is common, and it is often a reasonable place to start, but the isolation from context reduces the application of judgment, and limits critical evaluation of measurement, analysis assumptions, and sources of uncertainty.\n\n\n\n\n\n\nTip\n\n\n\nWe can do better.\n\n\nA more productive approach – this is the approach we will take – is to expose, and talk about some of the real challenges that anybody who handles data, or quantitative evidence, deals with in professional life:\n\nThinking about the mapping from our concerns to the research questions, to the things we measure, the analysis we do, and then the conclusions we make.\nSelecting or constructing valid measures that can be assumed to measure the things they are supposed to measure.\nTaking samples of observations, and making conclusions about the population.\nMaking estimates and linking these estimates to an account that is explicit about causes."
  },
  {
    "objectID": "visualization.html#sec-aims",
    "href": "visualization.html#sec-aims",
    "title": "2  Data visualization",
    "section": "2.1 Aims",
    "text": "2.1 Aims\nIn writing this chapter, I have two aims.\n\nThe first aim for this chapter is to expose students to an outline summary of some key ideas and techniques for data visualization in psychological science.\n\nThere is an extensive experimental and theoretical literature concerning data visualization, what choices we can or should make, and how these choices have more or less impact, in different circumstances or for different audiences. Here, we can only give you a flavour of the on-going discussion. If you are interested, you can follow-up the references in the cited articles. But, using this chapter, I hope that you will gain a sense of the reasons how or why we may choose to do different things when we produce visualizations.\n\nThe second aim is to provide materials, and to show visualizations, to raise an awareness of what results come from making different choices. This is because we hope to encourage students to make choices based on reasons and it is hard to know what choices count without first seeing what the results might look like.\n\nIn my experience, knowing that there are choices is the first step. In proprietary software packages like Excel and SPSS there are plenty of choices but these are limited by the menu systems to certain combinations of elements. Here, in using R to produce visualizations, there is much more freedom, and much more capacity to control what a plot shows and how it looks, but knowing where to start has to begin with seeing examples of what some of the choices result in.\nAt the end of the chapter, I highlight some resources you can use in independent learning for further development, see Section 2.9.\nSo, we are aiming to (1.) start to build insight into the choices we make and (2.) provide resources to enable making those choices in data visualization."
  },
  {
    "objectID": "visualization.html#sec-why-visualization-matters",
    "href": "visualization.html#sec-why-visualization-matters",
    "title": "2  Data visualization",
    "section": "2.2 Why data visualization matters",
    "text": "2.2 Why data visualization matters\nData visualization is important. Building skills in visualization matters to you because, even if you do not go on to professional work in which you produce visualizations you will certainly be working in fields in which you need to work with, or read or evaluate, visualizations.\nYou have already been doing this: our cultural or visual environment is awash in visualizations, from weather maps to charts on the television news. It will empower you if you know a bit about how or why these visualizations are produced in the ways that they are produced. That is a complex development trajectory but we can get started here.\nIn the context of the research report exercise, see Section 4.2.3.1, I mention data visualization in relation to stages of the data analysis pipeline or workflow. But the reality is that, most of the time, visualization is useful and used at every stage of data analysis workflow.\n\n\n\n\n\n\n\n\nQ\n\n \n\ncluster_R\n\n   \n\nnd_1\n\n Get raw data   \n\nnd_2\n\n Tidy data   \n\nnd_1-&gt;nd_2\n\n    \n\nnd_3_l\n\n Visualize   \n\nnd_2-&gt;nd_3_l\n\n    \n\nnd_3\n\n Analyze   \n\nnd_2-&gt;nd_3\n\n    \n\nnd_3_r\n\n Explore   \n\nnd_2-&gt;nd_3_r\n\n    \n\nnd_3_a\n\n Assumptions   \n\nnd_3_a-&gt;nd_3_l\n\n    \n\nnd_3_a-&gt;nd_3\n\n    \n\nnd_3_a-&gt;nd_3_r\n\n    \n\nnd_3_l-&gt;nd_3\n\n   \n\nnd_4\n\n Present   \n\nnd_3_l-&gt;nd_4\n\n    \n\nnd_3-&gt;nd_4\n\n   \n\n\nFigure 2.1: The data analysis pipeline or workflow"
  },
  {
    "objectID": "visualization.html#sec-honesty",
    "href": "visualization.html#sec-honesty",
    "title": "2  Data visualization",
    "section": "2.3 Three kinds of honesty",
    "text": "2.3 Three kinds of honesty\nI write this chapter with three kinds of honesty in mind.\n\nI will expose some of the process involved in thinking about and preparing for the production of plots.\n\n\nI can assure you that when a professional data analysis worker produces plots in R they will be looking for information about what to do, and how to do it, online. I will provide links to the information I used, when I wrote this chapter, in order to figure out the coding to produce the plots.\nI won’t pretend that I got the plots “right first time” or that I know all the coding steps by memory. Neither is true for me and they would not be true for most professionals if they were to write a chapter like this. Looking things up online is something we all do so showing you where the information can be found will help you grow your skills.\n\n\nI will show how we often prepare for the production of plots by processing the data that we must use to inform the plots.\n\n\nWe almost always have to process the data we collected or gathered together from our exerimental work or our observations.\nIn this chapter, some of the coding steps I will outline are done in advance of producing a plot, to give the plotting code something to work with.\nKnowing about these processing steps will ensure you have more flexibility or power in getting your plots ready.\n\n\nI am going to expose variation, as often as I can, in observations.\n\n\nWe typically collect data about or from people, about their responses to things we may present (stimuli) or, given tasks, under different conditions, or concerning individual differences on an array of dimensions.\nSources of variation will be everywhere in our data, even though we often work with statistical analyses (like the t-test) that focus our attention on the average participant or the average response.\nModern analysis methods (like mixed-effects models) enable us to account for sources of variation systematically, so it is good to begin thinking about, say, how people vary in their response to different experimental conditions from early in your development."
  },
  {
    "objectID": "visualization.html#sec-tidyverse",
    "href": "visualization.html#sec-tidyverse",
    "title": "2  Data visualization",
    "section": "2.4 Our approach: tidyverse",
    "text": "2.4 Our approach: tidyverse\nThe approach we will take is to focus on step-by-step guides to coding. I will show plots and I will walk through the coding steps, explaining my reasons for the choices I make.\nWe will be working with plotting functions like ggplot() provided in libraries like ggplot2 (Wickham, 2016) which is part of the tidyverse (Wickham, 2017) collection of libraries.\nYou can access information about the tidyverse collection here.\n\n2.4.1 Grammar of graphics\nThe gg in ggplot stands for the “Grammar of Graphics”, and the ideas motivating the development of the ggplot2 library of functions are grounded in the ideas concerning the grammar of graphics, set out in the book of that name (Wilkinson, 2013).\nWhat is helpful to us, here, is the insight that the code elements (and how they result in visual elements) can be identified as building blocks, or layers, that we can add and adjust piece by piece when we are producing a visualization.\nA plot represents information and, critically, every time we write ggplot code we must specify somewhere the ways that our plot links data to something we see. In terms of ggplot, we specify aesthetic mappings using the aes() code to tell R what variables should be mapped e.g. to x-axis or y-axis location, to colour, or to group assignments. We then add elements to instruct R how to represent the aesthetic mappings as visual objects or attributes: geometric objects like a scatter of points geom_point() or a collection of bars geom_bar(); or visual features like colour, shape or size e.g. aes(colour = group). We can add visual elements in a series of layers, as shall see in the practical demonstrations of plot construction. We can adjust how scaling works. And we can add annotation, labels, and other elements to guide and inform the attention of the audience.\nYou can read more about mastering the grammar here.\n\n\n2.4.2 Pipes\nWe know that (some of) you want to see more use of pipes (represented as %&gt;% or |&gt;) in coding. There will be plenty of pipes in this chapter.\nIn using pipes in the code, I am structuring the code so that it works — and is presented — in a sequence of steps. There are different ways to write code but I find this way easier to work with and to read and I think you will too.\nLet’s take a small example:\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  summarise(average = mean(Reaction)) %&gt;%\n  ggplot(aes(x = average)) + \n  geom_histogram()\n\n\n\n\nHere, we work through a series of steps:\n\nsleepstudy %&gt;% we first tell R we want to work with the dataset called sleepstudy and the %&gt;% pipe symbol at the end of the line tells R that we want it to pass that dataset on to the next step for what happens next.\ngroup_by(Subject) %&gt;% tells R that we want it to do something, here, group the rows of data according to the Subject (participant identity) coding variable, and pass the grouped data on to the next step for what happens following.\nsummarise(average = mean(Reaction)) %&gt;% tells R to take the grouped variable and calculate a summary, the mean Reaction score, for each group of observations for each participant. The %&gt;% pipe at the end of the line tells R to pass the summary dataset of mean Reaction scores on to the next process.\nggplot(aes(x = average)) + tells R that we want it to take these summary average Reaction scores and make a plot out of them.\ngeom_histogram() tells R that we want a histogram plot.\n\nWhat you can see is that each line ending in a %&gt; pipe passes something on to the next line. A following line takes the output of the process coded in the preceding line, and works with it.\nEach step is executed in turn, in strict sequence. This means that if I delete line 3 summarise(average = mean(Reaction)) %&gt;% then the following lines cannot work because the ggplot() function will be looking for a variable average that does not yet exist.\n\n\n\n\n\n\nWarning\n\n\n\n\nYou can see that in the data processing part of the code, successive steps in data processing end in a pipe %&gt;%.\nIn contrast, successive steps of the plotting code add ggplot elements line by line with each line (except the last) ending in a +.\n\n\n\nNotice that none of the processing steps actually changes the dataset called sleepstudy. The results of the process exist and can be used only within the sequence of steps that I have coded. If you want to keep the results of processing steps, you need to assign an object name to hold them, and I show how to do this, in the following.\nYou can read a clear explanation of pipes here.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the code you see:\n\nEach chunk of code is highlighted in the chapter.\nIf you hover a cursor over the highlighted code a little clipboard symbol appears in the top right of the code chunk.\nClick on the clipboard symbol to copy the code, paste it into your own R-Studio instance.\nThen experiment: try out things like removing or commmenting out lines, or changing lines, to see what effect that has.\nBreaking things, or changing things, helps to show what each bit of code does."
  },
  {
    "objectID": "visualization.html#sec-ideas",
    "href": "visualization.html#sec-ideas",
    "title": "2  Data visualization",
    "section": "2.5 Key ideas",
    "text": "2.5 Key ideas\nData visualization is not really about coding, as about thinking.\n\nWhat are our goals?\nWhy do we make some choices instead of others?\n\n\n2.5.1 Purposes\nGelman & Unwin (2013) outline the goals we may contemplate when we produce or evaluate visual data displays. In general, they argue, we are doing one or both of two things.\n\nDiscovery\nCommunication\n\nIn practice, this may involve the following (I paraphrase them, here).\n\nDiscovery goals\n\n\nGetting a sense of what is in a dataset, checking assumptions, confirming expectations, and looking for distinct patterns.\nMaking sense of the scale and complexity of the dataset.\nExploring the data to reveal unexpected aspects. As we will see, using small multiples (grids of plots) can often help with this.\n\n\nCommunication goals\n\n\nWe communicate about our data to ourselves and to others. The process of constructing and evaluating a plot is often one way we speak to ourselves about own data, developing an understanding of what we have got. Once we have done this for ourselves, we can better figure out how to do it to benefit the understanding of an audience.\nWe often use a plot to tell a story: the story of our study, our data, or our insight and how we get to it.\nWe can use visualizations to attract attention and stimulate interest. Often, in presenting data to an audience through a talk or a report we need to use effective visualizations to ensure we get attention and that we locate the attention of our audience in the right places.\n\n\n\n2.5.2 Psychological science of data visualization\nYou will see a rich variety of data visualizations in media and in the research literature. You will know that some choices, in the production of those visualizations, appear to work better than others.\nSome of the reasons why some choices work better will relate to what we can understand in terms of the psychological science of how visual data communication works. A useful recent review of relevant research is presented by Franconeri et al. (2021).\nFranconeri et al. (2021) provide a reason for working on visualizations: they allow us humans to process an array of information at once, often faster than if we were reading about the information, bit by bit. Effective visualization, then, is about harnessing the power of the human visual system, or visual cognition, for quick, efficient, information processing. Critically for science, in addition, visualizations can be more effective for discovering or communicating the critical features of data than summary statistics, as we shall see.\nIn producing visualizations, we often work with a vocabulary or palette of objects or visual elements. Franconeri et al. (2021) discuss how visualizations rely on visual channels to transform numbers into images that we can process visually.\n\nDot plots and scatterplots represent values as position.\nBar graphs represent values as position (the heights of the tops of bars) but also as lengths.\nAngles are presented when we connect points to form a line, allowing us to encode the differences between points.\nIntensity can be presented through variation in luminance contrast or colour saturation.\n\nThese channels can be ordered by how precisely they have been found to communicate different numeric values to the viewer. Your audience may more accurately perceive the difference between two quantities if you communicate that difference through the difference in the location of two points than if you ask your audience to compare the angles of two lines or the intensity of two colour spots.\nIn constructing data visualizations, we often work with conventions, established through common practice in a research tradition. For example, if you are producing a scatterplot, then most of the time your audience will expect to see the outcome (or dependent variable) represented by the vertical height (on the y-axis) of points. And your audience will expect that higher points represent larger quantities of the y-axis variable.\nIn constructing visualizations, we need to be aware of the cognitive work that we require the audience to do. Comparisons are harder, requiring more processing and imposing more load on working memory. You can help your reader by guiding their attention, by grouping or ordering visual elements to identify the most important comparisons. We can vary colour and shape to group or distinguish visual elements. We can add annotation or elements like lines or arrows to guide attention.\nVisualizations are presented in context, whether in presentations or in reports. This context should be provided, by you the producer, with the intention to support the communication of your key messages. A visual representation, a plot, will be presented with a title, maybe a title note, maybe with annotation in the plot, and maybe with accompanying text. You should use these textual elements to lead your audience, to help them make sense of what they are looking at.\nThe diversity of audiences means that we should habitually add alt text for data visualizations to help those who use screen readers by providing a summary description of what images show. This chapter has been written using Quarto and rendered to .html with alt text included along with all images. Please do let me know if you are using a screen reader and the alt text description is or is not so helpful.\nYou can read a helpful explanation of alt text here.\nIf you use colour in images then we should use colour bind colour palettes.\nYou can read about using colour blind palettes here or here.\nIn the following practical exercises, we work with many of the insights in our construction of visualizations."
  },
  {
    "objectID": "visualization.html#sec-quick-start",
    "href": "visualization.html#sec-quick-start",
    "title": "2  Data visualization",
    "section": "2.6 A quick start",
    "text": "2.6 A quick start\nWe can get started before we understand in depth the key ideas or the coding steps. This will help to show where we are going. We will work with the sleepstudy dataset.\nI will model the process, to give you an example workflow:\n\nthe data, where they come from — what we can find out;\nhow we approach the data — what we expect to see;\nhow we visualize the data — discovery, communication.\n\n\n2.6.1 Sleepstudy data\nWhen we work with R, we usually work with functions like ggplot() provided in libraries like ggplot2 (Wickham, 2016). These libraries typically provide not only functions but also datasets that we can use for demonstration and learning.\nThe lme4 library (Bates et al., 2015) provides the sleepstudy dataset and we will take a look at these data to offer a taste of what we can learn to do. Usually, information about the R libraries we use will be located on the Comprehensive R Archive Network (CRAN) web pages, and we can find the technical reference information for lme4 in the CRAN reference manual for the library, where we see that the sleepstudy data are from a study reported by (Belenky et al., 2003). The manual says that the sleepstudy dataset comprises:\n\nA data frame with 180 observations on the following 3 variables. [1.] Reaction – Average reaction time (ms) [2.] Days – Number of days of sleep deprivation [3.] Subject – Subject number on which the observation was made.\n\nWe can take a look at the first few rows of the dataset.\n\nsleepstudy %&gt;%\n    head(n = 4)\n\n  Reaction Days Subject\n1 249.5600    0     308\n2 258.7047    1     308\n3 250.8006    2     308\n4 321.4398    3     308\n\n\nWhat we are looking at are:\n\nThe average reaction time per day (in milliseconds) for subjects in a sleep deprivation study. Days 0-1 were adaptation and training (T1/T2), day 2 was baseline (B); sleep deprivation started after day 2.\n\nThe abstract for Belenky et al. (2003) tells us that participants were deprived of sleep and the impact of relative deprivation was tested using a cognitive vigilance task for which the reaction times of responses were recorded.\nSo, we can expect to find:\n\nA set of rows corresponding to multiple observations for each participant (Subject)\nA reaction time value for each participant (Reaction)\nRecorded on each Day\n\n\n\n2.6.2 Discovery and communication\nIn data analysis work, we often begin with the objective to understand the structure or the nature of the data we are working with.\nYou can call this the discovery phase:\n\nwhat have we got?\ndoes it match our expectations?\n\nIf these are reaction time data (collected in an cognitive experiment) do they look like cognitive reaction time data should look? We would expect to see a skewed distribution of observed reaction times distributed around an average located somewhere in the range 200-700ms.\nFigure 2.2 represents the distribution of reaction times in the sleepstudy dataset.\nI provide notes on the code steps that result in the plot. Click on the Notes tab to see them. Later, I will discuss some of these elements.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Reaction)) +\n  geom_histogram(binwidth = 15) +\n  geom_vline(xintercept = mean(sleepstudy$Reaction), \n             colour = \"red\", linetype = 'dashed', size = 1.5) +\n  annotate(\"text\", x = 370, y =20, \n                    colour = \"red\", \n                    label = \"Average value shown in red\") +\n  theme_bw()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nFigure 2.2: Figure showing a histogram of sleepstudy reaction time data\n\n\n\n\n\n\nThe plotting code pipes the data into the plotting code steps to produce the plot. You can see some elements that will be familiar to you and some new elements.\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Reaction)) +\n  geom_histogram(binwidth = 15) +\n  geom_vline(xintercept = mean(sleepstudy$Reaction), \n             colour = \"red\", linetype = 'dashed', size = 1.5) +\n  annotate(\"text\", x = 370, y =20, \n                    colour = \"red\", \n                    label = \"Average value shown in red\") +\n  theme_bw()\n\nLet’s go through the code step-by-step:\n\nsleepstudy %&gt;% asks R to take the sleepstudy dataset and %&gt;% pipe it to the next steps for processing.\nggplot(aes(x = Reaction)) + takes the sleepstudy data and asks R to use the ggplot() function to produce a plot.\naes(x = Reaction) tells R that in the plot we want it to map the Reaction variable values to locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = 15) + tells R to produce a histogram then add a step.\ngeom_vline(...) + tells R we want to draw vertical line.\nxintercept = mean(sleepstudy$Reaction), ... tells R to draw the vertical line at the mean value of the variable Reaction in the sleepstudy dataset.\ncolour = \"red\", linetype = 'dashed', size = 1.5 tells R we want the vertical line to be red, dashed and 1.5 times the usual size.\nannotate(\"text\", ...) tells R we want to add a text note.\nx = 370, y =20, ... tells R we want the note added at the x,y coordinates given.\ncolour = \"red\", ..; and we want the text in red.\n...label = \"Average value shown in red\") + tells R we want the text note to say that this is where the average is.\ntheme_bw() lastly, we change the theme.\n\n\n\n\nFigure 2.2 shows a distribution of reaction times, ranging from about 200ms to 500ms. The distribution has a peak around 300ms. The location of the mean is shown with a dashed red line. The distribution includes a long tail of longer times. This is pretty much what we would expect to see.\nWe may wish to communicate the information we gain through using this histogram, in a presentation or in a report.\n\n\n2.6.3 Discovery and communication\nLet us imagine that it is our study. (Here, we shall not concern ourselves too much — with apologies — with understanding what the original study authors actually did.)\nIf we are looking at the impact of sleep deprivation on cognitive performance, we might predict that reaction times got longer (responses slowed) as the study progressed. Is that what we see?\nTo examine the association between two variables, we often use scatterplots. Figure 2.3 is a scatterplot indicating the possible association between reaction time and days in the sleepstudy data. Points are ordered on x-axis from 0 to 9 days, on y-axis from 200 to 500 ms reaction time.\nI provide notes on the code steps that result in the plot. Click on the Notes tab to see them. Later, I will discuss some of these elements.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point(size = 1.5, alpha = .5) + \n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  theme_bw()\n\n\n\n\nFigure 2.3: Figure showing a scatterplot of the relation between reaction time and days in the sleepstudy data\n\n\n\n\n\n\nNotice the numbered steps in producing this plot.\n\nsleepstudy %&gt;% \n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  theme_bw()\n\n\nName the dataset: the dataset is called sleepstudy in the lme4 library which makes it available therefore we use this name to specify it.\nsleepstudy %&gt;% uses the %&gt;% pipe operator to pass this dataset to ggplot() to work with, in creating the plot. Because ggplot() now knows about the sleepstudy data, we can next specify what aesthetic mappings we need to use.\nggplot(aes(x = Days, y = Reaction)) + tells R that we want to map Days information to x-axis position and Reaction (response time) information to y-axis position.\ngeom_point() + tells R that we want to locate points – creating a scatterplot – at the paired x-axis and y-xis coordinates.\nscale_x_continuous(breaks = c(0, 3, 6, 9)) + is new: we tell R that we want the x-axis tick labels – the numbers R shows as labels on the x-axis – at the values 0, 3, 6, 9 only.\ntheme_bw() requires R to make the plot background white and the foreground plot elements black.\n\nYou can find more information on scale_ functions in the ggplot2 reference information.\nhttps://ggplot2.tidyverse.org/reference/scale_continuous.html\n\n\n\nThe plot suggests that reaction time increases with increasing number of days.\nIn producing this plot, we are both (1.) engaged in discovery and, potentially, (2.) able to do communication.\n\nDiscovery: is the relation between variables what we should expect, given our assumptions?\nCommunication: to ourselves and others, what relation do we observe, given our sample?\n\nAt this time, we have used and discussed scatterplots before, why we use them, how we write code to produce them, and how we read them.\nWith two additional steps we can significantly increase the power of the visualization. Figure 2.4 is a grid of scatterplots indicating the possible association between reaction time and days separately for each participant.\nAgain, I hide an explanation of the coding steps in the Notes tab: the interested reader can click on the tab to view the step-by-step guide to what is happening.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  mutate(average = mean(Reaction)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Subject = fct_reorder(Subject, average)) %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  geom_line() +\n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  facet_wrap(~ Subject) +\n  theme_bw()\n\n\n\n\nFigure 2.4: Figure showing a scatterplot of the relation between reaction time and days: here, we plot the data for each participant separately\n\n\n\n\n\n\nNotice the numbered steps in producing this plot.\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  mutate(average = mean(Reaction)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Subject = fct_reorder(Subject, average)) %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  geom_line() +\n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  facet_wrap(~ Subject) +\n  theme_bw()\n\nYou can see that the block of code combines data processing and data plotting steps. Let’s look at the data processing steps then the plotting steps in order.\nFirst: why are we doing this? My aim is to produce a plot in which I show the association between Days and Reaction for each Subject individually. I suspect that the association between Days and Reaction may be stronger – so the trend will be steeper – for participants who are slower overall. I suspect this because, given experience, I know that slower, less accurate, participants tend to show larger effects.\nSo: in order to get a grid of plots, one plot for each Subject, in order of the average Reaction for each individual Subject, I need to first calculate the average Reaction then order the dataset rows by those averages. I do that in steps, using pipes to feed information from one step to the next step, as follows.\n\nsleepstudy %&gt;% tells R what data I want to use, and pipe it to the next step.\ngroup_by(Subject) tells R I want it to work with data (rows) grouped by Subject identity code, %&gt;% piping the grouped form of the data forward to the next step\nmutate(average = mean(Reaction)) uses mutate() to create a new variable average which I calculate as the mean() of Reaction, piping the data with this additional variable %&gt;% forward to the next step.\nungroup() %&gt;% tells R I want it to go back to working with the data in rows not grouped rows, and pipe the now ungrouped form of the data to the next step.\nmutate(Subject = fct_reorder(Subject, average)) tells R I want it to sort the rows of the whole sleepstudy dataset in order, moving groups of rows identified by Subject so that data for Subject codes associated with faster times are located near the top of the dataset.\n\nThese data, ordered by Subject by the average Reaction for each participant, are then %&gt;% piped to ggplot to create a plot.\n\nggplot(aes(x = Days, y = Reaction)) + specifies the aesthetic mappings, as before.\ngeom_point() + asks R to locate points at the x-axis, y-axis coordinates, creating a scatterplot, as before.\ngeom_line() + is new: I want R to connect the points, showing the trend in the association between Days and Reaction for each person.\nscale_x_continuous(breaks = c(0, 3, 6, 9)) + fixes the x-axis labels, as before.\nfacet_wrap(~ Subject) + is the big new step: I ask R to plot a separate scatterplot for the data for each individual Subject.\n\nYou can see more information about facetting here:\nhttps://ggplot2.tidyverse.org/reference/facet_wrap.html\nIn short, with the facet_wrap(~ .) function, we are asking R to subset the data by a grouping variable, specified (~ .) by replacing the dot with the name of the variable.\nNotice that I use %&gt;% pipes to move the data processing forward, step by step. But I use + to add plot elements, layer by layer.\n\n\n\nFigure Figure 2.4 is a grid or lattice of scatterplots revealing how the possible association between reaction time and days varies quite substantially between the participants in the sleepstudy data. Most plots indicate that reaction time increases with increasing number of days. However, different participants show this trend to differing extents.\nWhat are the two additions I made to the conventional scatterplot code?\n\nI calculated the average reaction time per participant, and I ordered the data by those averages.\nI facetted the plots, breaking them out into separate scatterplots per participant.\n\nWhy would you do this? Variation between people or groups, in effects or in average outcomes, are often to be found in psychological data (Vasishth & Gelman, 2021). The variation between people that we see in these data — in the average response reaction time, and in how days affects times — would motivate the use of linear mixed-effects models to analyze the way that sleep patterns affect responses in the sleep study (Pinheiro & Bates, 2000).\n\n\n\n\n\n\nTip\n\n\n\nThe data processing and plotting functions in the tidyverse collection of libraries enable us to discover and to communicate variation in behaviours that should strengthen our and others’ scientific understanding.\n\n\n\n\n2.6.4 Summary: Quick start lessons\nWhat we have seen, so far, is that we can make dramatic changes to the appearance of visualizations (e.g., through faceting) and also that we can exert fine control over the details (e.g., adjusting scale labels). What we need to stop and consider are what we want to do (and why), in what order.\nWe have seen how we can feed a data process into a plot to first prepare then produce the plot in a sequence of steps. In processing the data, we can take some original data and extract or calculate information that we can use for our plotting e.g. calculating the mean of a distribution in order to then highlight where that mean is located.\nWe have also seen the use of plots, and the editing of their appearance, to represent information visually. We can verbalize the thought process behind the production of these plots through a series of questions.\n\nAre we looking at the distribution of one variable (if yes: consider a histogram) or are we comparing the distributions of two or more variables (if yes: consider a scatterplot)?\nIs there a salient feature of the plot we want to draw the attention of the audience to? We can add a visual element (like a line) and annotation text to guide the audience.\nAre we interested in variation between sub-sets of the data? We can facet the plot to examine variation between sub-sets (facets) enabling the comparison of trends."
  },
  {
    "objectID": "visualization.html#sec-practical-visualization",
    "href": "visualization.html#sec-practical-visualization",
    "title": "2  Data visualization",
    "section": "2.7 A practical guide to visualization ideas",
    "text": "2.7 A practical guide to visualization ideas\nIn this guide, we illustrate some of the ideas about visualization we discussed at the start, working with practical coding examples. We will be working with real data from a published research project. We are going to focus the practical coding examples on the data collected for the analysis reported by Ricketts et al. (2021).\n\nWe will focus on working with the data from one of the tasks, in one of the studies reported by Ricketts et al. (2021).\n\nThis means that you can consolidate your learning by applying the same code moves to data from the other task in the same study, or to data from the other study.\nIn applying code to other data, you will need to be aware of differences in, say, the way that some things like the outcome response variable are coded.\n\nYou can then further extend your development by trying out the coding moves for yourself using the data collected by Rodríguez-Ferreiro et al. (2020).\n\nThese data are from a quite distinct kind of investigation, on a different research topic than the topic we will be exploring through our working examples.\nHowever, some aspects of the data structure are similar.\nCritically, the data are provided with comprehensive documentation.\n\n\n\n2.7.1 Set up for coding\nTo do our practical work, we will need functions and data. We get these at the start of our workflow.\n\n2.7.1.1 Get libraries\nWe are going to need the lme4, patchwork, psych and tidyverse libraries of functions and data.\n\nlibrary(ggeffects)\nlibrary(patchwork)\nlibrary(psych)\nlibrary(tidyverse)\n\n\n\n2.7.1.2 Get the data\nYou can access the data we are going to use in two different ways.\n\n2.7.1.2.1 Get the data from project repositories\nThe data associated with both (Ricketts et al., 2021) and (Rodríguez-Ferreiro et al., 2020) are freely available through project repositories on the Open Science Framework web pages.\nYou can get the data from the Ricketts et al. (2021) paper through the repository located here.\nYou can get the data from the Rodríguez-Ferreiro et al. (2020) paper through the repository located here.\nThese data are associated with full explanations of data collection methods, materials, data processing and data analysis code. You can review the papers and the repository material guides for further information.\nIn the following, I am going to abstract summary information about the Ricketts et al. (2021) study and data. I shall leave you to do the same for the Rodríguez-Ferreiro et al. (2020) study.\n\n\n2.7.1.2.2 Get the data through a downloadable archive\nDownload the data.zip files folder and upload the files to RStudio Server.\nThe folder includes the Ricketts et al. (2021) data files:\n\nconcurrent.orth_2020-08-11.csv\nconcurrent.sem_2020-08-11.csv\nlong.orth_2020-08-11.csv\nlong.sem_2020-08-11.csv\n\nThe folder also includes the Rodríguez-Ferreiro et al. (2020) data files:\n\nPrimDir-111019_English.csv\nPrimInd-111019_English.csv\n\n\n\n\n\n\n\nWarning\n\n\n\n\nThese data files are collected together in a folder for download, for your convenience, but the version of record for the data for each study comprise the files located on the OSF repositories associated with the original articles.\n\n\n\n\n\n\n\n2.7.2 Information about the Ricketts study and the datasets\nRicketts et al. (2021) conducted an investigation of word learning in school-aged children. They taught children 16 novel words in a study with a 2 x 2 factorial design. In this investigation, they tested whether word learning is helped by presenting targets for word learning with their spellings, and whether learning is helped by telling children that they would benefit from the presence of those spellings.\nThe presence of orthography (the word spelling) was manipulated within participants (orthography absent vs. orthography present): for all children, eight of the words were taught with orthography present and eight with orthography absent. Instructions (incidental vs. explicit) were manipulated between participants such that children in the explicit condition were alerted to the presence of orthography whereas children in the incidental condition were not.\nA pre-test was conducted to establish participants’ knowledge of the stimuli. Then, each child was seen for three 45-minute sessions to complete training (Sessions 1 and 2) and post-tests (Session 3). Ricketts et al. (2021) completed two studies: Study 1 and Study 2. All children, in both studies 1 and 2 completed the Session 3 post-tests.\nIn Study 1, longitudinal post-test data were collected because children were tested at two time points. Children were administered post-tests in Session 3, as noted: Time 1. Post-tests were then re-administered approximately eight months later at Time 2 (\\(M = 241.58\\) days from Session 3, \\(SD = 6.10\\)). In Study 2, the Study 1 sample was combined with an older sample of children. The additional Study 2 children were not tested at Time 2, and the analysis of Study 2 data did not incorporate test time as a factor.\nThe outcome data for both studies consisted of performance on post-tests.\nThe semantic post-test assessed knowledge for the meanings of newly trained words using a dynamic or sequential testing approach. I will not explain this approach in more detail, here, because the practical visualization exercises focus on the orthographic knowledge (spelling knowledge) post-test, explained next.\nThe orthographic post-test was included to ascertain the extent of orthographic knowledge after training. Children were asked to spell each word to dictation and spelling productions were transcribed for scoring. Responses were scored using a Levenshtein distance measure indexing the number of letter deletions, insertions and substitutions that distinguish between the target and child’s response. The maximum score is 0, with higher scores indicating less accurate responses.\nFor the Study 1 analysis, the files are:\n\nlong.orth_2020-08-11.csv\nlong.sem_2020-08-11.csv\n\nWhere long indicates the longitudinal nature of the data-set.\nFor the Study 2 analysis, the files are:\n\nconcurrent.orth_2020-08-11.csv\nconcurrent.sem_2020-08-11.csv\n\nWhere concurrent indicates the inclusion of concurrent (younger and older) child participant samples.\nEach column in each data-set corresponds to a variable and each row corresponds to an observation (i.e., the data are tidy). Because the design of the study involves the collection of repeated observations, the data can be understood to be in a long format.\nEach child was asked to respond to 16 words and, for each of the 16 words, we collected post-test responses from multiple children. All words were presented to all children.\nWe explain what you will find when you inspect the .csv files, next.\n\n2.7.2.1 Data – variables and value coding\nThe variables included in .csv files are listed, following, with information about value coding or calculation.\n\nParticipant — Participant identity codes were used to anonymize participation. Children included in studies 1 and 2 – participants in the longitudinal data collection – were coded “EOF[number]”. Children included in Study 2 only (i.e., the older, additional, sample) were coded “ND[number]”.\nTime — Test time was coded 1 (time 1) or 2 (time 2). For the Study 1 longitudinal data, it can be seen that each participant identity code is associated with observations taken at test times 1 and 2.\nStudy — Observations taken for children included in studies 1 and 2 – participants in the longitudinal data collection – were coded “Study1&2”. Children included in Study 2 only (i.e., the older, additional, sample) were coded “Study2”.\nInstructions — Variable coding for whether participants undertook training in the explicit or incidental conditions.\nVersion — Experiment administration coding\nWord — Letter string values show the words presented as stimuli to children.\nConsistency_H — Calculated orthography-to-phonology consistency value for each word.\nOrthography — Variable coding for whether participants had seen a word in training in the orthography absent or present conditions.\nMeasure — Variable coding for the post-test measure: Sem_all if the semantic post-test; Orth_sp if the orthographic post-test.\nScore — Variable coding for response category.\n\nFor the semantic (sequential or dynamic) post-test, responses were scored as corresponding to:\n\n3 – correct response in the definition task\n2 – correct response in the cued definition task\n1 – correct response in the recognition task\n0 – if the item wasn’t correctly defined or recognised\n\nFor the orthographic post-test, responses were scored as:\n\n1 – correct, if the target spelling was produced in full\n0 – incorrect\n\nHowever, the analysis reported by Ricketts et al. (2021) focused on the more sensitive Levenshtein distance measure (see following).\n\nWASImRS — Raw score – Matrix Reasoning subtest of the Wechsler Abbreviated Scale of Intelligence\nTOWREsweRS — Raw score – Sight Word Efficiency (SWE) subtest of the Test of Word Reading Efficiency; number of words read correctly in 45 seconds\nTOWREpdeRS — Raw score – Phonemic Decoding Efficiency (PDE) subtest of the Test of Word Reading Efficiency; number of nonwords read correctly in 45 seconds\nCC2regRS — Raw score – Castles and Coltheart Test 2; number of regular words read correctly\nCC2irregRS — Raw score – Castles and Coltheart Test 2; number of irregular words read correctly\nCC2nwRS — Raw score – Castles and Coltheart Test 2; number of nonwords read correctly\nWASIvRS — Raw score – vocabulary knowledge indexed by the Vocabulary subtest of the WASI-II\nBPVSRS — Raw score – vocabulary knowledge indexed by the British Picture Vocabulary Scale – Third Edition\nSpelling.transcription — Transcription of the spelling response produced by children in the orthographic post-test\nLevenshtein.Score — Children were asked to spell each word to dictation and spelling productions were transcribed for scoring. Responses were scored using a Levenshtein distance measure indexing the number of letter deletions, insertions and substitutions that distinguish between the target and child’s response. For example, the response ‘epegram’ for target ‘epigram’ attracts a Levenshtein score of 1 (one substitution). Thus, this score gives credit for partially correct responses, as well as entirely correct responses. The maximum score is 0, with higher scores indicating less accurate responses.\n\n(Notice that, for the sake of brevity, I do not list the z_ variables but these are explained in the study OSF repository materials.)\n\n\n\n\n\n\nWarning\n\n\n\nLevenshtein distance scores are higher if a child makes more errors in producing the letters in a spelling response.\n\nThis means that if we want to see what factors help a child to learn a word, including its spelling, then we want to see that helpful factors are associated with lower Levenshtein scores.\n\n\n\nTo demonstrate some of the processes we can enact to process and visualize data, and some of the benefits of doing so, we are going to work with the concurrent.orth_2020-08-11.csv dataset. These are data corresponding to the Ricketts et al. (2021) Study 2. concurrent refers to the analysis (a concurrent comparison) of data from younger and older children.\n\n\n\n2.7.3 Read the data into R\nAssuming you have downloaded the data files, we first read the dataset into the R environment: concurrent.orth_2020-08-11.csv. We do the data read in a bit differently than you have seen it done before; we will come back to what is going on (in Section 2.7.4.1).\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\",\n\n                      col_types = cols(\n\n                        Participant = col_factor(),\n                        Time = col_factor(),\n                        Study = col_factor(),\n                        Instructions = col_factor(),\n                        Version = col_factor(),\n                        Word = col_factor(),\n                        Orthography = col_factor(),\n                        Measure = col_factor(),\n                        Spelling.transcription = col_factor()\n\n                      ))\n\nWe can inspect these data using summary().\n\nsummary(conc.orth)\n\n  Participant   Time          Study         Instructions Version\n EOF001 :  16   1:1167   Study1&2:655   explicit  :592   a:543  \n EOF002 :  16            Study2  :512   incidental:575   b:624  \n EOF004 :  16                                                   \n EOF006 :  16                                                   \n EOF007 :  16                                                   \n EOF008 :  16                                                   \n (Other):1071                                                   \n         Word     Consistency_H     Orthography     Measure    \n Accolade  : 73   Min.   :0.9048   absent :583   Orth_sp:1167  \n Cataclysm : 73   1st Qu.:1.5043   present:584                 \n Contrition: 73   Median :1.9142                               \n Debacle   : 73   Mean   :2.3253                               \n Dormancy  : 73   3rd Qu.:3.0436                               \n Epigram   : 73   Max.   :3.9681                               \n (Other)   :729                                                \n     Score           WASImRS     TOWREsweRS      TOWREpdeRS       CC2regRS    \n Min.   :0.0000   Min.   : 5   Min.   :51.00   Min.   :19.00   Min.   :28.00  \n 1st Qu.:0.0000   1st Qu.:13   1st Qu.:69.00   1st Qu.:35.00   1st Qu.:36.00  \n Median :0.0000   Median :17   Median :74.00   Median :41.00   Median :38.00  \n Mean   :0.2913   Mean   :16   Mean   :74.23   Mean   :41.59   Mean   :36.91  \n 3rd Qu.:1.0000   3rd Qu.:19   3rd Qu.:80.00   3rd Qu.:50.00   3rd Qu.:39.00  \n Max.   :1.0000   Max.   :25   Max.   :93.00   Max.   :59.00   Max.   :40.00  \n                                                                              \n   CC2irregRS       CC2nwRS         WASIvRS          BPVSRS     \n Min.   :17.00   Min.   :13.00   Min.   :16.00   Min.   :103.0  \n 1st Qu.:23.00   1st Qu.:29.00   1st Qu.:25.00   1st Qu.:119.0  \n Median :25.00   Median :33.00   Median :29.00   Median :133.0  \n Mean   :25.24   Mean   :32.01   Mean   :29.12   Mean   :130.9  \n 3rd Qu.:27.00   3rd Qu.:37.00   3rd Qu.:33.00   3rd Qu.:142.0  \n Max.   :35.00   Max.   :40.00   Max.   :39.00   Max.   :158.0  \n                                                                \n Spelling.transcription Levenshtein.Score  zTOWREsweRS        zTOWREpdeRS      \n Epigram   : 57         Min.   :0.000     Min.   :-2.67807   Min.   :-2.33900  \n Platitude : 43         1st Qu.:0.000     1st Qu.:-0.60283   1st Qu.:-0.68243  \n Contrition: 42         Median :1.000     Median :-0.02638   Median :-0.06122  \n fracar    : 39         Mean   :1.374     Mean   : 0.00000   Mean   : 0.00000  \n Nonentity : 39         3rd Qu.:2.000     3rd Qu.: 0.66537   3rd Qu.: 0.87061  \n raconter  : 35         Max.   :7.000     Max.   : 2.16415   Max.   : 1.80243  \n (Other)   :912                                                                \n   zCC2regRS        zCC2irregRS          zCC2nwRS          zWASIvRS       \n Min.   :-3.3636   Min.   :-2.22727   Min.   :-3.1053   Min.   :-2.63031  \n 1st Qu.:-0.3435   1st Qu.:-0.60461   1st Qu.:-0.4920   1st Qu.:-0.82633  \n Median : 0.4115   Median :-0.06373   Median : 0.1614   Median :-0.02456  \n Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.00000  \n 3rd Qu.: 0.7890   3rd Qu.: 0.47716   3rd Qu.: 0.8147   3rd Qu.: 0.77721  \n Max.   : 1.1665   Max.   : 2.64070   Max.   : 1.3047   Max.   : 1.97986  \n                                                                          \n    zBPVSRS         mean_z_vocab       mean_z_read       zConsistency_H   \n Min.   :-1.9946   Min.   :-2.06910   Min.   :-2.39045   Min.   :-1.4153  \n 1st Qu.:-0.8495   1st Qu.:-0.85941   1st Qu.:-0.43321   1st Qu.:-0.8181  \n Median : 0.1525   Median :-0.01483   Median : 0.08829   Median :-0.4096  \n Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.0000  \n 3rd Qu.: 0.7967   3rd Qu.: 0.72964   3rd Qu.: 0.68438   3rd Qu.: 0.7157  \n Max.   : 1.9418   Max.   : 1.96083   Max.   : 1.52690   Max.   : 1.6368  \n                                                                          \n\n\nYou should notice one key bit of information in the summary. Focus on the summary for what is in the Participant column. You can see that we have a number of participants in this dataset, listed by Participant identity code in the summary() view e.g. EOF001. For each participant, we have 16 rows of data.\nWhen we ask R for a summary of a nominal variable or factor it will show us the levels of each factor (i.e., each category or class of objects encoded by the categorical variable), and a count for the number of observations for each level.\nTake a look at the rows of data for EOF001.\n\n\n\n\n\nParticipant\nTime\nStudy\nInstructions\nVersion\nWord\nConsistency_H\nOrthography\nMeasure\nScore\nWASImRS\nTOWREsweRS\nTOWREpdeRS\nCC2regRS\nCC2irregRS\nCC2nwRS\nWASIvRS\nBPVSRS\nSpelling.transcription\nLevenshtein.Score\nzTOWREsweRS\nzTOWREpdeRS\nzCC2regRS\nzCC2irregRS\nzCC2nwRS\nzWASIvRS\nzBPVSRS\nmean_z_vocab\nmean_z_read\nzConsistency_H\n\n\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nAccolade\n1.9142393\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nacalade\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.4095955\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nCataclysm\n3.5060075\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nCataclysm\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.1763372\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nContrition\n1.7486898\nabsent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nContrition\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.5745381\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nDebacle\n2.9008386\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\ndibarcle\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.5733869\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nDormancy\n1.6263089\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\ndoormensy\n3\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.6964704\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nEpigram\n1.3822337\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nEpigram\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.9396508\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nFoible\n2.7051987\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nFoible\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.3784641\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nFracas\n3.1443345\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nfracar\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.8159901\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nLassitude\n0.9048202\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nlacitude\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.4153141\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nLuminary\n1.0985931\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nloomenery\n4\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.2222516\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nNonentity\n3.9681391\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nnonenterty\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.6367746\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nPlatitude\n0.9048202\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nPlatitude\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.4153141\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nPropensity\n1.6861898\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\npropencity\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.6368090\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nRaconteur\n3.8245334\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nraconter\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.4936954\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nSyncopation\n3.0436450\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nsincipation\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.7156697\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nVeracity\n2.8693837\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nvaracity\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.5420473\n\n\n\n\n\n\n\nYou can see that for EOF001, as for every participant, we have information on the conditions under which we observed their responses (Instructions, Orthography), as well as information about the stimuli that we asked participants to respond to (e.g., Word, Consistency_H), information about the responses or outcomes we recorded (Measure, Score, Spelling.transcription,  Levenshtein.Score), and information about the participants themselves (e.g., TOWREsweRS, TOWREpdeRS).\n\n\n2.7.4 Process the data\nWe almost always need to process data in order to render the information ready for discovery or communication data visualization.\n\n2.7.4.1 Specify column data types\nYou will have seen that data processing began when we first read the data in for use. Let’s go back and take a look at the code steps.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\",\n\n                      col_types = cols(\n\n                        Participant = col_factor(),\n                        Time = col_factor(),\n                        Study = col_factor(),\n                        Instructions = col_factor(),\n                        Version = col_factor(),\n                        Word = col_factor(),\n                        Orthography = col_factor(),\n                        Measure = col_factor(),\n                        Spelling.transcription = col_factor()\n\n                        )\n                      )\n\nThe chunk of code is doing two things: first, we tell R what .csv file we want to read into the environment, and what we want to call the dataset; and then we tell R how we want to classify the data variable columns.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\" first reads the named .csv file, creating an object I will call conc.orth: a dataset or tibble we can now work with in R.\n\n\nYou have been using the read.csv() function to read in data files.\nThe read_csv() function is the more modern tidyverse form of the function you were introduced to.\nBoth versions work in similar ways but read_csv() is a bit more efficient, and it allows us to do what we do next.\n\n\ncol_types = cols( ... ) tells R how to interpret some of the columns in the .csv.\n\n\nThe read_csv() function is excellent at working out what types of data are held in each column but sometimes we have to tell it what to do.\nHere, I am specifying with e.g. Participant = col_factor() that the Participant column should be treated as a categorical or nominal variable, a factor.\n\nUsing the col_types = cols( ... ) argument saves me from having to first read the data in then using code like the following to require, technically, coerce R into recognizing the nominal nature of variables like Participant with code like\n\nconc.orth$Participant &lt;- as.factor(conc.orth$Participant)\n\n\n2.7.4.1.1 Exercise\nI do not have to do step 2 of the read-in process, here. What happens if we use just read_csv()? Try it.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\")\n\n\n\n2.7.4.1.2 Further information\nYou can read more about read_csv() here\nYou can read more about col_types = cols() here\n\n\n\n2.7.4.2 Extract information from the dataset\nThe Ricketts et al. (2021) dataset orth.conc is a moderately sized and rich dataset with several observations, on multiple variables, for each of many participants. Sometimes, we want to extract information from a more complex dataset because we want to understand or present a part of it, or a relatively simple account of it. We look at an example of how you might do that now.\nAs you saw when you looked at the summary of the orth.conc dataset, we have multiple rows of data for each participant. Recall the design of the study. For each participant, we recorded their response to a stimulus word, in a test of word learning, for 16 words.\nFor each participant, we have a separate row for each response the participant made to each word. But you will have noticed that information about the participant is repeated. So, for participant EOF001, we have data about their performance e.g. on the BPVSRS vocabulary test (they scored 126). Notice that that score is repeated: the same value is copied for each row, for this participant, in the BPVSRS column. The reason the data are structured like this are not relevant here 1 but it does require us to do some data processing, as I explain next.\nIt is a very common task to want to present a summary of the attributes of your participants or stimuli when you are reporting data in a report of a psychological research project. We could get a summary of the participant attributes using the psych library describe function as follows.\n\nconc.orth %&gt;%\n  select(WASImRS:BPVSRS) %&gt;%\n  describe(ranges = FALSE, skew = FALSE)\n\n           vars    n   mean    sd   se\nWASImRS       1 1167  16.00  4.30 0.13\nTOWREsweRS    2 1167  74.23  8.67 0.25\nTOWREpdeRS    3 1167  41.59  9.66 0.28\nCC2regRS      4 1167  36.91  2.65 0.08\nCC2irregRS    5 1167  25.24  3.70 0.11\nCC2nwRS       6 1167  32.01  6.12 0.18\nWASIvRS       7 1167  29.12  4.99 0.15\nBPVSRS        8 1167 130.87 13.97 0.41\n\n\nBut you can see that part of the information in the summary does not appear to make sense at first glance. We do not have 1167 participants in this dataset, as Ricketts et al. (2021) report.\nHow do we extract the participant attribute variable data for each unique participant code for the participants in our dataset?\n\nconc.orth.subjs &lt;- conc.orth %&gt;%\n  group_by(Participant) %&gt;%\n  mutate(mean.score = mean(Levenshtein.Score)) %&gt;%\n  ungroup() %&gt;%\n  distinct(Participant, .keep_all = TRUE) %&gt;%\n  select(WASImRS:BPVSRS, mean.score, Participant)\n\nWe create a new dataset conc.orth.subjs by taking conc.orth and piping it through a series of processing steps. As part of the process, we want to extract the data for each unique unique Participant identity code using distinct(). Along the way, we want to calculate the mean accuracy of response on the outcome measure (Score), that is, the average number of edits separating a child’s spelling of a target word from the correct spelling.\nThis is how we do it.\n\nconc.orth.subjs &lt;- ... tells R to create a new dataset conc.orth.subjs.\nconc.orth %&gt;% ... we do this by telling R to take conc.orth and pipe it through the following steps.\ngroup_by(Participant) %&gt;% first we group the data by Participant identity code.\nmutate(mean.score = mean(Score)) %&gt;% then we use mutate() to create the new variable mean.score by calculating the mean() of the Score variable values (i.e. the average score) for each participant. We then pipe to the next step.\nungroup() %&gt;% we tell R to ungroup the data because we want to work with all rows for what comes next, and we then pipe to the next step.\ndistinct(Participant, .keep_all = TRUE) %&gt;% requires R to extract from the full orth.conc dataset the set of (here, 16) data rows we have for each distinct (uniquely identified) Participant. We use the argument .keep_all = TRUE to tell R that we want to keep all columns. This requires the next step, so we tell R to pipe %&gt;% the data.\nselect(WASImRS:BPVSRS, mean.score, Participant) then tells R to select just the columns with information about participant attributes. (WASImRS:BPVSRS tells R to select every column between WASImRS and BPVSRS inclusive. mean.score, Participant tells R we also want those columns, specified by name, including the mean.score column of average response scores we calculated just earlier.\n\nWe can now get a sensible summary of the descriptive statistics for the participants in Study 2 of the Ricketts et al. (2021) investigation.\n\nconc.orth.subjs %&gt;%\n  select(-Participant) %&gt;%\n  describe(ranges = FALSE, skew = FALSE)\n\n           vars  n   mean    sd   se\nWASImRS       1 73  16.00  4.33 0.51\nTOWREsweRS    2 73  74.22  8.73 1.02\nTOWREpdeRS    3 73  41.58  9.73 1.14\nCC2regRS      4 73  36.90  2.67 0.31\nCC2irregRS    5 73  25.23  3.72 0.44\nCC2nwRS       6 73  32.00  6.17 0.72\nWASIvRS       7 73  29.12  5.02 0.59\nBPVSRS        8 73 130.88 14.06 1.65\nmean.score    9 73   1.38  0.62 0.07\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis is exactly the kind of tabled summary of descriptive statistics we would expect to produce in a report, in a presentation of the participant characteristics for a study sample (in e.g., the Methods section).\nNotice:\n\nThe table has not yet been formatted according to APA rules.\nWe would prefer to use real words for row name labels instead of dataset variable column labels, e.g, replace TOWREsweRS with: “TOWRE word reading score”.\n\n\n\n\n2.7.4.2.1 Exercise\nIn these bits of demonstration code, we extract information relating just to participants. However, in this study, we recorded the responses participants made to 16 stimulus words, and we include in the dataset information about the word properties Consistency_H.\n\nCan you adapt the code you see here in order to calculate a mean score for each word, and then extract the word-level information for each distinct stimulus word identity?\n\n\n\n2.7.4.2.2 Further information\nYou can read more about the psych library, which is often useful, here. You can read more about the distinct() function here.\n\n\n\n\n2.7.5 Visualize the data: introduction\nIt has taken us a while but now we are ready to examine the data using visualizations. Remember, we are engaging in visualization to (1.) do discovery, to get a sense of our data, and maybe reveal unexpected aspects, and (2.) potentially to communicate to ourselves and others what we have observed or perhaps what insights we can gain.\nWe have been learning to use histograms, in other classes, so let’s start there.\n\n\n2.7.6 Examine the distributions of numeric variables\nWe can use histograms to visualize the distribution of observed values for a numeric variable. Let’s start simple, and then explore how to elaborate the plotting code, in a series of edits, to polish the plot presentation.\n\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram()\n\n\n\n\nFigure 2.5: Distribution of WASImRS intelligence scores\n\n\n\n\nThis is how the code works.\n\nggplot(data = conc.orth.subjs, ... tells R what function to use ggplot() and what data to work with data = conc.orth.subjs.\naes(x = WASImRS) tells R what aesthetic mapping to use: we want to map values on the WASImRS variable (small to large) to locations on the x-axis (left to right).\ngeom_histogram() tells R to construct a histogram, presenting a statistical summary of the distribution of intelligence scores.\n\nWith histograms, we are visualizing the distribution of a single continuous variable by dividing the variable values into bins (i.e. subsets) and counting the number of observations in each bin. Histograms display the counts with bars.\nYou can see more information about geom_histogram here.\nFigure 2.5 shows how intelligence (WASImRS) scores vary in the Ricketts Study 2 dataset. Scores peak around 17, with a long tail of lower scores towards 5, and a maximum around 25.\n\nWhere I use the word “peak” I am talking about the tallest bar in the plot (or, later the highest point in a density curve). At this point, we have the most observations of the value under the bar. Here, we observed the score WASImRS \\(= 17\\) for the most children in this sample.\n\nA primary function of discovery visualization is to assess whether the distribution of scores on a variable is consistent with expectations, granted assumptions about a sample (e.g., that the children are typically developing). We would normally use research area knowledge to assess whether this distribution fits expectations for a sample of typically developing school-aged children in the UK. However, I shall leave that concern aside, here, so that we can focus on enriching the plot presentation, next.\nThere are two main problems with the plot:\n\nThe bars are “gappy” in the histogram, suggesting we have not grouped observed values in sufficiently wide subsets (bins). This is a problem because it weakens our ability to gain or communicate a visual sense of the distribution of scores.\nThe axis labeling uses the dataset variable name WASImRS but if we were to present the plot to others we could not expect them to know what that means.\n\nWe can fix both these problems, and polish the plot for presentation, through the following code steps.\n\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"Scores on the Wechsler Abbreviated Scale of Intelligence\") +\n  theme_bw()\n\n\n\n\nFigure 2.6: Distribution of WASImRS intelligence scores\n\n\n\n\nFigure 2.6 shows the same data, and furnishes us with the same picture of the distribution of intelligence scores but it is a bit easier to read. We achieve this by making three edits.\n\ngeom_histogram(binwidth = 2) + we change the binwidth.\n\n\nThis is so that more different observed values of the data variable are included in bins (subsets corresponding to bars) so that the bars correspond to information about a wider range of values.\nThis makes the bars bigger, wider, and closes the gaps.\nAnd this means we can focus the eyes of the audience for our plot on the visual impression we wish to communicate: the skewed distribution of intelligence scores.\n\n\nlabs(x = \"Scores on the Wechsler Abbreviated Scale of Intelligence\") + changes the label to something that should be understandable by people, in our audience, who do not have access to variable information (as we do) about the dataset.\ntheme_bw() we change the overall appearance of the plot by changing the theme.\n\n\n2.7.6.1 Exercise\nWe could, if we wanted, add a line and annotation to indicate the mean value, as you saw in Figure 2.2.\n\nCan you add the necessary code to indicate the mean value of WASI scores, for this plot?\n\nWe can, of course, plot histograms to indicate the distributions of other variables.\n\nCan you apply the histogram code to plot histograms of other variables?\n\n\n\n\n2.7.7 Comparing the distributions of numeric variables\nWe may wish to discover or communicate how values vary on dataset variables in two different ways. Sometimes, we need to examine how values vary on different variables. And sometimes, we need to examine how values vary on the same variable but in different groups of participants (or stimuli) or under different conditions. We look at this next. We begin by looking at how you might compare how values vary on different variables.\n\n2.7.7.1 Compare how values vary on different variables\nIt can be useful to compare the distributions of different variables. Why?\nConsider the Ricketts et al. (2021) investigation dataset. Like many developmental investigations (see also clinical investigations), we tested children and recorded their scores on a series of standardized measures, here, measures of ability on a range of dimensions. We did this, in part, to establish that the children in our sample are operating at about the level one might expect for typically developing children in cognitive ability dimensions of interest: dimensions like intelligence, reading ability or spelling ability. So, one of the aspects of the data we are considering is whether scores on these dimensions are higher or lower than typical threshold levels. But we also want to examine the distributions of scores because we want to find out:\n\nif participants are varied in ability (wide distribution) or if maybe they are all similar (narrow distribution) as would be the case if the ability measures are too easy (so all scores are at ceiling) or too hard (so all scores are at floor);\nif there are subgroups within the sample, maybe reflected by two or more peaks;\nif there are unusual scores, maybe reflected by small peaks at very low or very high scores.\n\nWe could look at each variable, one plot at a time. Instead, next, I will show you how to produce a set of histogram plots, and present them all as a single grid of plots.\n\n\n\n\n\n\nWarning\n\n\n\nI have to warn you that the way I write the code is not good practice. The code is written with repeats of the ggplot() block of code to produce each plot. This repetition is inefficient and leaves the coding vulnerable to errors because it is hard to spot a mistake in more code. What I should do is encapsulate the code as a function (see here). The reason I do not, here, is because I want to focus our attention on just the plotting.\n\n\nFigure 2.7 presents a grid of plots showing how scores vary for each ability test measure, for the children in the Ricketts et al. (2021) investigation dataset. We need to go through the code steps, next, and discuss what the plots show us (discovery and communication).\n\np.WASImRS &lt;- ggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"WASI matrix\") +\n  theme_bw()\n\np.TOWREsweRS &lt;- ggplot(data = conc.orth.subjs, aes(x = TOWREsweRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"TOWRE words\") +\n  theme_bw()\n\np.TOWREpdeRS &lt;- ggplot(data = conc.orth.subjs, aes(x = TOWREpdeRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"TOWRE phonemic\") +\n  theme_bw()\n\np.CC2regRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2regRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC regular words\") +\n  theme_bw()\n\np.CC2irregRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2irregRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC irregular words\") +\n  theme_bw()\n\np.CC2nwRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2nwRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC nonwords\") +\n  theme_bw()\n\np.WASIvRS &lt;- ggplot(data = conc.orth.subjs, aes(x = WASIvRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"WASI vocabulary\") +\n  theme_bw()\n\np.BPVSRS &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS)) +\n  geom_histogram(binwidth = 3) +\n  labs(x = \"BPVS vocabulary\") +\n  theme_bw()\n\np.mean.score &lt;- ggplot(data = conc.orth.subjs, aes(x = mean.score)) +\n  geom_histogram(binwidth = .25) +\n  labs(x = \"Mean orthographic test score\") +\n  theme_bw()\n\np.mean.score + p.BPVSRS + p.WASIvRS + p.WASImRS +\n  p.CC2nwRS + p.CC2irregRS + p.CC2regRS + \n  p.TOWREpdeRS + p.TOWREsweRS + plot_layout(ncol = 3)\n\n\n\n\nFigure 2.7: Distribution of childrens’ scores on ability measures\n\n\n\n\nThis is how the code works, step by step:\n\np.WASImRS &lt;- ggplot(...) first creates a plot object, which we call p.WASImRS.\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) + tells R what data to use, and what aesthetic mapping to work with mapping the variable WASImRS here to the x-axis location.\ngeom_histogram(binwidth = 2) + tells R to sort the values of WASImRS scores into bins and create a histogram to show how many children in the sample present scores of different sizes.\nlabs(x = \"WASI matrix\") + changes the x-axis label to make it more informative.\ntheme_bw() changes the theme to make it a bit cleaner looking.\n\nWe do this bit of code separately for each variable. We change the plot object name, the x = variable specification, and the axis label text for each variable. We adjust the binwidth where it appears to be necessary.\nWe then use the following plot code to put all the plots together in a single grid.\n\np.mean.score + p.BPVSRS + p.WASIvRS + p.WASImRS +\n  p.CC2nwRS + p.CC2irregRS + p.CC2regRS + \n  p.TOWREpdeRS + p.TOWREsweRS + plot_layout(ncol = 3)\n\n\nIn the code, we add a series of plots together e.g. p.mean.score + p.BPVSRS + p.WASIvRS ...\nand then specify we want a grid of plots with a layout of three columns plot_layout(ncol = 3).\n\nThis syntax requires the library(patchwork) and more information about this very useful library can be found here.\nWhat do the plots show us?\nFigure 2.7 shows a grid of 9 histogram plots. Each plot presents the distribution of scores for the Ricketts et al. (2021) Study 2 participant sample on a separate ability measure, including scores on the BPVS vocabulary, WASI vocabulary, TOWRE words and TOWRE nonwords reading tests, as well as scores on the Castles and Coltheart regular words, irregular words and nonwords reading tests, and the mean Levenshtein distance (spelling score) outcome measure of performance for the experimental word learning post-test.\nTake a look, you may notice the following features.\n\nThe mean orthographic test score suggests that many children produced spellings to the words they learned in the Ricketts et al. (2021) study that, on average, were correct (0 edits) or were one or two edits (e.g., a letter deletion or replacement) away from the target word spelling. The children were learning the words, and most of the time, they learned the spellings of the words effectively. However, one or two children tended to produce spellings that were 2-3 edits distant from the target spelling.\n\n\nWe can see these features because we can see that the histogram peaks around 1 (at Levenshtein distance score \\(= 1\\)) but that there is a small bar of scores at around 3.\n\n\nWe can see that there are two peaks on the BPVS and WASI measures of vocabulary. What is going on there?\n\n\nIs it the case that we have two sub-groups of children within the overall sample? For example, on the BPVS test, maybe one sub-group of children has a distribution of vocabulary scores with a peak around 120 (the peak shows where most children have scores) while another sub-group of children has a distribution of vocabulary scores with a peak around 140.\n\n\nIf we look at the CC nonwords and CC regular words tests of reading ability, we may notice that while most children present relatively high scores on these tests (CC nonwords peak around 35, CC regular words peak around 37) there is a skewed distribution. Many of the children’s scores are piled up towards the maximum value in the data on the measures. But we can also see that, on both measures, there are long tails in the distributions because relatively small numbers of children have substantially lower scores.\n\n\nDevelopmental samples are often highly varied (just like clinical samples). Are all the children in the sample at the same developmental stage, or are they all typically developing?\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that in presenting a grid of plots like this, we offer a compact visual way to present the same summary information we might otherwise present using a table of descriptive statistics. In some ways, this grid of plots is more informative than the descriptive statistics because the mean and SD values do not tell you what you can see:\n\nthe characteristics of the variation in values, like the presence of two peaks;\nor the presence of unusually high or low scores (for this sample).\n\n\n\nGrids of plots like this can be helpful to inspect the distributions of variables in a concise approach. They are not really too useful for comparing the distributions because they require your eyes to move between plots, repeatedly, to do the comparison.\nHere is a more compact way to code the grid of histograms using the library(ggridges) function geom_density_ridges(). I do not discuss it in detail because I want to focus your attention on core tidyverse functions (I show you more information in the Notes tab).\nNotice that if you produce all the plots so that the are in line in the same column with a shared x-axis it becomes much easier to compare the distributions of scores. You lose some of the fine detail, discussed in relation to Figure 2.7, but this style allows you to gain an impression, quickly, of how for distributions of scores compare between measures. For example, we can see that within the Castles and Coltheart (CC) measures of reading ability, children do better on regular words than on nonwords, and on nonwords better than on irregular words.\n\nPlotNotes\n\n\n\nlibrary(ggridges)\nconc.orth.subjs %&gt;%\n  pivot_longer(names_to = \"task\", values_to = \"score\", cols = WASImRS:mean.score) %&gt;% \n  ggplot(aes(y = task, x = score)) +\n  geom_density_ridges(stat = \"binline\", bins = 20, scale = 0.95, draw_baseline = FALSE) +\n  theme_ridges()\n\n\n\n\nFigure 2.8: Distribution of childrens’ scores on ability measures\n\n\n\n\n\n\n\nlibrary(ggridges) get the library we need.\nconc.orth.subjs %&gt;% pipe the dataset for processing.\npivot_longer(names_to = \"task\", values_to = \"score\", cols = WASImRS:mean.score) %&gt;% pivot the data so all test scores are in the same column, “scores” wwith coding for “task” name, and pipe to the next step for plotting.\nggplot(aes(y = task, x = score)) + create a plot for the scores on each task.\ngeom_density_ridges(stat = \"binline\", bins = 20, scale = 0.95, draw_baseline = FALSE) + show the plots as histograms.\ntheme_ridges() change the theme to the specific theme suitable for showing a grid of ridges.\n\nYou can find more information on ggridges here.\n\n\n\n\n\n2.7.7.2 Compare between groups how values vary on different variables\nWe will often want to compare the distributions of variable values between groups or between conditions. This need may appear when, for example, we are conducting a between-groups manipulation of some condition and we want to check that the groups are approximately matched on dimensions that are potentially linked to outcomes (i.e., on potential confounds). The need may appear when, alternatively, we have recruited or selected participant (or stimulus) samples and we want to check that the sample sub-groups are approximately matched or detectably different on one or more dimensions of interest or of concern.\nAs a demonstration of the visualization work we can do in such contexts, let’s pick up on an observation we made earlier, that there are two peaks on the BPVS and WASI measures of vocabulary. I asked: Is it the case that we have two sub-groups of children within the overall sample? Actually, we know the answer to that question because Ricketts et al. (2021) state that they recruited one set of children for their Study 1 and then, for Study 2:\n\nThirty-three children from an additional three socially mixed schools in the South-East of England were added to the Study 1 sample (total N = 74). These additional children were older (\\(M_{age}\\) = 12.57, SD = 0.29, 17 female)\n\nDo the younger (Study 1) children differ in any way from the older (additional) children?\nWe can check this through data visualization. Our aim is to present the distributions of variables side-by-side or superimposed to ensure easy comparison. We can do this in different ways, so I will demonstrate one approach with an outline explanation of the actions, and offer suggestions for further approaches.\nI am going to process the data before I do the plotting. I will re-use the code I used before (see Section 2.7.4.2) with one additional change. I will add a line to create a group coding variable. This addition shows you how to do an action that is very often useful in the data processing part of your workflow.\n\n2.7.7.2.1 Data processing\nYou have seen that the Ricketts et al. (2021) report states that an additional group of children was recruited for the investigation’s second study. How do we know who they are? If you recall the summary view of the complete dataset, there is one variable we can use to code group identity.\n\nsummary(conc.orth$Study)\n\nStudy1&2   Study2 \n     655      512 \n\n\nThis summary tells us that we have 512 observations concerning the additional group of children recruited for Study 2, and 655 observations for the (younger) children whose data were analyzed for both Study 1 and Study 2 (i.e., coded as Study1&2 in the Study variable column). We can use this information to create a coding variable. (If we had age data, we could use that instead but we do not.) This is how we do that.\n\nconc.orth.subjs &lt;- conc.orth %&gt;%\n  group_by(Participant) %&gt;%\n  mutate(mean.score = mean(Levenshtein.Score)) %&gt;%\n  ungroup() %&gt;%\n  distinct(Participant, .keep_all = TRUE) %&gt;%\n  mutate(age.group = fct_recode(Study,\n    \n    \"young\" = \"Study1&2\",\n    \"old\" = \"Study2\"\n    \n  )) %&gt;%\n  select(WASImRS:BPVSRS, mean.score, Participant, age.group)\n\nThe code block is mostly the same as the code I used in Section Section 2.7.4.2 to extract the data for each participant, with two changes:\n\nFirst, mutate(age.group = fct_recode(...) tells R that I want to create a new variable age.group through the process of recoding, with fct_recode(...) the variable I specify next, in the way that I specify.\nfct_recode(Study, ...) tells R I want to recode the variable Study.\n\"young\" = \"Study1&2\", \"old\" = \"Study2\" specifies what I want recoded.\n\n\nI am telling R to look in the Study column and (a.) whenever it finds the value Study1&2 replace it with young whereas (b.) whenever it finds the value Study2 replace it with old.\nNotice that the syntax in recoding is fct_recode: “new name” = “old name”.\nHaving done that, I tell R to pipe the data, including the recoded variable, to the next step.\n\n\nselect(WASImRS:BPVSRS, mean.score, Participant, age.group) where I add the new recoded variable to the selection of variables I want to include in the new dataset conc.orth.subjs.\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that R handles categorical or nominal variables like Study (or, in other data, variables e.g. gender, education or ethnicity) as factors.\n\nWithin a classification scheme like education, we may have different classes or categories or groups e.g. “further, higher, school”. We can code these different classes with numbers (e.g. \\(school = 1\\)) or with words “further, higher, school”. Whatever we use, the different classes or groups are referred to as levels and each level has a name.\nIn factor recoding, we are changing level names while keeping the underlying data the same.\n\n\n\nThe tidyverse collection includes the forcats library of functions for working with categorical variables (forcats = factors). These functions are often very useful and you can read more about them here.\nChanging factors level coding by hand is, for many, a common task, and the fct_recode() function makes it easy. You can find the technical information on the function, with further examples, here.\n\n\n2.7.7.2.2 Group comparison visualization\nThere are different ways to examine the distributions of variables so that we can compare the distributions of the same variable between groups.\nFigure 2.9 presents some alternatives as a grid of 4 different kinds of plots designed to enable the same comparison. Each plot presents the distribution of scores for the Ricketts et al. (2021) Study 2 participant sample on the BPVS vocabulary measure so that we can compare the distribution of vocabulary scores between age groups.\nThe plots differ in method using:\n\nfacetted histograms showing the distribution of vocabulary scores, separately for each group, in side-by-side histograms for comparison;\nboxplots, showing the distribution of scores for each group, indicated by the y-axis locations of the edges of the boxes (25% and 75% quartiles) and the middle lines (medians);\nsuperimposed histograms, where the histograms for the separate groups are laid on top of each other but given different colours to allow comparison; and\nsuperimposed density plots where the densities for the separate groups are laid on top of each other but given different colours to allow comparison.\n\n\n\n\n\n\n\nTip\n\n\n\nThere is one thing you should notice about all these plots.\n\nIt looks like the BPVS vocabulary scores have their peak – most children show this value – at around 120 for the young group and at around 140 for the old group.\n\nWe return to this shortly.\n\n\n\nI am going to hide the coding and the explanation of the coding behind the Notes tab. Click on the tab to get a step-by-step explanation. Of these alternatives, I focus on one which I explain in more depth, following: d. Superimposed density plots.\n\nPlotNotes\n\n\n\n\n\n\n\nFigure 2.9: Distribution of childrens’ scores on the BPVS vocabulary measure: distributions are compared between the younger and older age groups\n\n\n\n\n\n\n\np.facet.hist &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"BPVS vocabulary score\", title = \"a. Faceted histograms\") +\n  facet_wrap(~ age.group) +\n  theme_bw()\n\np.colour.boxplot &lt;- ggplot(data = conc.orth.subjs, aes(y = BPVSRS, colour = age.group)) +\n  geom_boxplot() +\n  labs(x = \"BPVS vocabulary score\", title = \"b. Boxplots\") +\n  theme_bw()\n\np.colour.hist &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"BPVS vocabulary score\", title = \"c. Superimposed histograms\") +\n  theme_bw()\n\np.colour.density &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  labs(x = \"BPVS vocabulary score\", title = \"d. Superimposed density plots\") +\n  theme_bw()\n\np.facet.hist + p.colour.boxplot + p.colour.hist + p.colour.density\n\n\nIn plot “a. Faceted histograms”, we use the code to construct a histogram but the difference is we use:\n\n\nfacet_wrap(~ age.group) to tell R to split the data by age.group then present the histograms indicating vocabulary score distributions separately for each group.\n\n\nIn plot “b. Boxplots”, we use the geom_boxplot() code to construct a boxplot to summarize the distributions of vocabulary scores – as you have seen previously – but the difference is we use:\n\n\naes(y = BPVSRS, colour = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\n\n\nIn plot “c. Superimposed histograms”, we use the code to construct a histogram but the difference is we use:\n\n\naes(x = BPVSRS, colour = age.group, fill = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\nNotice that the fill gives the colour inside the bars and colour gives the colour of the outline edges of the bars.\n\n\nIn plot “d. Superimposed density plots”, we use the code geom_density(...) to construct what is called a density plot.\n\n\nA density plot presents a smoothed histogram to show the distribution of variable values.\nWe add arguments in geom_density(alpha = .5, size = 1.5) to adjust the thickness of the line (size = 1.5) drawn to show the shape of the distribution and adjust the transparency of the colour fill inside the line alpha = .5).\nWe useaes(x = BPVSRS, colour = age.group, fill = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\nNotice that the fill gives the colour inside the density plots and colour gives the colour of the outline edges of the densities.\n\n\n\n\nDensity plots can be helpful when we wish to compare distributions. This is because we can superimpose distribution plots on top of each other, enabling us or our audience to directly compare the distributions: directly because the distributions are shown on the same scale, in the same image.\nWe can (roughly) understand a density plot as working like a smoothed version of the histogram. Imagine how the heights of the bars in the histogram represent how many observations we have of the values in a particular bin. If we draw a smooth curving line through the tops of the bars then we are representing the chances that an observation in our sample has a value (the value under the curve) at any specific location on the x-axis. You can see that in Figure 2.10.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\nFigure 2.10: Distribution of childrens’ scores on the BPVS vocabulary measure. The figure shows the histogram versus density plot representation of the same data distribution\n\n\n\n\nYou can find the ggplot2 reference information on the geom_density() function, with further examples, here. You can find technical information on density functions here and here.\nWe can develop the density plot to enrich the information we can discover or communicate through the plot. Figure 2.11 shows the distribution of scores on both the BPVS and WASI vocabulary knowledge measures.\n\np.BPVSRS.density &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  geom_rug(alpha = .5) +\n  geom_vline(xintercept = 120, linetype = \"dashed\") +\n  geom_vline(xintercept = 140, linetype = \"dotted\") +\n  labs(x = \"BPVSRS vocabulary score\") +\n  theme_bw()\n\np.WASIvRS.density &lt;- ggplot(data = conc.orth.subjs, aes(x = WASIvRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  geom_rug(alpha = .5) +\n  labs(x = \"WASI vocabulary score\") +\n  theme_bw()\n\np.BPVSRS.density + p.WASIvRS.density + plot_layout(guides = 'collect')\n\n\n\n\nFigure 2.11: Distribution of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\nHere is what the code does:\n\np.BPVRS.density &lt;- ggplot(...) creates a plot object called p.BPVRS.density.\ndata = conc.orth.subjs, ... says we use the conc.orth.subjs dataset to do this.\naes(x = BPVRS, colour = age.group, fill = age.group)) + says we want to map BPVRS scores to x-axis location, and age.group level coding (young, old) to both colour and fill.\ngeom_density(alpha = .5, size = 1.5) + draws a density plot; note that we said earlier what we want for colour and fill but here we also say that:\n\n\nalpha = .5 we want the fill to be transparent;\nsize = 1.5 we want the density curve line to be thicker than usual.\n\n\ngeom_rug(alpha = .5) + adds a one-dimensional plot, a series of tick marks, to show where we have observations of BPVRS scores for specific children. We ask R to make the tick marks semi-transparent.\ngeom_vline(xintercept = 120, linetype = \"dashed\") + draws a vertical dashed line where BPVRS = 120.\ngeom_vline(xintercept = 140, linetype = \"dotted\") + draws a vertical dotted line where BPVRS = 140.\nlabs(x = \"BPVS vocabulary score\") + makes the x-axis label something understandable to someone who does not know about the study.\ntheme_bw() changes the theme.\n\n\n\n2.7.7.2.3 Critical evaluation: discovery and communication\nAs we work with visualization, we should aim to develop skills in reading plots, so:\n\nWhat do we see?\n\nWhen we look at Figure 2.11, we can see that the younger and older children in the Ricketts et al. (2021) sample have broadly overlapping distributions of vocabulary scores. However, as we have noticed previously, the peak of the distribution is a bit lower for the younger children compared to the older children. This appears to be the case whether we are looking at the BPVS or at the WASI measures of vocabulary, suggesting that the observation does not depend on the particular vocabulary test. Is this observation unexpected? Probably not, as we should hope to see vocabulary knowledge increase as children get older. Is this observation a problem for our analysis? You need to read the paper to find out what we decided.\n\n\n2.7.7.2.4 Exercise\nIn the demonstration examples, I focused on comparing age groups on vocabulary, what about the other measures?\nI used superimposed density plots: are other plotting styles more effective, for you? Try using boxplots or superimposed or faceted histograms instead.\n\n\n\n\n2.7.8 Summary: Visualizing distributions\nSo far, we have looked at how and why we may examine the distributions of numeric variables. We have used histograms to visualize the distribution of variable values. We have explored the construction of grids of plots to enable the quick examination or concise communication of information about the distributions of multiple variables at the same time. And we have used histograms, boxplots and density plots to examine how the distributions of variables may differ between groups.\nThe comparison of the distributions of variable values in different groups (or, similarly, between different conditions) may be the kind of work we would need to do, in data visualization, as part of an analysis ending in, for example, a t-test comparison of mean values.\nWhile boxplots, density plots and histograms are typically used to examine how the values of a numeric variable vary, scatterplots are typically used when we wish to examine, to make sense of or communicate potential associations or relations between two (or more) numeric variables. We turn to scatterplots, next.\n\n\n2.7.9 Examine the associations between numeric variables\nMany of us start learning about scatterplots in high school math classes. Using the modern tools made available to us through the ggplot2 library (as part of tidyverse), we can produce effective, nice-looking, scatterplots for a range of discovery or communication scenarios.\nWe continue working with the Ricketts et al. (2021) dataset. In the context of the Ricketts et al. (2021) investigation, there is interest in how children vary in the reading, spelling and vocabulary abilities that may influence the capacity of children to learn new words. So, in this context, we can begin to progress our development in visualization skills by usefully considering the potential association between participant attributes in the Study 2 sample.\nLater on, we will look at more advanced plots that help us to communicate the impact of the experimental manipulations implemented by Ricketts et al. (2021), and also to discover the ways that these impacts may vary between children.\n\n2.7.9.1 Getting started: Scatterplot basics\nWe can begin by asking a simple research question we can guess the answer to:\n\nDo vocabulary knowledge scores on two alternative measures, the BPVS and the WASI, relate to each other?\n\nIf two measurement instruments or tests are intended to measure individual differences in the same psychological attribute, here, vocabulary knowledge, then we would reasonably expect that scores on one test should covary with scores on the second test.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\nFigure 2.12: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\nWhat does the plot show us?\nAs a reminder of how scatterplots work, we can recall that they present integrated information. Each point, for the Ricketts et al. (2021) data, represents information about both the BPVS and the WASI score for each child.\n\nThe vertical height of a point tells us the BPVS score recorded for a child: higher points represent higher scores.\nThe left-to-right horizontal position of the same point tells us the WASI score for the same child: points located more on the right represent higher scores.\n\nFigure 2.12 is a scatterplot comparing variation in childrens’ scores on the BPVS and WASI vocabulary measures: variation in BPVS scores are shown on the y-axis and variation in WASI scores are shown on the x-axis. Critically, the scientific insight the plot gives us is this: higher WASI scores are associated with higher BPVS scores.\nHow does the code work? We have seen scatterplots before but, to ensure we are comfortable with the coding, we can go through them step by step.\n\nggplot(data = conc.orth.subjs...) + tells R we want to produce a plot using ggplot() with the conc.orth.subjs dataset.\naes(x = WASIvRS, y = BPVSRS) tells R that, in the plot, WASIvRS values are mapped to x-axis (horizontal) position and BPVSRS values are mapped to y-axis (vertical) position.\ngeom_point() + constructs a scatterplot, using these data and these position mappings.\nlabs(x = \"WASI vocabulary score\", ... fixes the x-axis label.\ny = \"BPVSRS vocabulary score\",... fixes the y-axis label.\ntitle = \"Are WASI and BPVS vocabulary scores associated?\") + fixes the title.\ntheme_bw() changes the theme.\n\n\n\n2.7.9.2 Building complexity: adding information step by step\nFor this pair of variables in this dataset, the potential association in the variation of scores is quite obvious. However, sometimes it is helpful to guide the audience by imposing a smoother. There are different ways to do this, for different objectives and in different contexts. Here, we look at two different approaches. In addition, as we go, we examine how to adjust the appearance of the plot to address different potential discovery or communication needs.\nWe begin by adding what is called a LOESS smoother.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\nFigure 2.13: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\nThe only coding difference between this plot Figure 2.13 and the previous plot Figure 2.12 appears at line 3:\n\ngeom_smooth()\n\nThe addition of this bit of code results in the addition of the curving line you see in Figure 2.13. The blue line is curving, and visually suggests that the relation between BPVS and WASI scores is different – sometimes more sometimes less steep – for different values of WASI vocabulary score.\nThis line is generated by the geom_smooth() code, by default, in an approach in which the dataset is effectively split into sub-sets, dividing the data up into sub-sets from the lowest to the highest WASI scores, and the predicted association between the y-axis variable (here, BPVS score) and the x-axis variable (here, WASI score) is calculated bit by bit, in a series of regression analyses, working in order through sub-sets of the data. This calculation of what is called the LOESS (locally estimated scatterplot smoothing) trend is done by ggplot for us. And this approach to visualizing the trend in a potential association between variables is often a helpful way to discover curved or non-linear relations.\nYou can find technical information on geom_smooth() here and an explanation of LOESS here.\nFor us, this default visualization is not helpful for two reasons:\n\nWe have not yet learned about linear models, so learning about LOESS comes a bit early in our development.\nIt is hard to look at Figure 2.13 and identify a convincing curvilinear relation between the two variables. A lot of the curve for low WASI scores appears to be linked to the presence of a small number of data points.\n\nAt this stage, it is more helpful to adjust the addition of the smoother. We can do that by adding an argument to the geom_smooth() function code.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\nFigure 2.14: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\nNotice the difference between Figure 2.13 and Figure 2.14:\n\ngeom_smooth(method = 'lm') tells R to draw a trend line, a smoother, using the lm method.\n\nThe lm method requires R to estimate the association between the two variables, here, BPVS and WASI, assuming a linear model. Of course, we are going to learn about linear models but, in short, right now, what we need to know is that we assume a “straight line” relationship between the variables. This assumption requires that for any interval of WASI scores – e.g., whether we are talking about WASI scores between 20-25 or about WASI scores between 30-35 – the relation between BPVS and WASI scores has the same shape: the direction and steepness of the slope of the line is the same.\n\n\n2.7.9.3 Exercise\n\nDeveloping skill in working with data visualizations is not just about developing coding skills, it is also about developing skills in reading, and critically evaluating, the information the plots we produce show us.\n\nStop and take a good look at the scatterplot in Figure 2.14. Use the visual representation of data to critically evaluate the potential association between the BPVS and WASI variables. What can you see?\nYou can train your critical evaluation by asking yourself questions like the following:\n\nHow does variation in the x-axis variable relate to variation in values of the y-axis variable?\n\n\nWe can see, here, that higher WASI scores are associated with higher BPVS scores.\n\n\nHow strong is the relation?\n\n\nThe strength of the relation can be indicated by the steepness of the trend indicated by the smoother, here, the blue line.\nIf you track the position of the line, you can see, for example, that going from a WASI score of 20 to a WASI score of 40 is associated with going from a BPVS score of a little over 110 to a BPVS score of about a 150.\nThat seems like a big difference.\n\n\nHow well does the trend we are looking at capture the data in our sample?\n\n\nHere, we are concerned with how close the points are to the trend line.\nIf the trend line represents a set of predictions about how the BPVS scores vary (in height) given variation in WASI scores, we can see that in places the prediction is not very good.\nTake a look at the points located at WASI 25. We can see that there there are points indicating that different children have the same WASI score of 25 but BPVS scores ranging from about 115 to 140.\n\n\n\n2.7.9.4 Polish the appearance of a plot for presentation\nFigure 2.14 presents a satisfactory looking plot but it is worth checking what edits we can make to the appearance of the plot, to indicate some of the ways that you can exercise choice in determining what a plot looks like. This will be helpful to you when you are constructing plots for presentation and report and you want to ensure the plots are as effective as possible.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point(alpha = .5, size = 2) +\n  geom_smooth(method = 'lm', colour = \"red\", size = 1.5) +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  xlim(0, 40) + ylim(0, 160) +\n  theme_bw()\n\n\n\n\nFigure 2.15: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\nIf you inspect the code, you can see that I have made three changes:\n\ngeom_point(alpha = .5, size = 2 changes the size of the points and their transparency (using alpha).\ngeom_smooth(method = 'lm', colour = \"red\", size = 1.5) change the colour of the smoother line, and the thickness (size) of the line.\nxlim(0, 40) + ylim(0, 160) changes the axis limits.\n\nThe last step — changing the axis limits — reveals how the sample data can be understood in the context of possible scores on these ability measures. Children could get BPVS scores of 0 or WASI scores of 0. By showing the start of the axes we get a more realistic sense of how our sample compares to the possible ranges of scores we could see in the wider population of children. This perhaps offers a more honest or realistic visualization of the potential association between BPVS and WASI vocabulary scores.\n\n\n2.7.9.5 Examining associations among multiple variables\nAs we have seen previously, we can construct a series of plots and present them all at once in a grid or lattice. Figure 2.16 presents just such a grid: of scatterplots, indicating a series of potential associations.\nLet’s suppose that we are primarily interested in what factors influence the extent to which children in the Ricketts et al. (2021) word learning experiment are able to correctly spell the target words they were given to learn. As explained earlier, in Section 2.7.2, Ricketts et al. (2021) examined the spellings produced by participant children in response to target words, counting how many string edits (i.e., letter deletions etc.) separated the spelling each child produced from the target spelling they should have produced.\nWe can calculate the mean spelling accuracy score for each child, over all the target words we observed their response to. We can identify mean spelling score as the outcome variable. We can then examine whether the outcome spelling scores are or are not influenced by participant attributes like vocabulary knowledge.\nFigure 2.16 presents a grid of scatterplots indicating the potential association between mean spelling score and each of the variables we have in the conc.orth dataset, including the Castles and Coltheart (CC) and TOWRE measures of word or nonword reading skill, WASI and BPVS measures of vocabulary knowledge, and the WASI matrix measure of intelligence, as well as (our newly coded) age group factor.\nI hide an explanation of the coding behind the Notes tab, because we have seen how to produce grids of plots, but you can take a look if you want to learn how the plot is produced.\n\nPlotNotes\n\n\n\n\n\n\n\nFigure 2.16: Grid of scatterplots showing the potential association between mean spelling score, for each child, and variation in the Castles and Coltheart (CC) and TOWRE measures of word or nonword reading skill, WASI and BPVS measures of vocabulary knowledge, the WASI matrix measure of intelligence, and age group factor\n\n\n\n\n\n\nThe code to produce the figure is set out as follows.\n\np.wordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                              y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Word reading\", \n       y = \"Spelling score\",\n       title = \"(a.)\") +\n  theme_bw()\n\np.nonwordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Nonword reading\", \n       y = \"Spelling score\",\n       title = \"(b.)\") +\n  theme_bw()\n\np.WASIvRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = WASIvRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"WASI vocabulary\", \n       y = \"Spelling score\",\n       title = \"(c.)\") +\n  theme_bw()\n\np.BPVSRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = BPVSRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"BPVS vocabulary score\", \n       y = \"Spelling score\",\n       title = \"(d.)\") +\n  theme_bw()\n\np.WASImRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = WASImRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"WASI matrix\", \n       y = \"Spelling score\",\n       title = \"(e.)\") +\n  theme_bw()\n\np.CC2regRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2regRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC regular words\", \n       y = \"Spelling score\",\n       title = \"(f.)\") +\n  theme_bw()\n\np.CC2irregRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2irregRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC irregular words\", \n       y = \"Spelling score\",\n       title = \"(g.)\") +\n  theme_bw()\n\np.CC2nwRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2nwRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC nonwords\", \n       y = \"Spelling score\",\n       title = \"(h.)\") +\n  theme_bw()\n\np.age.groupvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = age.group, \n                                  y = mean.score)) +\n  geom_boxplot() +\n  labs(x = \"Age group\", \n       y = \"Spelling score\",\n       title = \"(i.)\") +\n  theme_bw()\n\np.wordsvsmean.score + p.nonwordsvsmean.score + p.WASIvRSvsmean.score +\n  p.BPVSRSvsmean.score + p.WASImRSvsmean.score + p.CC2regRSvsmean.score +\n  p.CC2irregRSvsmean.score + p.CC2nwRSvsmean.score + p.age.groupvsmean.score\n\n\nTo produce the grid of plots, we first create a series of plot objects using code like that shown in the chunk.\n\n\np.wordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                              y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Word reading\", \n       y = \"Spelling score\",\n       title = \"(a.)\") +\n  theme_bw()\n\n\np.wordsvsmean.score &lt;- ggplot(...) creates the plot.\ndata = conc.orth.subjs tells R what data to work with.\naes(x = TOWREsweRS, y = mean.score) specifies the aesthetic data mappings.\ngeom_point(alpha = .5, size = 3) tells R to produce a scatterplot, specifying the size and transparency of the points.\ngeom_smooth(method = 'lm', size = 1.5) tells R to add a smoother, specifying the method and the thickness of the line.\nlabs(x = \"Word reading\", y = \"Spelling score\", title = \"(a.)\") fixes the labels.\ntheme_bw() adjusts the theme.\n\n\nWe then put the plots together, using the patchwork syntax where we list the plot objects by name, separating each name by a +.\n\n\np.BPVSRSvsmean.score + p.WASImRSvsmean.score + p.CC2regRSvsmean.score +\n  p.CC2irregRSvsmean.score + p.CC2nwRSvsmean.score + p.age.groupvsmean.score\n\n\n\n\nFigure 2.16 allows us to visually represent the potential association between an outcome measure, the average spelling score, and a series of other variables that may or may not have an influence on that outcome. Using a grid in this fashion allows us to compare the extent to which different variables appear to have an influence on the outcome. We can see, for example, that measures of variation in word reading skill appear to have stronger association (the trend lines are more steeply slowed) than measures of vocabulary knowledge or intelligence, or age group.\nUsing grids of plots like this allow us to compactly communicate these potential associations in a single figure.\n\n\n\n\n\n\nWarning\n\n\n\nLevenshtein distance scores are higher if a child makes more errors in producing the letters in a spelling response.\n\nThis means that if we want to see what factors help a child to learn a word, including its spelling, then we want to see that helpful factors are associated with lower Levenshtein scores.\n\n\n\n\n\n\n2.7.10 Answering a scientific question: Visualize the effects of experimental conditions\nAs explained in Section 2.7.2, in the Ricketts et al. (2021) study, we taught children taught 16 novel words in a study with a 2 x 2 factorial design. The presence of orthography (orthography absent vs. orthography present) was manipulated within participants: for all children, eight of the words were taught with orthography (the word spelling) present and eight with orthography absent. Instructions (incidental vs. explicit) were manipulated between participants such that children in the explicit condition were alerted to the presence of orthography whereas children in the incidental condition were not. The Ricketts et al. (2021) investigation was primarily concerned with the effects on word learning of presenting words for learning with or without showing the words with their spellings, with or without instructing students explicitly that they would be helped by the presence of the spellings.\nWe can analyze the effects of orthography and instruction using a linear model.\n\nmodel &lt;- lm(Levenshtein.Score ~ Instructions*Orthography, data = conc.orth)\n\nThe model code estimates variation in spelling score (values of the Levenshtein.Score) variable, given variation in the levels of the Instructions and Orthography factors, and their interaction.\nThis model is a limited approximation of the analysis we would need to do with these data to estimate the effects of orthography and instruction; see Ricketts et al. (2021) for more information on what analysis is required (in our view). However, it is good enough as a basis for exploring the kind of data visualization work — in terms of both discovery and communication — that you can do when you are working with data from an experimental study.\nWe can get a summary of the model results which presents the estimated effect of each experimental factor. These estimates represent the predicted change in spelling score, given variation in Orthography (present, absent) or Instruction (explicit, incidental), and given the possibility that the effect of the presence of orthography is different for different levels of instruction.\nNotice that some of the p-values are incorrectly shown as 0.000. This is a result of using functions to automatically take a model summary and generate a table. I am going to leave this error with a warning because our focus is on visualization, next.\n\n\n\nModel summary\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.584\n0.072\n21.857\n0.000\n\n\nInstructionsincidental\n-0.041\n0.103\n-0.396\n0.692\n\n\nOrthographypresent\n-0.409\n0.103\n-3.987\n0.000\n\n\nInstructionsincidental:Orthographypresent\n0.060\n0.146\n0.409\n0.683\n\n\n\n\n\n\n\nVery often, when we complete a statistical analysis of outcome data, in which we estimate or test the effects on outcomes of variation in some variables or of variation in experimental conditions, then we present a table summary of the analysis results. However, these estimates are typically difficult to interpret (it gets easier with practice) and talk about. Take a look at the summary table. We are often to focus on whether effects are significant or not significant. But, really, what we should consider is how much the outcome changes given the different experimental conditions.\nHow do we get that information from the analysis results? We can communicate results — to ourselves or to an audience — by constructing plots from the model information. The ggeffects library extends ggplot2 to enable us to do this quite efficiently.\nWhen we write code to fit a linear model like:\n\nmodel &lt;- lm(Levenshtein.Score ~ Instructions*Orthography, data = conc.orth)\n\nWe record the results as an object called model because we specify model &lt;- lm(...). We can take these results and ask R to create a plot showing predicted change in outcome (spelling) given our model. We can then present the effects of the variables, as shown in Figure 2.17.\n\ndat &lt;- ggpredict(model, terms = c(\"Instructions\", \"Orthography\"))\nplot(dat, facet = TRUE) + ylim(0, 3)\n\n\n\n\nFigure 2.17: Dot and whisker plots showing the predicted effect on outcome spelling (Levenshtein) score, given different experimental conditions: Orthography (present, absent) x Instruction (explicit, incidental).\n\n\n\n\nThe code works as follows:\n\ndat &lt;- ggpredict(model, terms = c(\"Instructions\", \"Orthography\")) tells R to calculate predicted outcomes, given our model information, for the factors \"Instructions\", \"Orthography\".\nplot(dat, facet = TRUE) plot the effects, given the predictions, showing the effect of different instruction conditions in different plot facets (the left and right panels).\nylim(0, 3) fix the y-axis to show a more honest indication of the effect on outcomes, given the potential range of spelling scores can start at 0.\n\nIn Figure 2.17, the dots represent the linear model estimates of outcome spelling, predicted under different conditions. The plots indicate that spelling scores are predicted to be lower when orthography is present. There appears to be little or no effect associated with different kinds of instruction.\nThe vertical lines (often termed “whiskers”) indicate the 95% confidence interval about these estimates. Confidence intervals (CIs) are often mis-interpreted so I will give the quick definition outlined by Hoekstra et al. (2014) here:\n\nA CI is a numerical interval constructed around the estimate of a parameter [i.e. the model estimate of the effect]. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95 % of the cases.\n\nIn short, the interval shows us the range of values within which we can expect to capture the effects of interest, in the long run, if we were to run our experiment over and over again.\nGiven our data and our model, these intervals indicate where the outcome might be expected to vary, given different conditions, and that is quite useful information. If you look at Figure 2.17, you can see that the presence of orthography (present versus absent) appears to shift outcome spelling, on average, by about a quarter of a letter edit: from over 1.5 to about 1.25. This is about one quarter of the difference, on average, between getting a target spelling correct and getting it wrong by one letter (e.g., the response ‘epegram’ for the target ‘epigram’). This is a relatively small effect but we may consider how such small effects add up, over a child’s development, cumulatively, in making the difference between wrong or nearly right spellings to correct spellings.\nIn the Ricketts et al. (2021) paper, we conducted Bayesian analyses which allow us to plot the estimated effects of experimental conditions along with what are called credible intervals indicating our uncertainty about the estimates. In a Bayesian analysis, we can indicate the probable or plausible effect of conditions, or range of plausible effects, given our data and our model. (This intuitive sense of the probable location of effects is, sometimes, what researchers and students mis-interpret confidence intervals as showing; Hoekstra et al. (2014).) Accounting for our uncertainty is a productive approach to considering how much we learn from the evidence we collect in experiments.\nBut this gets ahead of where we are now in our development of skills and understanding. There is another way to discover how uncertain we may be about the results of our analysis. This is an approach we have already experienced: plotting trends or estimates together with the observed data points. We present an example in Figure 2.18.\n\nplot(dat, add.data = TRUE)\n\n\n\n\nFigure 2.18: Dot and whisker plots showing the predicted effect on outcome spelling (Levenshtein) score, given different experimental conditions: Orthography (present, absent) x Instruction (explicit, incidental). The estimates are shown as dot-whisker points. In addition, the plot shows as points the spelling score observed for each child for each response recorded in the conc.orth dataset.\n\n\n\n\nFigure 2.18 reveals the usefulness of plotting model estimates of effects alongside the raw observed outcomes. We can make two critical observations.\n\nWe can see that the observed scores clearly cluster around outcome spelling values of 0, 1, 2, 3, 4, and 5.\n\n\nThis is not a surprise because Ricketts et al. (2021) scored each response in their test of spelling knowledge by counting the number of letter edits (letter deletions, additions etc.) separating a spelling response from a target response.\nBut the plot does suggest that the linear model is missing something about the outcome data because there is no recognition in the model or the results of this bunching or clustering around whole number values of the outcome variable. (This is why Ricketts et al. (2021) use a different analysis approach.)\n\n\nWe can also see that it is actually quite difficult to distinguish the effects of the experimental condition differences on the observed spelling responses. There is a lot of variation in the responses.\n\nHow can we make sense of this variation?\nAnother approach we can take to experimental data is to examine visually how the effects of experimental conditions vary between individual participants. Usually, in teaching, learning and doing foundation or introductory statistical analyses we think about the average impact on outcomes of the experimental conditions or some set of predictor variables. It often makes sense, also, or instead, to consider the ways that the impact on outcomes vary between individuals.\nHere, it might be worthwhile to look at the effect of the conditions for each child. We can do that in different ways. In the following, we will look at a couple of approaches that are often useful. We will focus on the effect of variation in the Orthography condition (present, absent)\nTo begin our work, we first calculate the average outcome (Levenshtein.Score) spelling score for each child in each of the experimental conditions (Orthography, present versus absent):\nWe do this in a series of steps.\n\nscore.by.subj &lt;- conc.orth %&gt;%\n  group_by(Participant, Orthography) %&gt;%\n  summarise(mean.score = mean(Levenshtein.Score))\n\n\nscore.by.subj &lt;- conc.orth %&gt;% create a new dataset score.by.subj by taking the original data conc.orth and piping it through a series of processing steps, to follow.\ngroup_by(Participant, Orthography) %&gt;% first group the rows of the original dataset and piped the grouped data to the next bit. We group the data by participant identity code and by Orthography condition\nsummarise(mean.score = mean(Levenshtein.Score)) then calculate the mean Levenshtein.Score for each participant, for their responses in the Orthography present and in the Orthography absent conditions.\n\nThis first step produces a summary version of the original dataset, with two mean outcome spelling scores for each child, for their responses in the Orthography present and in the Orthography absent conditions. This arranges the summary mean scores in rows, with two rows per child: one for the absent, one for the present condition. You can see what we get in the extract from the dataset, shown next.\n\n\n\n\n\nParticipant\nOrthography\nmean.score\n\n\n\n\nEOF001\nabsent\n1.750\n\n\nEOF001\npresent\n0.875\n\n\nEOF002\nabsent\n1.375\n\n\nEOF002\npresent\n2.125\n\n\nEOF004\nabsent\n1.625\n\n\nEOF004\npresent\n1.000\n\n\nEOF006\nabsent\n0.750\n\n\nEOF006\npresent\n0.500\n\n\nEOF007\nabsent\n1.500\n\n\nEOF007\npresent\n0.625\n\n\n\n\n\n\n\nIn the second step, we also calculate the difference between spelling scores in the different Orthography conditions. We do this because Ricketts et al. (2021) were interested in whether spelling responses were different in the different conditions.\n\nscore.by.subj.diff &lt;- score.by.subj %&gt;%\n  pivot_wider(names_from = Orthography, values_from = mean.score) %&gt;%\n  mutate(difference.score = absent - present) %&gt;%\n  pivot_longer(cols = c(absent, present), \n               names_to = 'Orthography',\n               values_to = 'mean.score') \n\n\nscore.by.subj.diff &lt;- score.by.subj %&gt;% creates a new version of the summary dataset from the dataset we just produced.\npivot_wider(names_from = Orthography, values_from = mean.score) %&gt;% re-arranges the dataset so that the absent, present mean scores are side-by-side, in different columns, for each child.\nmutate(difference.score = absent - present) %&gt;% calculates the difference between the absent, present mean scores, creating a new variable, difference.score.\npivot_longer(cols = c(absent, present) ...) re-arranges the data back again so that the dataset is in tidy format, with one column of mean spelling scores, with two rows for each participant for the absent, present mean scores.\n\nThis code arranges the summary mean scores in rows, with two rows per child: one for the absent, one for the present condition — plus a difference score.\n\n\n\n\n\nParticipant\ndifference.score\nOrthography\nmean.score\n\n\n\n\nEOF001\n0.875\nabsent\n1.750\n\n\nEOF001\n0.875\npresent\n0.875\n\n\nEOF002\n-0.750\nabsent\n1.375\n\n\nEOF002\n-0.750\npresent\n2.125\n\n\nEOF004\n0.625\nabsent\n1.625\n\n\nEOF004\n0.625\npresent\n1.000\n\n\nEOF006\n0.250\nabsent\n0.750\n\n\nEOF006\n0.250\npresent\n0.500\n\n\nEOF007\n0.875\nabsent\n1.500\n\n\nEOF007\n0.875\npresent\n0.625\n\n\n\n\n\n\n\nNow we can use these data to consider how the impact of the experimental condition (Orthography: present versus absent) varies between individual participants. We do this by showing the mean outcome spelling score, separately for each participant, in each condition.\nFigure 2.19 shows dot plots indicating the different outcome spelling (Levenshtein) scores, for each participant, in the different experimental conditions: Orthography (present, absent). Plots are ordered, from top left to bottom right, by the difference between mean spelling scores in the absent versus present conditions. The plots indicate that some children show higher spelling scores in the present than in the absent condition (top left plots), some children show little difference between conditions (middle rows), while some children show higher spelling scores in the absent than in the present condition (bottom rows).\n\nggplot(data = score.by.subj.diff, \n       aes(x = Orthography, y = mean.score,\n           colour = Orthography)) +\n  geom_point() +\n  facet_wrap(~ reorder(Participant, difference.score)) +\n  theme(axis.text.x = element_blank())\n\n\n\n\nFigure 2.19: Dot plots showing the different outcome spelling (Levenshtein) scores, for each participant, in the different experimental conditions: Orthography (present, absent). Plots are ordered, from top left to bottom right, by the difference between mean spelling scores in the absent versus present conditions.\n\n\n\n\nOnce we have done the data processing in preparation, the code to produce the plot is fairly compact.\n\nggplot(data = score.by.subj.diff ... tells R to produce a plot, using ggplot() and the newly created score.by.subj.diff dataset.\naes(x = Orthography, y = mean.score,... specifies the aesthetic mappings: we tell R to locate mean.score on the y-axis and Orthography condition on the x-axis/\naes(...colour = Orthography)) + specifies a further aesthetic mapping: we tell R to map different Orthography conditions to different colours.\ngeom_point() + tells R to take the data and produce a scatterplot, given our mapping specifications.\nfacet_wrap(...) + tells to split the dataset into sub-sets (facets).\nfacet_wrap(~ reorder(Participant, difference.score)) tells R that we want the sub-sets to be organized by Participant, and we want the facets to be ordered by the difference.score calculated for each participant.\ntheme(axis.text.x = element_blank()) removes the x-axis labels because it is too crowded with the axis labels left in, and the information is already present in the colour guide legend shown on the right of the plot.\n\n\n\n2.7.11 Summary: Visualizing associations\nVisualizing associations between variables encompasses a wide range of the things we have to do, in terms of both discovery and communication, when we work with data from psychological experiments.\nThe conventional method to visualize how the distribution of values in one variable covaries with the distribution of values in another variable is through using a scatterplot. However, the construction of a scatterplot can be elaborated in various ways to enrich the information we present or communicate to our audiences, or to ourselves.\n\nWe can add elements like smoothers to indicate trends.\nWe can add annotation, as with the histograms, to highlight specific thresholds.\nWe can facet the plots to indicate how trends may vary between sub-sets of the data.\n\nIn the final phases of our practical work, we started by presenting model-based predictions of the effects of experimental manipulations. However, you will have noticed that presenting plots of effects is not where we stop when we engage with a dataset. Further plotting indicates quite marked variation between participants in the effects of the conditions. This kind of insight is something we can and should seek to reveal through our visualization work."
  },
  {
    "objectID": "visualization.html#next-steps-for-development",
    "href": "visualization.html#next-steps-for-development",
    "title": "2  Data visualization",
    "section": "2.8 Next steps for development",
    "text": "2.8 Next steps for development\nTo take your development further, take a look at the resources listed in Section 2.9.\nIn my experience, the most productive way to learn about visualization and about coding the production of plots, is by doing. And this work is most interesting if you have a dataset you care about: for your research report, or for your dissertation study.\nAs you have the alternate datasets described in Section 2.7.1.2.1, you can start with the data from the other task or the other study in Ricketts et al. (2021). Ricketts et al. (2021) recorded children’s responses in two different outcome tasks, the orthographic spelling task we have looked at, and a semantic or meaning-based task. It would be a fairly short step to adapt the code you see in the example code chunks to work with the semantic datasets.\nAlternatively, you can look at the data reported by Rodríguez-Ferreiro et al. (2020). Rodríguez-Ferreiro et al. (2020) present both measures of individual differences (on schizotypyal traits) and experimental manipulations (of semantic priming) so you can do similar things with those data as we have explored here."
  },
  {
    "objectID": "visualization.html#sec-resources",
    "href": "visualization.html#sec-resources",
    "title": "2  Data visualization",
    "section": "2.9 Helpful resources",
    "text": "2.9 Helpful resources\n\n2.9.1 Some helpful websites\n\nWe typically use the ggplot library (part of the tidyverse) to produce plots. Clear technical information, with useful examples you can copy and run, can be found in the reference webpages:\n\nhttps://ggplot2.tidyverse.org/reference/index.html\n\nA source of inspiration can be found here:\n\nhttps://r-graph-gallery.com\nIf you are trying to work out how to do things by searching for information online, you often find yourself at tutorial webpages. You will develop a sense of quality and usefulness with experience. Most often, what you are looking for is a tutorial that provides some explanation, and example code you can adapt for your own purposes. Here are some examples.\n\nCedric Scherer on producing raincloud plots:\n\nhttps://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-and-how-to-create-them-with-ggplot2/\n\nWinston Chang on colours and colour blind palettes:\n\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nThomas Lin Pedersen (and others) on putting together plots into a single presentation using the patchwork library functions:\n\nhttps://patchwork.data-imaginist.com/articles/patchwork.html\n\n\n2.9.2 Some helpful books\n\nThe book “R for Data Science” (Wickham & Grolemund, 2016) will guide you through the data analysis workflow, including data visualization, and the latest version can be accessed in an online free version here:\n\nhttps://r4ds.hadley.nz\n\nThe “ggplot2: Elegant Graphics for Data Analysis” book (Wickham, 2016) corresponding to the ggplot library was written by Hadley Wickham in its first edition, it is now in its third edition (as a work in progress, co-authored by Wickham, Danielle Navarro and Thomas Lin Pedersen) and this latest version can be accessed in an online free version here:\n\nhttps://ggplot2-book.org/index.html\n\nThe “R graphics cookbook” (Chang, 2013), and the latest version can be accessed in an online free version here:\n\nhttps://r-graphics.org\n\nThe book “Fundamentals of Data Visualization” (Wilke, n.d.) is about different aspects of visualization, and can be accessed in an online free version here:\n\nhttps://clauswilke.com/dataviz/\n\n\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBelenky, G., Wesensten, N. J., Thorne, D. R., Thomas, M. L., Sing, H. C., Redmond, D. P., Russo, M. B., & Balkin, T. J. (2003). Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research, 12(1), 1–12. https://doi.org/10.1046/j.1365-2869.2003.00337.x\n\n\nChang, W. (2013). R graphics cookbook. o’Reilly Media.\n\n\nFranconeri, S. L., Padilla, L. M., Shah, P., Zacks, J. M., & Hullman, J. (2021). The Science of Visual Data Communication: What Works. Psychological Science in the Public Interest, 22(3), 110–161. https://doi.org/10.1177/15291006211051956\n\n\nGelman, A., & Unwin, A. (2013). Infovis and Statistical Graphics: Different Goals, Different Looks. Journal of Computational and Graphical Statistics, 22(1), 2–28. https://doi.org/10.1080/10618600.2012.761137\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164. https://doi.org/10.3758/s13423-013-0572-3\n\n\nPinheiro, J. C., & Bates, D. M. (2000). Mixed-effects models in s and s-plus (statistics and computing). Springer.\n\n\nRicketts, J., Dawson, N., & Davies, R. (2021). The hidden depths of new word knowledge: Using graded measures of orthographic and semantic learning to measure vocabulary acquisition. Learning and Instruction, 74, 101468. https://doi.org/10.1016/j.learninstruc.2021.101468\n\n\nRodríguez-Ferreiro, J., Aguilera, M., & Davies, R. (2020). Semantic priming and schizotypal personality: reassessing the link between thought disorder and enhanced spreading of semantic activation. PeerJ, 8, e9511. https://doi.org/10.7717/peerj.9511\n\n\nVasishth, S., & Gelman, A. (2021). How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis. Linguistics, 59(5), 1311–1342. https://doi.org/10.1515/ling-2019-0051\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2017). Tidyverse: Easily install and load the ’tidyverse’. https://cran.r-project.org/package=tidyverse\n\n\nWickham, H., & Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (n.d.). Fundamentals of data visualization. https://clauswilke.com/dataviz/\n\n\nWilkinson, L. (2013). The Grammar of Graphics. Springer Science & Business Media."
  },
  {
    "objectID": "visualization.html#footnotes",
    "href": "visualization.html#footnotes",
    "title": "2  Data visualization",
    "section": "",
    "text": "As you can see if you read the Ricketts et al. (2021) paper, and the associated guide to the data and analysis on the OSF repository, we analysed the word learning data using Generalized Linear Mixed-effects Models (GLMM). GLMMs are used when we are analyzing data with a multilevel structure. These structures are very common and can be identified whenever we have groups or clusters observations: here, we have multiple observations of the test response, for each participant and for each stimulus word. When we fit GLMMs, the functions we use to do the analysis require the data to be structured in this tidy fashion, with different rows for each response or outcome observation, and repeated information for each participant or stimulus (if present).↩︎"
  },
  {
    "objectID": "report-preface.html",
    "href": "report-preface.html",
    "title": "2  The research report assignment: Outline introduction",
    "section": "",
    "text": "Warning\n\n\n\nUnder construction"
  },
  {
    "objectID": "intro.html#sec-why-key-ideas",
    "href": "intro.html#sec-why-key-ideas",
    "title": "4  Reasons why we do the research report assignment: What you will learn",
    "section": "4.1 The key ideas",
    "text": "4.1 The key ideas\nThere are two ideas motivating our approach. It will be helpful to you if I sketch them out early, here. We can demonstrate the usefulness of these ideas as we progress through our work.\nThe first key idea is expressed clearly in sociological discussions of science. This is that there is a difference between science “…being done, science in the making, and science already done, a finished product …” [Bourdieu (2004); p.2]. The awareness we want to develop is that there are two things: there is the story that may be presented in a textbook or in a lecture about scientific work or scientific claims; and there is the work we do in practice, as we develop graduate skills, and as we exercise those skills professionally in the workplace.\nThe second key idea connects to the first. This idea is that reported analyses are not necessary or sufficient to the data or the question. What does this mean? It means that the same data can reasonably be analysed in different ways. There is no necessary way to analyse some data though there may be conventions or normal practices (Kuhn, 1970). It means that it is unlikely that any one analysis will do all the work that could be done (a sufficiency) to get you from your data to useful or reasonable answers to your questions.\nThese ideas may be unsettling but they are realistic. Stating them will better prepare you for professional work. In the workplace, the accuracy of these ideas will emerge when you see how a team in any sector (health, marketing …) gets from its data to its product. If we talk about the ideas now, we can get you ready for dealing with the practical and the ethical concerns you will confront when that happens.\nWe will begin by discussing psychological research, and research about psychological research, to answer the question: Why: what is the motivation for the assignment? We will then move to answering the What question Chapter 4 and the How question Chapter 5."
  },
  {
    "objectID": "intro.html#sec-motivation-for-assignment",
    "href": "intro.html#sec-motivation-for-assignment",
    "title": "4  Reasons why we do the research report assignment: What you will learn",
    "section": "4.2 Why: what is the motivation for the assignment?",
    "text": "4.2 Why: what is the motivation for the assignment?\n\n4.2.1 The wider context: crisis and revolution\nWe are here because we are interested in humans and human behaviour, and because we are interested in scientific methods of making sense of these things. Some of us are aware that science (including psychological science) has undergone a rolling series of crises: the replicability or replication crisis (Pashler & Harris, 2012; Pashler & Wagenmakers, 2012); the statistical crisis (A. Gelman & Loken, 2014b); and the generalizability crisis (Yarkoni, 2022). And that science is undergoing a response to these crises, evidenced in the advocacy of pre-registration (Nosek et al., 2018, 2019), and of registered reports (Nosek & Lakens, 2014), the use of open science badges (e.g., for the journal Psychological Science), the completion of large-scale replication studies (Aarts et al., 2015), and the identification of open science principles (Munafò et al., 2017). We may usefully refer, collectively, to the crises and the responses, as the credibility revolution (Vazire, 2018)\nWe could teach a course on this (in Lancaster, we do) but, here, I invite you to follow the references if you are interested. Before going on, I want to call your attention to the fact that important elements of the hard work in trying to make science work better has been led by PhD students and by junior researchers (e.g., Herndon et al., 2014). Graduate students may, at first, assume that the fact that a research article has been published in a journal means the findings that are reported must be true. Most of the time, some educated skepticism is more appropriate. An important driver of the realization that there are problems evident in the literature, and that there are changes we can make to improve practice, comes from independent post-publication review work exposing the problems in published work (see, e.g., this account by Andrew Gelman)\n\n\n\n\n\n\nTip\n\n\n\n\nAllow yourself to feel skeptical about the reports you read then work with the motivation this feeling provides.\n\n\n\nIn brief, then, most practicing scientists now understand or should understand that many of the claims we encounter in the published scientific literature are unlikely to be supported by the evidence (Ioannidis, 2005), whether we are looking at the evidence of the results in the reports themselves, or evidence in later attempts to find the same results (e.g., Aarts et al., 2015). We suspect that this may result from a number of causes. We understand that researchers may engage in questionable research practices (John et al., 2012). We understand that researchers may exploit the potential for flexibility in doing and reporting analyses (Simmons et al., 2011a). We understand that there are problems in how psychologists use or talk about the measurement of psychological constructs (Flake & Fried, 2020). We understand that there are problems in how psychologists sample people for their studies, both in where we recruit (Bornstein et al., 2013; Henrich et al., 2010; Wild et al., 2022), and in how many we recruit (Button et al., 2013; Cohen, 1962; Sedlmeier & Gigerenzer, 1989; Vankov et al., 2014). We understand that there are problems in how psychologists specify or think about their hypotheses or predictions (Meehl, 1967; Scheel, 2022). And we understand that there are problems in how scientists do, or rather do not, comply with good practice recommendations designed to fix these problems (discussed further in the following).\nThis discussion could (again) be unsettling. This list of problems could make you angry or sad. I, like others, think it is exciting. It is exciting because these problems have probably existed for a long time (e.g., Cohen, 1962; Meehl, 1967) but now, having identified the problems, we can hope to do something about it. It is exciting because if you care about people, the study of people, or the applications in clinical, education and other domains of the results of the study of people, then you might hope to see better, more useful, science in the future (Vazire, 2018).\nAs someone who teaches graduate and undergraduate students, I want to help you to be the change you want to see in the world 1. We cannot solve every problem but we can try to do better those things that are within our reach. I am going to end this introduction with a brief discussion of some ideas we can use to guide our better practices.\n\n\n4.2.2 The specific context: what we need to look at, conceptually and practically\nIn this course, for this assignment, we are going to focus on:\n\nmultiverse analyses\nkinds of reproducibility\nthe current state of the match between open science ideas and practices\n\nIn the classes on the linear model, we will discuss:\n\nthe links between theory, prediction and analysis\npsychological measurement\nsamples\nvariation in results\n\n\n\n4.2.3 Multiverse analyses: multi- what?\n\n4.2.3.1 A first useful metaphor: the pipeline\nI am going to link this discussion to a metaphor (see Figure Figure 4.1) or a description you will find useful: the data analysis pipeline or workflow.\n\n\n\n\n\n\n\n\nQ\n\n \n\ncluster_R\n\n   \n\nnd_1\n\n Get raw data   \n\nnd_2\n\n Tidy data   \n\nnd_1-&gt;nd_2\n\n    \n\nnd_3_l\n\n Visualize   \n\nnd_2-&gt;nd_3_l\n\n    \n\nnd_3\n\n analyse   \n\nnd_2-&gt;nd_3\n\n    \n\nnd_3_r\n\n Explore   \n\nnd_2-&gt;nd_3_r\n\n    \n\nnd_3_a\n\n Assumptions   \n\nnd_3_a-&gt;nd_3_l\n\n    \n\nnd_3_a-&gt;nd_3\n\n    \n\nnd_3_a-&gt;nd_3_r\n\n    \n\nnd_3_l-&gt;nd_3\n\n   \n\nnd_4\n\n Present   \n\nnd_3_l-&gt;nd_4\n\n    \n\nnd_3-&gt;nd_4\n\n   \n\n\nFigure 4.1: The data analysis pipeline or workflow\n\n\n\n\nThis metaphor or way of thinking is very common (take a look at the diagram in Wickham and Grolemund’s 2017 book “R for Data Science) and you may see the words “data pipeline” used in job descriptions, or you may benefit from saying, in a job application, something like: I am skilled in designing and implementing each stage of the quantitative data analysis pipeline, from data tidying to results presentation. I say this because scientists I have mentored got their jobs because they can do these things – and successfully explained that they can do these things – in sectors like educational testing, behavioural analysis, or public policy research.\nThe reason this metaphor is useful is that it helps us to organize our thinking, and to manage what we do when we do data analysis, we:\n\nget some data;\nprocess or tidy the data;\nexplore, visualize, and analyse the data;\npresent or report our findings.\n\nWe introduce the idea that your analysis work will flow through the stages of a pipeline from getting the data to presenting your findings because, next, we will examine how pipelines can multiply.\n\n\n\n\n\n\nTip\n\n\n\n\nAs you practice your data analysis work, try to identify the elements and the order of your work, as the parts of a workflow.\n\n\n\n\n\n4.2.3.2 A second useful metaphor: the garden of forking paths\nWhat researchers have come to realize: because we started looking … The open secret that has been well kept (Bourdieu, 2004): because everybody who does science knows about it, yet we may not teach it; and because we do not write textbooks revealing it … Is that at each stage in the analysis workflow, we can and do make choices where multiple alternative choices are possible. A. Gelman & Loken (2014a) capture this insight as the “garden of forking paths”2 (see Figure 4.2).\nThe general idea is that it is possible to have multiple potential different paths from the data to the results. The results will vary, depending on the path we take. In an analysis, we could take multiple different paths simply because at point A we decide to do B1, B2 or B3, maybe we choose B1, and then at point B1, we may decide to do C1, C2 or C3. Here, maybe we have our raw data at point A. Maybe we could do one of two different things when we tidy the data: action B1 or B2. Then, when we have our tidy data, maybe we can choose to do our analysis in one of six ways. Where we are at each step depends on the choices we made at the previous steps.\n\n\n\n\n\n\n\n\nD\n\n  \n\nA\n\n A   \n\nB1\n\n B1   \n\nA-&gt;B1\n\n    \n\nB2\n\n B2   \n\nA-&gt;B2\n\n    \n\nC1\n\n C1   \n\nB1-&gt;C1\n\n    \n\nC2\n\n C2   \n\nB1-&gt;C2\n\n    \n\nC3\n\n C3   \n\nB1-&gt;C3\n\n    \n\nC4\n\n C4   \n\nB2-&gt;C4\n\n    \n\nC5\n\n C5   \n\nB2-&gt;C5\n\n    \n\nC6\n\n C6   \n\nB2-&gt;C6\n\n   \n\n\nFigure 4.2: Forking paths in data analysis\n\n\n\n\nIn the end, it may appear to us that we took one path or that only one path was possible. When we report our analysis, in a dissertation or in a published journal article, we may report the analysis as if only one analysis path had been considered. But, critically, our findings may depend on the choices we made and this variation in results may be hidden from view.\nI am talking about forking paths because the multiplicity of paths has consequences, and we discuss these next.\n\n\n\n\n\n\nTip\n\n\n\n\nIt is about here, I hope, that you can start to see why it would makes sense to access data from a published study and to examine if you can get the same results as the study authors.\n\n\n\n\n\n\n4.2.4 Multiverse analyses\nI am going to discuss, now, what are commonly called multiverse analyses. Psychologists use this term, having been introduced to it in an influential paper by Steegen et al. (2016a), but it comes from theoretical physics (take a look at wikipedia).\nI explain this because I do not want you to worry. The ideas themselves are within your grasp whatever your background in psychology or elsewhere. It is the implications for our data analysis practices that are challenging. They are challenging because what we discuss should increase your skepticism about the results you encounter in published papers. And they are challenging because they reveal your freedom to question whether published authors could have done their analysis in a different way.\nWe are going to look at:\n\ndata-set construction\nanalysis choices\n\n\n4.2.4.1 The link between the credibility revolution and the multiverse\nIn first discussing the wider context (of crisis and revolution), then discussing the specific context (of multiverses and, in the following, of reproducibility), I should be clear about the link between the two things. The finding that some results may not be supported by the evidence is probably due to a mix of causes. But one of those causes will be the combination of uncertainty over data processing or the uncertainty over analysis methods revealed in multiverse analyses, as we see next, combined with the limitations of data and code sharing, and the incompleteness of results reporting (as we see later).\n\n\n4.2.4.2 The data multiverse\nWhen you collect or access data for a research study, the complete raw data-set you receive is almost never the complete data-set you analyse or whose analysis you report. This is not a story about deliberately cheating. It is a story about the normal practice of science (Kuhn, 1970).\nPicture some common scenarios. You did a survey, you got responses from a 100 participants on 10 questions, and you asked people to report their education, ethnicity and gender. You did an experimental study, you tested two groups of 50 people each in 100 trials (imagine a common task like the Stroop test), and you observed the accuracy and the timing of their responses. You tested 100 children, 20 children in each of five different schools, on a range of educational ability measures.\nIn these scenarios, the psychologist or the analyst of behavioural data must process their data. In doing so, you will ask yourself a series of questions like:\n\nhow do we code for gender, ethnicity, education?\nwhat do we about reaction times that are very short, e.g., \\(RT &lt; 200ms\\) or very long, e.g., \\(RT &gt; 1500ms\\))?\nif we present multiple questions measuring broadly the same thing (e.g. how confident are you that you understand what you have read? how easy did you find what you read?) how do we summarize the scores on those questions? do we combine scores?\nwhat do we do about people who may not appear to have understood the task instructions?\n\nTypically, the answers to these questions will be given to you by your supervisor, a colleague or a textbook example. For example, we might say:\n\n“We excluded all reaction times greater than 1500ms before analysis.”\n\nTypically, the explanation for these answers are rarely explained. We might say:\n\n“Consistent with common practice in this field, we excluded all reaction times greater than 1500ms before analysis.”\n\nBut the reader of a journal article typically will not see an explanation for why, as in the example, we exclude reaction times greater than 1500ms and not 2000ms or 3000ms, etc. We typically do not see an explanation for why we exclude all reaction times greater than 1500ms but other researchers exclude all reaction times greater than 2000ms. (I do not pick this example at random: there are serious concerns about the impact on analyses of exclusions like this (Ulrich & Miller, 1994).)\nWhat Steegen et al. (2016a) showed is that a data-set can be processed for analysis in multiple different ways, with a number of reasonable alternate choices that can be applied, for each choice point: construction choices about classifying people or about excluding participants given their responses. If a different data-set is constructed for each combination of alternatives then many different data-sets can be produced, all starting from the same raw data. (For their example study, Steegen et al. (2016a) found they could construct 120 or 210 different data-sets, based on the choice combinations.) Critically, for us, Steegen et al. (2016a) showed that if we apply the same analysis method to the different data-sets then our results will vary.\nLet me spell this out, bit by bit:\n\nwe approach our study with the same research question, and the same verbal prediction;\nwe begin with the exact same data;\nwe then construct different data-sets depending on different but equally reasonable processing choices;\nwe then apply the same analysis analysis, to test the same prediction, using each different data-set;\nwe will see different results for the analyses of the different data-sets.\n\nAlternate constructions of the same data may cause variation in the results of statistical tests. Some kinds of data processing choices may be more influential on results than others. It seems unlikely that we can identify, in advance, which choices matter more.\nSteegen et al. (2016a) suggest that we can deflate (shrink) the multiverse in different ways. I want to state their suggestions, here, because we will come back to these ideas in the classes on the linear model.\n\nDevelop better theories and improved measurement of the constructs of interest.\nDevelop more complete and precise theory for why some processing options are better than others.\n\nBut you will be asking yourself: What do I need to think about, for the research report assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you read a psychological research report, identify where the researchers talk about how they process their data: classification, coding, exclusion, transformation, etc.\nIf you can access the raw data, ask yourself: could different choices change the results of the same analysis?\n\n\n\n\n\n4.2.4.3 Analysis multiverses\nEven if we begin with the same research question and, critically, the same data-set, the results of a series of studies show that different researchers will often (reasonably) make different choices about the analysis they do to answer the research question. We often call these studies (analysis or model) multiverse studies. In these studies, we see variation in analysis and this variation is also associated with variation in results.\nAn influential example, in psychology, is reported by Silberzahn and colleagues (Silberzahn et al., 2017; Silberzahn & Uhlmann, 2015) who asked 29 teams of researchers to answer the same question (“Are (soccer) referees more likely to give red cards to players with dark skin than to players with light skin?”) with the same data-set (data about referee decisions in football league games). The teams made their own decisions about how to answer the question in doing the analysis. The teams shared their plans, and commented on each others’ ideas. The discussion did not lead to a consensus about what analysis approach is best. In the end, the different teams did different analyses and, critically, the different analyses had different results. The results varied in whether the test of the effect of players skin colour (on whether red cards were given) was significant or not, and on the strength of the estimated association between the darkness of skin colour (lighter to darker) and the chances (low to high) of getting a red card.\nThere have now been a series of multiverse or multi-analyst studies which demonstrate that, under certain conditions, different researchers may adopt different analysis approaches – which will have different results – in answering the same research question with the same data. This demonstration has been repeated in studies in health, medicine, psychology, neuoscience, and sociology, among other research fields (e.g., Parsons (n.d.); Breznau et al. (2022); Klau et al. (n.d.); Klau et al. (2021); Wessel et al. (2020); Poline et al. (2006); Maier-Hein et al. (2017); Starns et al. (2019); Fillard et al. (2011); Dutilh et al. (2019); Salganik et al. (2020); Bastiaansen et al. (2020); Botvinik-Nezer et al. (2020); Schweinsberg et al. (2021); Patel et al. (2015); see, for reviews, and some helpful guidance, Aczel et al. (2021); Del Giudice & Gangestad (2021); Hoffmann et al. (n.d.); Wagenmakers et al. (2022)).\nIn these studies, we typically see variation in how psychological constructs are operationalized (e.g., how do we measure or code for social status?), how data are processed or data-sets constructed (as in Steegen et al. (2016b)), plus variation in what statistical techniques are used, and in how those techniques are used. This variation can be understood to reflect kinds of uncertainty (Klau et al., n.d.; Klau et al., 2021): uncertainty about how to process data, and uncertainty about the model or methods we should use to test or estimate effects. Further research makes it clear that we should be aware, if we are not already, of the variation in results that can be expected because different researchers may choose to design studies, and construct stimulus materials, in different ways given the same research hypothesis information (Landy et al., 2020).\nBut you will be asking yourself: What do I need to think about, for the research report assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you read a psychological research report, identify where the researchers talk about how they analyse their data: the hypothesis or prediction they test; the method; their assumptions; the variables they include; the checks or the alternate analyses they did or did not do.\nIf you can access the data and analysis code, ask yourself: could different methods change the results of the same analysis?\n\n\n\n\n\n4.2.4.4 What can we conclude – the story so far?\nThis is a good place to look at what we have discussed, and present an evaluation of the story so far.\nThis is not a story where everybody or nobody is right or where everything or nothing is true 3. Instead, we can be guided by the advice (Meehl, 1967; Scheel, 2022; Steegen et al., 2016a) that we should:\n\nseek better and more complete theorizing about the constructs of interest and how we measure them, and\nseek more complete and more precise theory so that some options are theoretically superior than others, and should be preferred, when constructing data-sets or specifying analysis methods.\n\nNot all research questions and not all hypothesis information will allow an equally wide variety of potential reasonable approaches to the analysis. As Paul Meehl argued a long time ago (Meehl, 1967, 1978), and researchers like Anne Scheel (Scheel et al., 2021; Scheel, 2022) argued more recently, the complexity of the thing we study – people, and what they do – and the still early development of our understanding of this thing, mean that what we want but what we do not see, in psychology, are scientifically productive tests of falsifiable theories. (See, consistent with this perspective, discussions by Auspurg & Brüderl (2021) and by Del Giudice & Gangestad (2021) about the range of analysis possibilities that may or may not be allowed, in multiverse analyses, by more or less clear research questions or well-developed causal theories.) Our concern should not so much be with being able to do statistical analysis, or with finding significant or not significant results. It would be more useful to do analyses to test concrete, inflexible, precise predictions that can be wrong.\nNor is this a story, I think, about the potential for cheating. While we may refer to subjective choices or to researcher flexibility, the differences that we see do not resemble the researcher degrees of freedom (Simmons et al., 2011b) some may exploit, consciously or unconsciously, to change results to suit their aims. Instead, the multiverse results show us the impact of the reasonable differences in approach that different researchers may sensibly choose to take when they try to answer a research question with data.\nNot all alternates, at a given point of choosing, in the data analysis workflow, will have equal impact. Work by Young (Young, 2018; Young & Holsteen, 2017) indicates that if we deliberately examine the impact of method or model uncertainty, over different sets of possible choices — about what variables or what observations we include in an analysis, for example — we may find that some results are robust to an array of different options, while other results are highly susceptible to different choices. This work suggests another way in which uncertainty about methods or variation in results can be turned into progress in understanding the phenomena that interest us: through systematic, informed, interrogation of the ways that results can vary.\nIn general, in science, the acceptance of research findings must always be negotiated (Bourdieu, 2004). Here, we see that the grounds of negotiation should often include an analysis of the impact on the value of evidence of the different analysis approaches that researchers can or do apply to the data that underlie that evidence.\nBut you will be asking yourself: what do I need to think about, for the assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nThe results of multiverse analyses show us that if we see one analysis reported in a paper, or one workflow, that does not mean that only one analysis can reasonably be applied.\nIf you read the methods or results section of a paper, you should reflect: what other analysis methods could be used here? How could variation in analysis method — in what or how you do the analysis — influence the results?\n\n\n\nMaking you aware of the potential for analysis choices is useful because developing researchers, including graduate students, are often not aware of the room for choice in the data analysis workflow. Developing researchers — you — may be instructed that “this is how we do things” or “you should follow what researchers did previously”. Following convention is not necessarily a bad thing: it is a feature of the normal practice of science (Kuhn, 1970). However, you can now see, perhaps, that there likely will be alternative ways to process or to analyse data than the approach a supervisor, lab or field normally adopts.\nThis understanding or awareness has three implications for practice, it means:\n\nWhen we talk about the analysis we do, we should explain our choices.\nWe should check, or enable others to check, what impact making different choices would have on our results.\nMost importantly: we can allow ourselves the freedom to critically evaluate the choices researchers make, even the choices researchers make in published articles.\n\n\n\n\n4.2.5 From the multiverse to kinds of reproducibility\nMultiverse analyses and post-publication analyses, in general, show that we can and should question or critically evaluate the analyses we encounter in the literature. This work can usefully detect problems in original published analyses (e.g., A. Gelman & Weakliem, 2009; Herndon et al., 2014; Wagenmakers et al., 2011). It can demonstrate where original published claims are or are not robust to variation of analysis method or approach.\nGiven these lessons, and the implications we have identified, we should expect or hope to see open science practices (Munafò et al., 2017; Nosek et al., 2022):\n\nshare data and code;\npublish research reports in ways that enable others to check or query analyses.\n\nAs we discuss, following, these practices are now common but the quality of practice can sometimes be questioned. This matters for you because it makes it more challenging – in specific identifiable locations – to locate, access, analyse and report previously collected data.\nThe discussion of current practices identifies where or how the assignment may be more challenging, but also identifies some of the exact places where the assignment provides a real opportunity to do original research work.\nFirst, I am going to introduce some ideas that will help you to think about what you are doing when you do this work. We focus on the concept of reproducibility.\nGilmore et al. (2017; following Goodman et al., 2016) present three kinds of reproducibility:\n\nmethods reproducibility\nresults reproducibility\ninferential reproducibility\n\nIn looking at reproducibility, here, we are considering how much, or in what ways, the results or the claims that are made in a published study can be found or repeated by someone else.\n\n4.2.5.1 Methods reproducibility\nAs Gilmore et al. (2017) discuss, methods reproducibility means that another researcher should be able to get the same results if they use the same tools and analysis methods to analyse the same data-set [some researchers also refer to analytic reproducibility or computational reproducibility; see e.g. Crüwell et al. (n.d.); Hardwicke et al. (2018); Hardwicke et al. (n.d.); Laurinavichyute et al. (2022); Minocher et al. (n.d.)].\nIn neuroimaging, the multiplicity of possible implementations of the data analysis pipeline (Carp, 2012a), and the fact that important elements or information about the pipeline deployed by researchers may be missing from published reports (Carp, 2012b), can make it challenging to identify how results can be reproduced.\nIn psychological science, in evaluating reports of results from analyses of behavioural data collected through survey or experimental work, in principle, we should expect to be able to access the data collected by the study authors, follow the description of their analysis method, and reproduce the results they report.\n\n\n\n\n\n\nTip\n\n\n\n\nFor an assignment in which we ask students to locate, access, analyse and report previously collected data, we are directly concerned with methods reproducibility.\n\n\n\n\n\n4.2.5.2 Results reproducibility\nResults reproducibility means that if another researcher completes a new study with new data they are able to get the same results as the results reported following an original study: this often referred to as replication. The replication studies that have been reported (e.g., Aarts et al., 2015), and continue to be reported (see, for example, the studies discussed by Nosek et al. (2022)), in the last several years, present attempts to examine the results reproducibility of published findings.\nIn the classes on the linear model, we will examine if similar or different results are observed in a series of studies using the same procedure and the same materials. We shall discuss, in those classes, in more depth, what results reproducibility (or study replication) can or cannot tell us about the behaviours that interest us.\n\n\n4.2.5.3 Inferential reproducibility\nInferential reproducibility means that if a researcher repeats a study (aiming for results reproducibility) or re-analyses an original data-set (aiming for methods reproducibility) then they can come to the same or similar conclusions as the authors of the report of an original study.\nHow is inferential reproducibility not methods or results reproducibility? Goodman et al. (2016) explain that researchers can make the same conclusions from different sets of results and can reach different conclusions from the same set of results.\nHow is it possible to reach different conclusions from the same results? We can imagine two scenarios.\nFirst, we have to think about the wider research field, the research context, within which we consider a set of results. It may be that two different researchers will come to look at the same results with different expectations about what the results could tell us (in Bayesian terms, with different prior expectations). Given different expectations, it is easy to imagine different researchers looking at the same results and, for example, one researcher being more skeptical than another about what conclusion can be taken from those results. (In the class on graduate writing skills, I discuss in some depth the importance of reviewing a research literature in order to get an understanding of the assumptions, conventions or expectations that may be shared by the researchers working in the field.)\nSecond, imagine two different researchers looking at the same results — picture the original authors of a published study, and someone doing a post-publication re-analysis of their data — you can expect that the re-analysis or the reproducibility analysis could identify reasons to value the evidence differently, or to reach more skeptical conclusions, through critical evaluation of:\n\ndata processing choices;\nthe choice of the method used to do analysis;\nchoices in how the analysis method is used.\n\n… where that critical evaluation involves an analysis of the choices the original researchers made, perhaps involving an analysis of other choices they could have made, perhaps reflecting on how effectively the analyses address a given research question or test a given prediction.\n\n\n\n\n\n\nTip\n\n\n\n\nWe can think about the work we do, when we analyse previously reported data, in terms of the need to identify the reproducibility of results, methods and inferences.\nIn psychological science, determining that someone can get the same results, by analysing the same data, or will reach the same conclusions from the same results, are important – potentially, original – research contributions.\n\n\n\n\n\n\n4.2.6 The current state of the match between open science ideas and practices\nI have said that we should expect or hope to see open science practices (Munafò et al., 2017; Nosek et al., 2022) where researchers:\n\nshare data and code;\npublish research reports in ways that enable others to check or query analyses.\n\nThis raises an important question: What exactly do we see, when we look at current practices? The question is important because answering it helps to identify where the challenges are located when you complete your work to locate, access, analyse and report previously collected data.\nI break the discussion of what we see into two parts. Firstly, I look at the results of audits of data and code sharing (see Section 4.2.6.2): are data shared and can we access the data? Secondly, I discuss analyses of methods reproducibility, and shared data and code usability (see Section 4.2.6.3): can others reproduce the results reported in published articles, given shared data? can others access and run shared analysis code? can others use the shared code to reproduce the reported results? Again, I need to be brief but reference sources that you can follow-up.\n\n4.2.6.1 The link between the credibility revolution and the reproducibility of results\nI should be clear, before we go on, about the link between the credibility revolution in science, and the effort to examine reproducibility of results. Many elements of the credibility revolution emerged out of the observation that it has often been difficult to repeat the results of published studies when we conduct new studies (replication studies or results reproducibility; e.g., Aarts et al. (2015)). However, it is clearly difficult to know what to replicate or reproduce if we cannot reproduce the results presented in a study report (methods reproducibility), given the study data (Artner et al., 2021; Laurinavichyute et al., 2022; Minocher et al., n.d.).\n\n\n4.2.6.2 Data and code sharing\nResearch on data and code sharing practices suggest that practices have improved, from earlier low levels.\nIn an important early report, Wicherts et al. (2006) observed that it was very difficult to obtain data reported in psychological research articles from the authors of the articles. They asked for data from the lead authors of 141 articles published in four leading psychology journals, for about 25% of the studies. This low response rate was found despite the fact that authors in these journals must agree to the principle that data can be shared with others wishing to verify claims.\nPractice has changed: how?\nOne change to practice has involved the use of open science badges. In journals like Psychological Science authors of articles may be awarded badges — Open Data, Open Materials, Preregistration badges — by the editorial team. Authors can apply for and earn the badges by providing information about open practices, and journal articles are published with the badges displayed near the front of the articles.\nIn theory, initiatives like encouraging authors to earn open science badges should mean that data sharing practices improve, enabling access to data and code for those, like you, who would like to re-analyse previously published data. In theory, all you should need to do — to locate and access data — is just search articles in the journal Psychological Science for studies with open data badges, and follow links from the published articles to then access study data at an open repository like the Open Science Framework (OSF) What do we see in practice?\nAnalyses reported by Kidwell et al. (2016) as well as analyses reviewed by Nosek et al. (2022) indicate that more articles have claimed to make data available in the time since badges were introduced. When they did their analysis, Kidwell et al. (2016) found that a substantial proportion, but not all, of the articles in Psychological Science can be found to actually provide access to shared data. However, critically, many but not all the articles with open data badges provide access to data available through an open repository, data that are correct, complete and usable (Kidwell et al., 2016). In their later report, the analyses reviewed by Nosek et al. (2022) suggest that the use of repositories like OSF for data sharing may be accelerating but that, over the last few years, the rate at which open science practices like sharing data, overall, appears to be substantial but not yet reported or observed in a majority of the work of researchers.\nMany journals now require the authors of articles to include a Data Availability Statement to locate their data. Analyses by Federer (2022) indicate that Data Availability Statements for articles published in the open access 4 journal PLOS ONE often, helpfully, include Digital Object Identifiers (DOIs) or Universal resource locators (URLs) enabling direct access to shared data (i.e., without having to contact authors). Of those DOIs or URLs, most appeared to be associated with resources that could successfully be retrieved. In contrast, analyses reported by Gabelica et al. (2022) indicate that where article authors state that “data sets are available on reasonable request” (the most common availability statement), most of the time, the authors did not respond or declined to share the data (see similar findings, across fields, by Tedersoo et al., 2021). Clearly, in the analyses of open science practices we have seen so far, data sharing is more effective where sharing does not have to work through authors.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you are looking for a study in order to get data that you can then re-analyse, it makes sense to look, first, for studies focusing on research questions that interest you.\nWhen you are looking for published reports where the authors share data, look for articles with open science badges or where you can see a Data Availability Statement.\nChoose articles where the authors provide a direct link to their data, where the data are located on an open repository like the Open Science Framework (there are other repositories).\n\n\n\n\n\n4.2.6.3 Enabling others to check or query analyses\nResearch on data and code sharing practices suggest that practices have improved but that there are concerns about the quality of the sharing. Here, the critical concern relates to the word enable in the objective: that we should publish research reports in ways that enable others to check or query analyses.\nJohn Towse and colleagues (Towse et al., 2021) at Lancaster University examined the quality of open data-sets to assess their quality in terms of their completeness and reusability (see also Roche et al., 2015).\n\ncompleteness: are all the data and the data descriptors supporting a study’s findings publicly available?\nreusability: how readily can the data be accessed and understood by others?\n\nFor a sample of data-sets, they found that about half were incomplete, and about two-thirds were shared in a way that made them difficult to use. Practices tended to be slightly better in more recent publications. (Broadly similar results are reported by (Hardwicke et al., 2018).)\nWhere data were found to be incomplete, this appeared to be, in part, because participants were excluded in the processing of the data for analysis but this information was not in the report, or because data were shared without a guide or “readme” file or data dictionary (or codebook) explaining the structure, coding or composition of the shared data.\nPotentially important for future open science practices, (Towse et al., 2021; also Roche et al., 2015) found that sharing data as Supplementary materials may appear to carry risks that, in the long term, mean that data may become inaccessible.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you locate open data you can access, look for a guide, “readme” file, codebook or data dictionary explaining the data: you need to be able to understand what the variables are, what the observations relate to (observations per person, per trial?) and how variables are coded.\nLocate and examine carefully the parts of the published report, or the data guide, where the authors explain how they processed their data.\n\n\n\nA number of studies have been conducted to examine whether shared data and analysis code can be reused by others to reproduce the results reported in papers (e.g., Artner et al., 2021; Crüwell et al., n.d.; Hardwicke et al., n.d.; Hardwicke et al., 2018; Laurinavichyute et al., 2022; Minocher et al., n.d.; Obels et al., 2020; see Artner et al., 2021 for a review of reproducibility studies). In critical respects, the researchers doing this work are doing work similar to the work we are helping students to do, locating, accessing, and analysing previously collected data. In these studies, typically, the researchers progressed through a series of steps.\n\nSearched the articles published in a journal (e.g., Cognition, the Journal of Memory and Language, Psychological Science), published in a topic area across multiple journals (e.g., social learning, psychological research), or associated with a specific practice (e.g., registered reports.\nSelected a subset of articles where it was identified that data could be accessed.\nIdentify a target result or outcome to reproduce, for each article. In their analyses, Hardwicke and colleagues (Hardwicke et al., n.d.; Hardwicke et al., 2018) focused on attempting to reproduce primary or straightforward and substantive outcomes: substantive – if emphasized in the abstract, or presented in a table or figure; straightforward – if the outcome could be calculated using the kind of test one would learn in an introductory psychology course (e.g., t-test, correlation).\nAttempted to reproduce the results reported in the article, using the description of the data analysis presented in the article, and the analysis code (if provided), in some cases asking for information from the original study authors, in other cases working independently of original authors.\n\nWhat the reproducibility studies appear to show is that, for many published reports, if data are shared and if the shared data are accessible and reusable then, most of the time, the researchers could reproduce the results presented by the original study authors (Hardwicke et al., n.d.; Hardwicke et al., 2018; Laurinavichyute et al., 2022; Minocher et al., n.d.; Obels et al., 2020; but see Crüwell et al., n.d.). This is great. But what is interesting, for us, is where the reproducibility researchers encountered challenges. You may encounter the same or similar challenges.\nI list some challenges that the researchers describe, following. Before you look at the list, I want to assure you: you will not find all these challenges present for any one article you look at. Most likely, you will find one or two challenges. Obviously, some challenges will be more difficult than others.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you find a study you are interested in, with open data and maybe open analysis code, your main challenge will often be to identify exactly what analysis the original study authors did to answer their research question.\nLocate and examine carefully the parts of the published report where the authors explain how they did the analysis that gave them their key result. Usually that key result should be identified in the abstract or in the conclusion.\n\n\n\n\n4.2.6.3.1 Data challenges\n\nData Availability Statements or open science badges indicate data are shared but data are not directly accessible through a link to an open repository.\nThe data are shared and accessible but there is missing or incorrect information about the data. The documentation, codebook or data dictionary is missing or incomplete. There is unclear or missing information about the variables or the observations, or about the coding of variable values, responses.\nOriginal study authors may share raw and processed data or just processed or just raw data. It may not be clear how raw data were processed to construct the data analysed for the report. It may not be clear how variables were transformed or calculated or processed.\nThere may be mismatches between the variables referred to in the report and the variables named in the data file. It may be unclear how a data file corresponds to a study described in a report, where there are multiple studies and multiple data files.\n\n\n\n4.2.6.3.2 Analysis challenges\n\nThe original report includes a description of the analysis but the description of the analysis procedure is incomplete or ambiguous.\nThere may be a mismatch, in the report, between a hypothesis, and the analysis specified to test the hypothesis (maybe in the Methods section), compared to a long sequence of results reported in the Results section. This makes it difficult to identify the key analysis.\nIt is easier to reproduce results if both data and code are shared because the presentation of the analysis code usually (not always) makes clear what analysis was done to get the results presented in the report.\nSometimes, analysis code is shared but it is difficult to use because it requires proprietary software (e.g., SPSS) or because it requires function libraries that are no longer publicly available.\nSometimes, there are errors in the analysis. Sometimes, there are errors in the presentation of the results, where results have been incorrectly copied into reports from analysis outputs."
  },
  {
    "objectID": "intro.html#this-is-why",
    "href": "intro.html#this-is-why",
    "title": "4  Reasons why we do the research report assignment: What you will learn",
    "section": "4.3 This is why",
    "text": "4.3 This is why\nThe research report assignment requires students to locate, access, analyse and report previously collected data. At the start of the introduction, I said I would explain the answer to the question:\n\nWhy: what is the motivation for the assignment?\n\nI summarize, following, the main points of the answer I have given. When you review these points, I want you to think about two things, returning to the ideas of Bourdieu (2004) and Kuhn (1970) I sketched at the start.\nOften what we do in science is guided by convention, the assumptions and habits of normal practice (Kuhn, 1970). These conventions can work in our minds so that if we encounter an anomaly or discrepancy between what we expect and what we find, in our work, we may usually blame ourselves: it was something wrong that we did or failed to do. It can cause us anxiety if we do not reproduce a result we think we should be able to reproduce (Lubega et al., n.d.). But I want you to understand, from the start, that sometimes, if you think you have found an error or a problem in a published analysis or a shared data-set, you may be right.\nIf there is anything we have learned, through the findings of replication studies, multiverse analyses, and reproducibility audits it is that people make mistakes, different choices are often reasonable, and we always need to check the evidence.\n\n4.3.1 Summary: this is why\n\nWe are in the middle of a credibility revolution. The lessons we have learned so far oblige us to think about and to teach good open science practices that safeguard the value of evidence in psychology.\nThis matters, even if we do not care about scientific methods, because if we care about the translation into policy or practice – in clinical psychology, in education, health, marketing and other fields – what we do will depend on the value of the research evidence that informs policy ideas or practice guides.\nFocusing on data analysis, it is useful to think about the whole data pipeline in analysis, the workflow that takes us from data collection to raw data to data processing to analysis to the presentation of results.\nAt every stage of the data pipeline, there are choices about what to do. There are not always reasons why we make one choice instead of another. Sometimes, we are guided by convention, example or instruction.\nThe existence of choices means the path we take, when we do data analysis, can be one path among multiple different forking paths.\nFor some parts of the pipeline – data-set construction, data analysis choices – reasonable people might make different decisions to sensibly answer the same research question, given the same data. This variation between pathways can be more or less important in influencing the results we see.\nIf results tend to stay similar across different ways of doing analysis, we might conclude that the results are reasonably robust across contexts, choices, or other variation in methods.\nTo enable others to see what we did (versus what we could have done), to see how we got to our results from our data, it is important to share our data and code.\nEveryone makes mistakes and we should make it easy for others, and ourselves, to find those mistakes by sharing our data and code in accessible, clear, usable ways.\nWe need to teach and learn how to share effectively the data and the code that we used to answer our research questions.\n\nIn constructing the assignment – in asking and supporting students to locate, access, analyse and report previously collected data – we are presenting an opportunity to really investigate and evaluate existing practices.\nYou may find that this work is challenging, in some of the places that reproducibility research has identified there can be challenges. Where the challenges cannot be fixed – if you have found an interesting study but the study data are inaccessible or unusable – we will advise you to move on to another study. Where the challenges can be fixed – if data require processing, or if analysis information requires clarification – we will provide you with help or enabling information so that you fix the problems yourself.\n\n\n\n\n\n\nTip\n\n\n\n\nMaybe the main lesson from this exercise is a reminder of the Golden rule: treat others as you would like to be treated.\nIf it is frustrating when it is difficult to understand information about an analysis or about data, or when it is difficult to access and reuse shared data and code.\nWhen it is your turn — do better — reflecting on what frustrated you.\n\n\n\nOne last question: why not just do less demanding or challenging tasks? Because this is part of what makes graduate degree valuable, what will make you more skilled in the workplace. Most of the time, we work in teams, we inherit problems or data analysis tasks, or are given results with partial information. The lessons you learn here will help you to effectively navigate those situations.\n\n\n\n\nAarts, E., Dolan, C. V., Verhage, M., & Van der Sluis, S. (2015). Multilevel analysis quantifies variation in the experimental effect while optimizing power and preventing false positives. BMC Neuroscience, 16(1), 1–15. https://doi.org/10.1186/s12868-015-0228-5\n\n\nAczel, B., Szaszi, B., Nilsonne, G., Akker, O. R. van den, Albers, C. J., Assen, M. A. van, Bastiaansen, J. A., Benjamin, D., Boehm, U., Botvinik-Nezer, R., Bringmann, L. F., Busch, N. A., Caruyer, E., Cataldo, A. M., Cowan, N., Delios, A., Dongen, N. N. van, Donkin, C., Doorn, J. B. van, … Wagenmakers, E.-J. (2021). Consensus-based guidance for conducting and reporting multi-analyst studies. eLife, 10, e72185. https://doi.org/10.7554/eLife.72185\n\n\nArtner, R., Verliefde, T., Steegen, S., Gomes, S., Traets, F., Tuerlinckx, F., & Vanpaemel, W. (2021). The reproducibility of statistical results in psychological research: An investigation using unpublished raw data. Psychological Methods, 26(5), 527–546. https://doi.org/10.1037/met0000365\n\n\nAuspurg, K., & Brüderl, J. (2021). Has the Credibility of the Social Sciences Been Credibly Destroyed? Reanalyzing the “Many Analysts, One Data Set” Project. Socius, 7, 23780231211024421. https://doi.org/10.1177/23780231211024421\n\n\nBastiaansen, J. A., Kunkels, Y. K., Blaauw, F. J., Boker, S. M., Ceulemans, E., Chen, M., Chow, S.-M., Jonge, P. de, Emerencia, A. C., Epskamp, S., Fisher, A. J., Hamaker, E. L., Kuppens, P., Lutz, W., Meyer, M. J., Moulder, R., Oravecz, Z., Riese, H., Rubel, J., … Bringmann, L. F. (2020). Time to get personal? The impact of researchers choices on the selection of treatment targets using the experience sampling methodology. Journal of Psychosomatic Research, 137, 110211. https://doi.org/10.1016/j.jpsychores.2020.110211\n\n\nBornstein, M. H., Jager, J., & Putnick, D. L. (2013). Sampling in developmental science: Situations, shortcomings, solutions, and standards. Developmental Review, 33(4), 357–370. https://doi.org/10.1016/j.dr.2013.08.003\n\n\nBotvinik-Nezer, R., Holzmeister, F., Camerer, C. F., Dreber, A., Huber, J., Johannesson, M., Kirchler, M., Iwanir, R., Mumford, J. A., Adcock, R. A., Avesani, P., Baczkowski, B. M., Bajracharya, A., Bakst, L., Ball, S., Barilari, M., Bault, N., Beaton, D., Beitner, J., … Schonberg, T. (2020). Variability in the analysis of a single neuroimaging dataset by many teams. Nature, 582(7810), 84–88. https://doi.org/10.1038/s41586-020-2314-9\n\n\nBourdieu, P. (2004). Science of Science and Reflexivity. Polity.\n\n\nBreznau, N., Rinke, E. M., Wuttke, A., Nguyen, H. H. V., Adem, M., Adriaans, J., Alvarez-Benjumea, A., Andersen, H. K., Auer, D., Azevedo, F., Bahnsen, O., Balzer, D., Bauer, G., Bauer, P. C., Baumann, M., Baute, S., Benoit, V., Bernauer, J., Berning, C., … Żółtak, T. (2022). Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty. Proceedings of the National Academy of Sciences, 119(44), e2203150119. https://doi.org/10.1073/pnas.2203150119\n\n\nButton, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: Why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCarp, J. (2012a). On the plurality of (methodological) worlds: Estimating the analytic flexibility of FMRI experiments. Frontiers in Neuroscience, 6, 149.\n\n\nCarp, J. (2012b). The secret lives of experiments: Methods reporting in the fMRI literature. Neuroimage, 63(1), 289–300.\n\n\nCohen, J. (1962). The statistical power of abnormal-social psychological research: A review. Journal of Abnormal and Social Psychology, 65(3), 145–153. https://doi.org/10.1037/h0045186\n\n\nCrüwell, S., Apthorp, D., Baker, B. J., Colling, L., Elson, M., Geiger, S. J., Lobentanzer, S., Monéger, J., Patterson, A., Schwarzkopf, D. S., Zaneva, M., & Brown, N. J. L. (n.d.). What’s in a badge? A computational reproducibility investigation of the open data badge policy in one issue of psychological science. https://doi.org/10.31234/osf.io/729qt\n\n\nDel Giudice, M., & Gangestad, S. W. (2021). A Traveler’s Guide to the Multiverse: Promises, Pitfalls, and a Framework for the Evaluation of Analytic Decisions. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920954925. https://doi.org/10.1177/2515245920954925\n\n\nDutilh, G., Annis, J., Brown, S. D., Cassey, P., Evans, N. J., Grasman, R. P. P. P., Hawkins, G. E., Heathcote, A., Holmes, W. R., Krypotos, A.-M., Kupitz, C. N., Leite, F. P., Lerche, V., Lin, Y.-S., Logan, G. D., Palmeri, T. J., Starns, J. J., Trueblood, J. S., Maanen, L. van, … Donkin, C. (2019). The Quality of Response Time Data Inference: A Blinded, Collaborative Assessment of the Validity of Cognitive Models. Psychonomic Bulletin & Review, 26(4), 1051–1069. https://doi.org/10.3758/s13423-017-1417-2\n\n\nFederer, L. M. (2022). Long-term availability of data associated with articles in PLOS ONE. PLOS ONE, 17(8), e0272845. https://doi.org/10.1371/journal.pone.0272845\n\n\nFillard, P., Descoteaux, M., Goh, A., Gouttard, S., Jeurissen, B., Malcolm, J., Ramirez-Manzanares, A., Reisert, M., Sakaie, K., Tensaouti, F., Yo, T., Mangin, J.-F., & Poupon, C. (2011). Quantitative evaluation of 10 tractography algorithms on a realistic diffusion MR phantom. NeuroImage, 56(1), 220–234. https://doi.org/10.1016/j.neuroimage.2011.01.032\n\n\nFlake, J. K., & Fried, E. I. (2020). Measurement Schmeasurement: Questionable Measurement Practices and How to Avoid Them. Advances in Methods and Practices in Psychological Science, 3(4), 456–465. https://doi.org/10.1177/2515245920952393\n\n\nGabelica, M., Bojčić, R., & Puljak, L. (2022). Many researchers were not compliant with their published data sharing statement: a mixed-methods study. Journal of Clinical Epidemiology, 150, 33–41. https://doi.org/10.1016/j.jclinepi.2022.05.019\n\n\nGelman, a. (2015). The connection between varying treatment effects and the crisis of unreplicable research: A bayesian perspective. Journal of Management, 41(2), 632–643. https://doi.org/10.1177/0149206314525208\n\n\nGelman, A., & Loken, E. (2014a). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time. Psychological Bulletin, 140(5), 1272–1280.\n\n\nGelman, A., & Loken, E. (2014b). The statistical crisis in science. American Scientist, 102(6), 460–465. https://doi.org/10.1511/2014.111.460\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power. American Scientist, 97(4), 310–316. https://doi.org/10.1511/2009.79.310\n\n\nGilmore, R. O., Diaz, M. T., Wyble, B. A., & Yarkoni, T. (2017). Progress toward openness, transparency, and reproducibility in cognitive neuroscience. Annals of the New York Academy of Sciences, 1396, 5–18. https://doi.org/10.1111/nyas.13325\n\n\nGoodman, S. N., Fanelli, D., & Ioannidis, J. P. A. (2016). What does research reproducibility mean? Science Translational Medicine, 8(341).\n\n\nHardwicke, T. E., Bohn, M., MacDonald, K., Hembacher, E., Nuijten, M. B., Peloquin, B. N., deMayo, B. E., Long, B., Yoon, E. J., & Frank, M. C. (n.d.). Analytic reproducibility in articles receiving open data badges at the journal psychological science: An observational study. Royal Society Open Science, 8(1), 201494. https://doi.org/10.1098/rsos.201494\n\n\nHardwicke, T. E., Mathur, M. B., MacDonald, K., Nilsonne, G., Banks, G. C., Kidwell, M. C., Hofelich Mohr, A., Clayton, E., Yoon, E. J., Henry Tessler, M., Lenne, R. L., Altman, S., Long, B., & Frank, M. C. (2018). Data availability, reusability, and analytic reproducibility: evaluating the impact of a mandatory open data policy at the journal Cognition. Royal Society Open Science, 5(8), 180448. https://doi.org/10.1098/rsos.180448\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010). The weirdest people in the world? The Behavioral and Brain Sciences, 33(2-3). https://doi.org/10.1017/S0140525X0999152X\n\n\nHerndon, T., Ash, M., & Pollin, R. (2014). Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff. Cambridge Journal of Economics, 38(2), 257–279. https://doi.org/10.1093/cje/bet075\n\n\nHoffmann, S., Schönbrodt, F., Elsas, R., Wilson, R., Strasser, U., & Boulesteix, A.-L. (n.d.). The multiplicity of analysis strategies jeopardizes replicability: Lessons learned across disciplines. Royal Society Open Science, 8(4), 201925. https://doi.org/10.1098/rsos.201925\n\n\nIoannidis, J. P. a. (2005). Why most published research findings are false. PLoS Medicine, 2(8), 0696–0701. https://doi.org/10.1371/journal.pmed.0020124\n\n\nJohn, L. K., Loewenstein, G., & Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth telling. Psychological Science, 23(5), 524–532. https://doi.org/10.1177/0956797611430953\n\n\nKidwell, M. C., Lazarević, L. B., Baranski, E., Hardwicke, T. E., Piechowski, S., Falkenberg, L. S., Kennett, C., Slowik, A., Sonnleitner, C., Hess-Holden, C., Errington, T. M., Fiedler, S., & Nosek, B. A. (2016). Badges to acknowledge open practices: A simple, low-cost, effective method for increasing transparency. PLoS Biology, 14(5), 1–15. https://doi.org/10.1371/journal.pbio.1002456\n\n\nKlau, S., Hoffmann, S., Patel, C. J., Ioannidis, J. P., & Boulesteix, A.-L. (2021). Examining the robustness of observational associations to model, measurement and sampling uncertainty with the vibration of effects framework. International Journal of Epidemiology, 50(1), 266–278. https://doi.org/10.1093/ije/dyaa164\n\n\nKlau, S., Schönbrodt, F., Patel, C. J., Ioannidis, J., Boulesteix, A.-L., & Hoffmann, S. (n.d.). Comparing the vibration of effects due to model, data pre-processing and sampling uncertainty on a large data set in personality psychology. https://doi.org/10.31234/osf.io/c7v8b\n\n\nKuhn, T. S. (1970). The structure of scientific revolutions ([2d ed., enl). University of Chicago Press.\n\n\nLandy, J. F., Jia, M. L., Ding, I. L., Viganola, D., Tierney, W., Dreber, A., Johannesson, M., Pfeiffer, T., Ebersole, C. R., Gronau, Q. F., Ly, A., Bergh, D. van den, Marsman, M., Derks, K., Wagenmakers, E.-J., Proctor, A., Bartels, D. M., Bauman, C. W., Brady, W. J., … Uhlmann, E. L. (2020). Crowdsourcing hypothesis tests: Making transparent how design choices shape research results. Psychological Bulletin, 146(5), 451–479. https://doi.org/10.1037/bul0000220\n\n\nLaurinavichyute, A., Yadav, H., & Vasishth, S. (2022). Share the code, not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy. Journal of Memory and Language, 125, 104332. https://doi.org/10.1016/j.jml.2022.104332\n\n\nLubega, N., Anderson, A., & Nelson, N. (n.d.). Experience of irreproducibility as a risk factor for poor mental health in biomedical science doctoral students: A survey and interview-based study. https://doi.org/10.31222/osf.io/h37kw\n\n\nMaier-Hein, K. H., Neher, P. F., Houde, J.-C., Côté, M.-A., Garyfallidis, E., Zhong, J., Chamberland, M., Yeh, F.-C., Lin, Y.-C., Ji, Q., Reddick, W. E., Glass, J. O., Chen, D. Q., Feng, Y., Gao, C., Wu, Y., Ma, J., He, R., Li, Q., … Descoteaux, M. (2017). The challenge of mapping the human connectome based on diffusion tractography. Nature Communications, 8(1), 1349. https://doi.org/10.1038/s41467-017-01285-x\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of Science, 34(2), 103–115.\n\n\nMeehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir karl, sir ronald, and the slow progress of soft psychology. 46(September 1976), 806–834.\n\n\nMinocher, R., Atmaca, S., Bavero, C., McElreath, R., & Beheim, B. (n.d.). Estimating the reproducibility of social learning research published between 1955 and 2018. Royal Society Open Science, 8(9), 210450. https://doi.org/10.1098/rsos.210450\n\n\nMunafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Percie Du Sert, N., Simonsohn, U., Wagenmakers, E. J., Ware, J. J., & Ioannidis, J. P. A. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1(1), 1–9. https://doi.org/10.1038/s41562-016-0021\n\n\nNosek, B. A., Beck, E. D., Campbell, L., Flake, J. K., Hardwicke, T. E., Mellor, D. T., van?t Veer, A. E., & Vazire, S. (2019). Preregistration is hard, and worthwhile. Trends in Cognitive Sciences, 23(10), 815–818.\n\n\nNosek, B. A., Ebersole, C. R., DeHaven, A. C., & Mellor, D. T. (2018). The preregistration revolution. Proceedings of the National Academy of Sciences, 115(11), 2600–2606.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., Rohrer, J. M., Romero, F., Scheel, A. M., Scherer, L. D., Schönbrodt, F. D., & Vazire, S. (2022). Replicability, Robustness, and Reproducibility in Psychological Science. Annual Review of Psychology, 73, 719–748. https://doi.org/10.1146/annurev-psych-020821-114157\n\n\nNosek, B. A., & Lakens, D. (2014). Registered reports: A method to increase the credibility of published results. Social Psychology, 45(3), 137–141. https://doi.org/10.1027/1864-9335/a000192\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nParsons, S. (n.d.). Exploring reliability heterogeneity with multiverse analyses: Data processing decisions unpredictably influence measurement reliability. https://doi.org/10.31234/osf.io/y6tcz\n\n\nPashler, H., & Harris, C. (2012). Is the replicability crisis overblown? Three arguments examined. Perspectives on Psychological Science, 7(6), 531–536. https://doi.org/10.1177/1745691612463401\n\n\nPashler, H., & Wagenmakers, E. J. (2012). Editors’ introduction to the special section on replicability in psychological science: A crisis of confidence? Perspectives on Psychological Science, 7(6), 528–530. https://doi.org/10.1177/1745691612465253\n\n\nPatel, C. J., Burford, B., & Ioannidis, J. P. A. (2015). Assessment of vibration of effects due to model specification can demonstrate the instability of observational associations. Journal of Clinical Epidemiology, 68(9), 1046–1058. https://doi.org/10.1016/j.jclinepi.2015.05.029\n\n\nPoline, J.-B., Strother, S. C., Dehaene-Lambertz, G., Egan, G. F., & Lancaster, J. L. (2006). Motivation and synthesis of the FIAC experiment: Reproducibility of fMRI results across expert analyses. Human Brain Mapping, 27(5), 351–359. https://doi.org/10.1002/hbm.20268\n\n\nRoche, D. G., Kruuk, L. E. B., Lanfear, R., & Binning, S. A. (2015). Public data archiving in ecology and evolution: How well are we doing? PLoS Biology, 13(11), 1–12. https://doi.org/10.1371/journal.pbio.1002295\n\n\nSalganik, M. J., Lundberg, I., Kindel, A. T., Ahearn, C. E., Al-Ghoneim, K., Almaatouq, A., Altschul, D. M., Brand, J. E., Carnegie, N. B., Compton, R. J., Datta, D., Davidson, T., Filippova, A., Gilroy, C., Goode, B. J., Jahani, E., Kashyap, R., Kirchner, A., McKay, S., … McLanahan, S. (2020). Measuring the predictability of life outcomes with a scientific mass collaboration. Proceedings of the National Academy of Sciences, 117(15), 8398–8403. https://doi.org/10.1073/pnas.1915006117\n\n\nScheel, A. M. (2022). Why most psychological research findings are not even wrong. Infant and Child Development, 31(1), e2295. https://doi.org/10.1002/icd.2295\n\n\nScheel, A. M., Tiokhin, L., Isager, P. M., & Lakens, D. (2021). Why Hypothesis Testers Should Spend Less Time Testing Hypotheses. Perspectives on Psychological Science, 16(4), 744–755. https://doi.org/10.1177/1745691620966795\n\n\nSchweinsberg, M., Feldman, M., Staub, N., Akker, O. R. van den, Aert, R. C. M. van, Assen, M. A. L. M. van, Liu, Y., Althoff, T., Heer, J., Kale, A., Mohamed, Z., Amireh, H., Venkatesh Prasad, V., Bernstein, A., Robinson, E., Snellman, K., Amy Sommer, S., Otner, S. M. G., Robinson, D., … Luis Uhlmann, E. (2021). Same data, different conclusions: Radical dispersion in empirical results when independent analysts operationalize and test the same hypothesis. Organizational Behavior and Human Decision Processes, 165, 228–249. https://doi.org/10.1016/j.obhdp.2021.02.003\n\n\nSedlmeier, P., & Gigerenzer, G. (1989). Statistical power studies. Psychological Bulletin, 105(2), 309–316.\n\n\nSilberzahn, R., & Uhlmann, E. L. (2015). Crowdsourced research: Many hands make tight work. Nature, 526(7572), 189–191. https://doi.org/10.1038/526189a\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahník, Š., Bai, F., Bannard, C., Bonnier, E., Carlsson, R., Cheung, F., Christensen, G., Clay, R., Craig, M., Dalla Rosa, A., Dam, L., Evans, M., Flores Cervantes, I., … Nosek, B. (2017). Many analysts, one dataset: Making transparent how variations in analytical choices affect results. Advances in Methods and Practices in Psychological Science. https://doi.org/10.31234/osf.io/qkwst\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011b). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011a). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nStarns, J. J., Cataldo, A. M., Rotello, C. M., Annis, J., Aschenbrenner, A., Bröder, A., Cox, G., Criss, A., Curl, R. A., Dobbins, I. G., Dunn, J., Enam, T., Evans, N. J., Farrell, S., Fraundorf, S. H., Gronlund, S. D., Heathcote, A., Heck, D. W., Hicks, J. L., … Wilson, J. (2019). Assessing Theoretical Conclusions With Blinded Inference to Investigate a Potential Inference Crisis. Advances in Methods and Practices in Psychological Science, 2(4), 335–349. https://doi.org/10.1177/2515245919869583\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016a). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016b). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.\n\n\nTedersoo, L., Küngas, R., Oras, E., Köster, K., Eenmaa, H., Leijen, Ä., Pedaste, M., Raju, M., Astapova, A., Lukner, H., Kogermann, K., & Sepp, T. (2021). Data sharing practices and data availability upon request differ across scientific disciplines. Scientific Data, 8(1), 192. https://doi.org/10.1038/s41597-021-00981-0\n\n\nTowse, J. N., Ellis, D. A., & Towse, A. S. (2021). Opening Pandora’s Box: Peeking inside Psychology’s data sharing practices, and seven recommendations for change. Behavior Research Methods, 53(4), 1455–1468. https://doi.org/10.3758/s13428-020-01486-1\n\n\nUlrich, R., & Miller, J. (1994). Effects of truncation on reaction time analysis. Journal of Experimental Psychology: General, 123, 34–80.\n\n\nVankov, I., Bowers, J., & Munafò, M. R. (2014). On the persistence of low power in psychological science. Quarterly Journal of Experimental Psychology, 67(5), 1037–1040. https://doi.org/10.1080/17470218.2014.885986\n\n\nVasishth, S., & Gelman, A. (2021). How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis. Linguistics, 59(5), 1311–1342. https://doi.org/10.1515/ling-2019-0051\n\n\nVazire, S. (2018). Implications of the Credibility Revolution for Productivity, Creativity, and Progress. Perspectives on Psychological Science, 13(4), 411–417. https://doi.org/10.1177/1745691617751884\n\n\nWagenmakers, E.-J., Sarafoglou, A., & Aczel, B. (2022). One statistical analysis must not rule them all. Nature, 605(7910), 423–425. https://doi.org/10.1038/d41586-022-01332-8\n\n\nWagenmakers, E.-J., Wetzels, R., Borsboom, D., & Maas, H. L. J. van der. (2011). Why psychologists must change the way they analyze their data: The case of psi: Comment on bem (2011). Journal of Personality and Social Psychology, 100(3), 426–432. https://doi.org/10.1037/a0022790\n\n\nWessel, I., Albers, C., Zandstra, A. R. E., & Heininga, V. E. (2020). A multiverse analysis of early attempts to replicate memory suppression with the think/no-think task.\n\n\nWicherts, J. M., Borsboom, D., Kats, J., & Molenaar, D. (2006). The poor availability of psychological research data for reanalysis. American Psychologist, 61(7), 726–728. https://doi.org/10.1037/0003-066X.61.7.726\n\n\nWild, H., Kyröläinen, A.-J., & Kuperman, V. (2022). How representative are student convenience samples? A study of literacy and numeracy skills in 32 countries. PLOS ONE, 17(7), e0271191. https://doi.org/10.1371/journal.pone.0271191\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1. https://doi.org/10.1017/S0140525X20001685\n\n\nYoung, C. (2018). Model uncertainty and the crisis in science. Socius, 4, 2378023117737206.\n\n\nYoung, C., & Holsteen, K. (2017). Model Uncertainty and Robustness: A Computational Framework for Multimodel Analysis. Sociological Methods & Research, 46(1), 3–40. https://doi.org/10.1177/0049124115610347"
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "4  Reasons why we do the research report assignment: What you will learn",
    "section": "",
    "text": "This encouragement is often attributed to Gandhi but is attributed ((here)) to a Brooklyn school teacher, Ms Arleen Lorrance, who led a transformative school project in the 1970s.↩︎\nThe term is taken from the name of a short story by Jorge Luis Borges, “El jardin de senderos que se bifurcan” (translated as ‘The garden of forking paths’).↩︎\nThere could be a story where the hero (us) ultimately learns to reject binary (present, absent; significant, non-significant) choices, and embrace variation, or embrace uncertainty (a. Gelman, 2015; Vasishth & Gelman, 2021).↩︎\nOpen access journals publish articles that are free to read or download.↩︎"
  },
  {
    "objectID": "what.html#sec-what-expected",
    "href": "what.html#sec-what-expected",
    "title": "5  What you have to do",
    "section": "5.1 The research report: what you are expected to do",
    "text": "5.1 The research report: what you are expected to do\nNote that the following information mirrors exactly the information provided on Moodle:\nhttps://modules.lancaster.ac.uk/mod/page/view.php?id=2212445\n\n5.1.1 What data can I analyse?\nReports will concern, usually, findings from analyses of data-sets we have provided to you. Some students may wish to analyse data collected in previous studies or data accessed from online sources: they should correspond with Padraic Monaghan or Rob Davies if they wish to do so.\nThe evaluation of reports will focus on clarity, read the following for discussion of what is required.\nWe expect students to use one of the analysis methods taught in the module. Marks will be awarded depending:\n\non how appropriate the method is to the context, to the study design, to answering the research question, and to the features of the data; the appropriateness of methods to contexts will be taught in class;\non how effectively the analysis is explained; students must explain the motivations for their decisions, explain their methods, and explain their findings effectively to gain points.\n\n\n\n5.1.2 What structure should reports take?\n\nThe reports should include abstract, introduction, methods, results, discussion and references sections, like a short research article in the journal Psychological Science. You can view examples of articles here\n\nhttps://journals.sagepub.com/home/pss\n\nWord count limit: no more than 1500 words are allowed for all materials.\nUnlike a published research article, for PSYC401, the Results and Discussion sections must be written in full, but the Introduction and Methods sections can be written in the form of notes.\n\n\n\n5.1.3 What content should reports present?\n\n5.1.3.1 Introduction and Method sections\nThe focus of marking will be on the quality of the Results and Discussion sections. This means you can write your notes in the Introduction and Methods sections as short answers to the following questions:-\n\n5.1.3.1.1 Introduction\n\nWhat did the researchers do and why did the researchers do it?\nWhat was the question addressed in the study and why is it interesting?\nWhat were the hypotheses?\nWhat results were expected and how would they relate to the hypotheses?\n\nHow can you write this as a set of notes? We require main points of information on the hypotheses concerning expected results. We will ignore the absence of citations, or of explanations of critical previous experimental work, in the Introduction.\n\n\n5.1.3.1.2 Method\nNote the origin of the data at the start of the method section. As for the Introduction, your method section writing needs to furnish answers to questions like the following:-\n\nWhat was done to collect the data?\nWho were tested (Participants)?\nWhat materials were used in testing (Materials)?\nWhat was the design of the study?\nWhat procedure was used?\n\nHow can you write this as a set of notes? We require main points of information, especially the main features of the data analyzed – what were the variables, how many observations were recorded, what exclusions or other data treatment steps were applied?\n\n\n\n5.1.3.2 Results and Discussion sections\nThe focus of marking will be on the quality of the Results and Discussion sections. This means you must write in complete sentences in full paragraphs in a style appropriate for a research article appearing in a journal like Psychological Science. You must not use notes for these sections. You must write text that explains to the reader the analysis you did, why you did it, the results you found, and the implications of those results. You should write the text for the sections so that the questions listed following are answered fully.\nIf you use a data set that is already published in a journal such as Psychological Science, then your presentation of the results must differ from that in the article in ways that highlight new features of the data.\n\n5.1.3.2.1 Results\nBe clear on what the outcome measure or dependent variable for analysis was, and on what factors or predictor variables were brought into the analysis of that outcome. You then need to ensure the Results section answers the following questions:-\n\nWhat hypotheses were tested?\nWhat methods were used to test the hypotheses?\nWhy are they appropriate?\nWhat were the results? What were the direction and relative size of effects?\n\nDo what seems reasonable using one or more of the analysis methods practiced in class, or practiced in association with the workbooks, and explain your reasoning.\n\n\n5.1.3.2.2 Discussion\nWhat the reader must be able to do, given your report, is understand the answer to the following questions:\n\nWhat are the theoretical implications of the study findings?\nWhat are the practical implications?\n\nReports should present enough information that the reader can understand: the background and motivation for a study; the features of the data analyzed and the methods of data collection; the approach taken in analysis, the analysis steps, and the results; the relationship between the observed results and the expected results, and the interpretation of findings in relation to previous work.\nTo be clear about clarity: explain, spell things out (decisions, reasoning, interpretations) as if you were explaining them to a reasonably intelligent reader, a Psychologist who is not a specialist in the area of study occupied by the study reported. The main point is that you should keep in mind what the reader should get out of (what benefit) reading your report.\n\n\n\n\n5.1.4 What format?\n\n5.1.4.1 Statistics, tables and figures should follow APA guidelines\nSee here for a free guide.\nFor general APA formatting of reports: https://owl.purdue.edu/owl/research_and_citation/apa_style/apa_style_introduction.html\nAnd for APA formatting of statistics and numbers:\nhttps://owl.purdue.edu/owl/research_and_citation/apa_style/apa_formatting_and_style_guide/apa_numbers_statistics.html\nThough the APA guidelines are the authoritative guide.\n\n\n5.1.4.2 Add a link to the data analysed for the report"
  },
  {
    "objectID": "what.html#sec-marking",
    "href": "what.html#sec-marking",
    "title": "5  What you have to do",
    "section": "5.2 The research report: assessment criteria",
    "text": "5.2 The research report: assessment criteria\nNote that the following information mirrors exactly the information provided on Moodle on assessment criteria:\nhttps://modules.lancaster.ac.uk/mod/page/view.php?id=2212446\nThese assessment criteria relate to the short research report:\nThe marks for the report will be depend primarily on the quality of the Results and Discussion sections of the report. This is because, in most cases, you will be using data for your analysis that were collected, previously, by other authors for an already published report. We cannot give you much credit for writing about the background research literature in the Introduction or about the Method of data collection because the authors of the original report did that work if you are using published data, or because I [or others] did that work if you are using demonstration data. We can give you credit for writing brief notes in the Introduction and Method sections, in your report, that present concise, clear, summaries of the background research literature and method of data collection.\nMarks will be awarded on the basis of the quality of the Results and Discussion sections. You can use whatever analysis approach you feel is justified. We will award marks for:-\n\nThe clarity and sense of the reasoning you describe for the approach you take. Explain your decisions. Why did you use the analysis method you chose to use?\nThe clarity of the description of the analysis method and results. Follow the APA style guide on how you should present tables and how you should report statistics in the text of the report. You must say not just whether a difference between conditions or the effect of a variable is significant. You must also describe the nature of the difference or of the effect. What is the size and the direction of the difference or the effect?\nHow effectively you make sense of the results in the context of the background research, and the research question. Explain how the reader should interpret the results. What are the theoretical or practical implications of the results?\n\n\n5.2.1 How will marks be awarded?\nRead the guide to postgraduate marking criteria, in the Masters handbook.\nSome things will be more important than others in determining your marks. What will be especially important for this assessment are the following.\nA distinction requires … Clear conceptual structure; a thorough understanding of the topic and its implications; a clearly expressed and convincing argument that is used to develop a coherent and logical answer to the question, and is effectively based in existing theory and research; evidence of independent research; an insightful argument showing evidence of original thinking; and mastery of analytic techniques or methods.\nWhat is required is mastery. To evidence mastery, we will want to see:\n\nthe ability to evaluate methodologies critically;\ncritical awareness of current problems or new insights from current research;\ndemonstration that you can handle complex issues systematically, making excellent judgements.\n\nMastery is about choices. Data analysis requires you to make choices. Those choices require awareness of alternative approaches, an evaluation of the relative appropriateness of one method compared to others, and an explanation motivating the approach you choose to take. To get to this level, you will need to work with our materials, and read more widely, perhaps even looking at primary and secondary literature on statistics in independent reading.\nOf course, you can get a distinction by doing what we teach you but you will evidence, in addition, some reflection on the relevant concerns, some creativity or original thinking or reading about the relevant issues.\nA merit requires … Clear conceptual structure; a good understanding of the topic and its implications; an ability to select and organize material to provide a clear and logical line of argument; some (limited) evidence of independent thought or reading; general competence in analytic techniques or methods.\nWhat is required is a good level of competence overall. To evidence good competence, we will want to see:\n\na clear correspondence between the research question, hypotheses or predictions, and the chosen analytic method, which must be applied in a clearly appropriate manner;\nan awareness of the concerns relevant to the data analysis required to address the research question;\na comprehensive understanding of the techniques, and the skilful application of those techniques where appropriate.\n\nGeneral competence is about skill and understanding. We expect you to be able to identify the appropriate method to analyse data to address a research question. To evidence a good level of competence, your explanation of why you use the method you use will need to show an understanding of the appropriateness of the method in the context of the research question. We may see some critical evaluation, or reflection, on the appropriateness of the method, or its limits, but less than we might see in work of distinction standard. We expect to see a skillful use of the techniques we taught you. We expect to see an effective communication of your explanation for why you use the method, and what the results show.\nA pass requires … Basic competence in the application of research methods or analytic techniques. It is distinguished from work in the Merit category by the level of analysis displayed and by the coherence with which the material is organized. There may be some errors, misjudgments or omissions of important details.\nWhat is required is basic competence overall. To evidence basic competence, we will want to see:\n\na clear correspondence between the research question, hypotheses or predictions, and the chosen analytic method, which must be applied in an appropriate manner;\nreasonably well-structured account of the key information, concepts or findings;\nevidence of understanding of and some skill in using the appropriate techniques, though there may be evidence of limitations in understanding, perhaps some minor errors or omissions in the use of techniques or in the reporting of results."
  },
  {
    "objectID": "how.html#sec-how-variety",
    "href": "how.html#sec-how-variety",
    "title": "6  How you can do it",
    "section": "6.1 The variety of things students do",
    "text": "6.1 The variety of things students do\nStudents have taken a variety of approaches to the assignment.\n\nUsing demonstration data — Some students choose to complete an analysis of one of the data-sets used for practical exercises in class: the example or demonstration data we collect together as curated data-sets.\nAnalyzing public data that have been previously analysed — Some students choose to complete an analysis of a publicly available data-set that has been analysed previously, where the analysis report has been published in a journal article.\nAnalyzing public data that have not been previously analysed — Some students choose to complete an analysis of a publicly available data-set where an analysis report has not been published in a journal article.\n\nAsk in class or on the Moodle discussion forum for advice about any one of these approaches.\nI consider, first, working with data-sets where an analysis of the data has been presented in the article (see Section 6.2). I then look at working with data-sets where the data are presented without an analysis (see Section 6.3). Our advice on working with data-sets presented without an analysis will overlap in key respects with our advice on working with curated demonstration data."
  },
  {
    "objectID": "how.html#sec-publishedanalysis",
    "href": "how.html#sec-publishedanalysis",
    "title": "6  How you can do it",
    "section": "6.2 Working with data associated with a published analysis",
    "text": "6.2 Working with data associated with a published analysis\nIn the following, I split our guidance into two parts.\n\nI look next at the task of locating, accessing and checking the data (Section 6.2.1).\nThen I look at the task of figuring out what analysis you can do with the data (see Section 6.2.2).\n\nObviously, you cannot consider an analysis if you cannot be sure that you can work with the data (Minocher et al., n.d.).\n\n6.2.1 Locate, access and check the data\nAt the start of your work on the assignment, you will need to (1.) locate then (2.) access data for analysis, and then you will need to (3.) check that the data are usable. I set out advice on doing each step, following. Work through the steps: one step at a time.\n\n6.2.1.1 Locate\nIt is usually helpful to find a data-set where the data have been collected in a study within a topic area you care about, or could be interested in. It is helpful because you will need to work with the data and it will be motivating if you are interested in what the data concern. And it is helpful because, often, you will need to do a bit of reading on related research to learn about the context for the data collection, and you will usually want to read research sources that interest you.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nDo a search: look for an article with usable data in a topic area that interests you.\n\n\n\nThere are at least two ways you can do this. Both should be reasonably quick methods to get to a usable data-set.\n\nDo a search on Google scholar).\nDo a search on the webpages of a journal.\n\nMost psychological research is published in journals like Psychological Science. If you want, you can look at a list of psychology journals here.\nIn a journal like Psychological Science you can look through lists of previously published articles (in issues, volumes, by year) on the journal webpage. Here is the list of issues for Psychological Science..\n\n6.2.1.1.1 Key words\nIn both methods, you are looking for an article associated with data (and maybe analysis code) you can access and that you are sure you can use. In both methods, you need to first think about some key words to use in your search. Ask yourself:\n\nWhat are you interested in? What population, intervention or effect, comparison, or outcome?\n\nThen:\n\nWhat words do people use, in articles you have seen, when they talk about this thing?\n\nYou can use these words, and maybe consider alternate terms. For example, I am interested in reading comprehension or development reading comprehension but researchers working on reading development might also refer to children reading comprehension.\nYou want to be as efficient as possible so combine your search for articles in an interesting topic area with your search for accessible data. We can learn from the research we discussed on data sharing practices (see Section 4.2.6.2) by looking for specific markers that data associated with an article should be accessible.\nIf you are doing a search (1.) on Google scholar), I would use the key words related to your topic plus words like: open data badge; open science badge. So, I would do a search for the words: reading comprehension open data badge. I have done this: you can try it. The search results will list articles related to the topic of reading comprehension, where the authors claim to have earned the open data badge because they have made data available.\nIf you are doing a search (2.) in a journal list of articles, then what you are looking for are articles that interest you and which are listed with open data badges. In the listing for Psychological Science (here)) a quick read of the journal issue articles index shows that article titles are listed together with symbols representing the open science badges that authors have claimed.\nIn other journals (e.g., PLOS ONE, PeerJ, Collabra), you may be looking for interesting articles with the words Data Availability Statement, Data Accessibility Statement, Supplementary data or Supplementary materials in the article webpage somewhere. Journals like PeerJ or Collabra, in particular, make it easy to locate data associated with published articles on their web pages.\nIn Collabra, you can find published articles through the journal webpage (here). If you click on the title of any article, and look at the article webpage, then on the left of the article text, you can see an index of article contents and that index lists the Data Availability Statement. Click on that and you are often taken to a link to a data repository.\n\n\n\n6.2.1.2 Access\nIf you have located an interesting article with evidence (an open data badge or a data accessibility statement) that the authors have shared their data, you need to check that you can access the data. Most of the time, now, you are looking for a link you can use to go directly to the shared data. The link is often presented as a hyperlink on a webpage, associated with Digital Object Identifiers (DOIs) or Universal resource locators (URLs). Or, increasingly, you are looking for a link to a data repository on a site like the Open Science Framework (OSF).\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nAccess the data associated with the article you have found.\n\n\n\nHere are some recent examples from my work that you can check, to give you a sense of where or how to find the accessible link to the shared data.\n\nRicketts, J., Dawson, N., & Davies, R. (2021). The hidden depths of new word knowledge: Using graded measures of orthographic and semantic learning to measure vocabulary acquisition. Learning and Instruction, 74, 101468. https://doi.org/10.1016/j.learninstruc.2021.101468\n\n\nRodríguez-Ferreiro, J., Aguilera, M., & Davies, R. (2020). Semantic priming and schizotypal personality: Reassessing the link between thought disorder and enhanced spreading of semantic activation. PeerJ, 8, e9511. https://doi.org/10.7717/peerj.9511\n\nThese are both open access articles.\nIf you look at the webpage for, Rodríguez-Ferreiro et al. (2020), (here)), you can do a search in the article text for the keyword OSF (on the article webpage, use keys CMD-F plus OSF). You are checking to see if you can click on the link and and if clicking on the link takes you to a repository listing the data for the article. The Rodríguez-Ferreiro et al. (2020) article is associated with a data plus analysis code repository (OSF))\nNotice that on the repository webpage, you can see a description of the project plus .pdf files and a folder data-set and Code. If you can click through to the folders, and download the datafiles, you have accessed the data successfully.\nI have guided you, here, through to the Rodríguez-Ferreiro et al. (2020) data repository, can you find the data for the Ricketts et al. (2021) repository?\n\n\n6.2.1.3 Check\nIf you have located an interesting article with data that you can access, and if you have read the introductory notes (see Section 4.2.6.3), then you will next need to make sure that you can use the data.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nCheck the data and the data documentation to make sure you can understand what you have got and whether you can use it.\n\n\n\nWhat make data usable are:\n\nInformation in the article, or in the data repository documentation, on the study design and data collection methods: you need to be able to understand where the data came from, how they were collected, and why.\nClear data documentation: you need to find information on the variables, the observations, the scoring, the coding, and whether and how the data were processed to get them from raw data state to the data ready for analysis.\n\nData documentation is often presented as a note or a wiki page or a miniature paper and may be called a codebook, data dictionary, guide to materials or something similar. You will need to check that you can find information on (examples shown are from the Rodríguez-Ferreiro et al. (2020) OSF guide to materials):\n\nwhat the data files are called e.g. PrimDir-111019.csv;\nhow the named data files correspond to the studies presented in the report;\nwhat the data file columns are called and what variables the column data represent e.g. relation, coding for prime-target relatedness condition ...;\nhow scores or responses in columns were collected or calculated e.g. age, giving the age in years ...;\nhow coding was done, if coding was used e.g. biling, giving the bilingualism status;\nwhether data were processed, how missing values were coded, whether participants or observations were excluded before analysis e.g. Missing values in the rt column ... coded as NA\n\n\n\n\n\n\n\nWarning\n\n\n\nIf these information are not presented, or are not clear: walk away.\n\n\n\n\n\n6.2.2 Plan the analysis you want to do\nAfter you have found an interesting article, and have confirmed that you can use the associated data, you will need to plan what analysis you want to do.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nIdentify and understand the analysis in the article.\nWork out what analysis you want to do.\n\n\n\nStudents have taken a variety of approaches to the assignment.\n\nSome students choose to complete a reanalysis of the data, in an attempt to reproduce the results presented in the article (see 4.2.5.1).\nSome students choose to complete an alternate analysis of the data, varying elements of the analysis (see the discussion in 4.2.4).\n\nEither way, you will want to first make sure you can identify exactly what the authors of the original study did, how they did it, and why they did it.\nYou can process the key article information efficiently using the QALMRI method we discussed in the class on graduate writing skills (Brosowsky et al., n.d.; Kosslyn & Rosenberg, 2005). You are first aiming to locate information on the broad and the specific question the study addresses, the methods the study authors used to collect data, the results they report, and the conclusions they present given the results. Can you find these bits of information?\n\n6.2.2.1 Completing a reanalysis of the data\nAre you interested in attempting a methods reproducibility test?\nFollowing Hardwicke and colleagues (Hardwicke et al., n.d.; Hardwicke et al., 2018), it would be sensible to focus on identifying the primary or substantive result for a study in an article.\n\nThe result is substantive if the researchers state that it is (e.g., “Our critical analysis is…”), if it is emphasized in the abstract, or if it is presented in a table or figure.\n\nAs we discussed in the class on graduate writing skills, the article authors should signal what they consider to be the primary result for a study by telling you that a result is critical or key or that a result is the or an answer to their research question.\n\n\n\n\n\n\nTip\n\n\n\n\nAn article may present multiple studies: focus on one.\nThe results section of an article, for a study, may list multiple results: identify the primary or substantive result.\n\n\n\nYou will want to identify a result that is both substantive and straightforward (Hardwicke et al., n.d.; Hardwicke et al., 2018).\n\nThe result is Straightforward if the outcome could be calculated using the kind of test you have been learning about or will learn about (e.g., t-test, correlation, the linear model)\n\nPsychological science researchers use a variety of data analysis methods and not all the analyses that you read about will be analyses done using methods that you know about. The use of the methods we teach — t-test, correlation, and the linear model — are very very common; that is why we teach them. But you may also see reports of analyses done using methods like ANOVA, and multilevel or (increasingly) linear mixed-effects models (Meteyard & Davies, 2020).\nIn research on the reproducibility of results in the literature (see Section 4.2.6.3), the researchers attempting to reproduce results often focused on answering the research question the original authors stated using the data the original authors shared. This does not mean that they always tried to exactly reproduce an analysis or an analysis result. Sometimes, that was not possible.\nSometimes, you will encounter an article and a data-set you are interested in but the analysis presented in the article looks a bit complicated, or more complex than the methods you have learned would allow you to do. In this situation, don’t give up.\nWhat you can do – maybe with our advice – is identify a part of the primary result that you can try to reproduce. For example, what if the original study authors report a linear mixed-effects analysis of the effects of both prime relatedness and schizotypy score on response reaction time (Rodríguez-Ferreiro et al., 2020)? Maybe you have not learned about mixed-effects models, or you have not learned about analysing the effects of two variables but you have (you will) learn about analysing the effect of one variable using the linear model method: OK then, do an analysis of the shared data using the method you know.\nYou may be helped, here, by knowing about two good-enough (mostly true) insights from statistical analysis:\n\nMany of the common analysis methods you see used in psychological science can be coded as a linear model.\nMore advanced common analysis methods — (Generalized) Linear Mixed-effects Models (GLMMs) — can be understood as more sophisticated versions of the linear model. (Conversely, the linear model can be understood as an approximation of a GLMM.)\n\nThere is a nice discussion of the idea that common statistical tests are linear models here.\n\n\n\n\n\n\nTip\n\n\n\n\nIdentify the analysis method used to get the result you are interested in.\nIf it is complex or unfamiliar, discuss whether a simpler method can be used.\nIf the result is complex, discuss whether you can attempt to reproduce a part or a simpler result.\n\n\n\n\n\n6.2.2.2 Completing an alternate analysis of the data\nAre you interested in attempting a different analysis than the analysis you see in the journal article?\nIt can be interesting and important work to complete a simpler analysis of shared data. Sometimes, we learn that a simpler analysis provides a good account of the behaviour we observe, perhaps as good an account as that produced using other, more complex, analyses. This can happen if, for example, our theory predicts that two effects should work together but an analysis shows that we can explain behaviour in an account in which the two effects are independent. For example, Ricketts et al. (2021) predicted that children should learn words more effectively if they were shown the spellings of the words and they were told they would be helped by seeing the spelling but, in our data, we found that just seeing the spellings was enough to explain the learning we observed.\nIn completing analyses that vary from original analyses, we are engaging in the kind of work people do when they do multiverse analyses or robustness checks (see Section 4.2.4).\n\n\n\n\n\n\nTip\n\n\n\nIn planning an alternate or multiverse analysis, do not suppose that you need to do multiple analyses: you do not.\n\n\nIn planning an alternate or multiverse analysis, you will want to begin by critically evaluating the analysis you see described in the published article. I talk about how to do this, next.\nBefore we go on, note that I previously discussed an example of how to critically evaluate the results of published research in the context of Rodríguez-Ferreiro et al. (2020). Take a look at the Introduction of that article. There, we summarised the analyses researchers did previously and used the information about the analyses to explain inconsistencies in the research literature. We found limitations in the analyses that people did that had (negative) consequences for the strength of the conclusions we can take from the data.\n\n6.2.2.2.1 Critically evaluate the analysis description\nIf you revisit our discussion of multiverse analyses, you will see that we discussed two things: (1.) analyses of the impact on results of varying how you construct data-sets for analysis (Section 4.2.4.2) and (2.) analyses of the impact on results of varying what analysis method you use, or how you use the method (see Section 4.2.4.3). These are both good ways to approach thinking about the description of the analysis you see in a published article.\nAs we noted in Section 4.2.4.2, you almost always have to process the data you collect (in an experiment or a survey) before you can analyse the data. Often, this means you need to code for responses to survey questions e.g. asking people to self-report their gender, or you need to identify and code for people making errors when they try to do the experimental task you set them, or you need to process the data to exclude participants who took too long to do the task (if taking too long is a problem). Not all of these processing steps will have an impact on the results but some might. This is why you can sometimes do useful and sometimes original research work in reanalysing previously published data.\nYou can begin your analysis planning work by first identifying exactly what data processing the original study authors did then identifying what different data processing they could have done. Remember the research we discussed in relation to reproducibility studies, you need to be prepared for the possibility that it is challenging to identify what researchers did to process their data for analysis Section 4.2.6.3.1. To identify the information you need, look for keywords like code, exclude, process, tidy, transform in the text of the article, or look for words like this in the documentation you find in the data repository.\nWhen you have identified this information, you can then consider three questions:\n\nWhat data processing steps were completed before analysis?\nWhat were the reasons given explaining why these processing steps were completed?\nWhat could happen to the results if different choices were made?\n\nWorking through these questions can then get you to a good plan for an analysis of the data. For example, a simple but useful analysis you can do is to check what happens to the results if you do an analysis with data from all the participants tested, if participants are excluded (for some reason) in the data processing step. Obviously, if the original study authors only share processed data (after exclusions), you cannot do this kind of work. Another simple but useful analysis you can do is to check what happens to the results if you change the coding of variables. Sometimes different coding of categorical variables (e.g., ethnicity) are reasonable. For example, you can ask: what happens if you analyse the impact of the variable given a different coding? (In case you are reading these notes and thinking about recoding a factor, there are some useful functions you can use; read about them here.)\n\n\n\n\n\n\nTip\n\n\n\n\nDo you want to check the impact of varying data processing choices: check, do you need and have access to the raw data? can you see how to recode variables?\n\n\n\nAs we noted in Section 4.2.4.3, when we consider how to answer a research question with a data-set, it is often possible to imagine multiple different analysis methods: reasonable alternatives. Most often, this is most clearly apparent when we are looking at an observational data-set or data collected given a cross-sectional study design.\nIn cross-sectional or observational studies, we typically are not manipulating experimental conditions, and we are often analysed data using some kind of linear model. We often collect data or have access to data on a number of different variables relevant to our interests. For example, in studies I have done on how people read (R. Davies et al., 2013; R. A. I. Davies et al., 2017), we wanted to know what factors would predict or influence how people do basic reading tasks like reading aloud. We collected information on many different kinds of word properties and on the attributes of the participants we tested. (Note: the papers are associated with data repositories in Supplementary Materials.) It is often an open question which variables should be included in a prediction model of the observed outcome (reading response reaction times). Therefore, if you are interested in a study like this, and can access usable data from the study, it will typically be true that you are able to sensibly motivate a different analysis of the study data using a different choice of variables.\nAs discussed in a number of interesting analyses over the years (e.g., Patel et al., 2015), researchers may be interested in the specific impact of one particular predictor variable (e.g., we may be interested in whether it is easier to read words we learned early in life), but will need to include in their analysis that variable plus other variables known to affect the outcome. In that situation, the effect of the variable of interest may appear to be different depending on what other variables are also analysed. This makes it interesting and useful to check the impact of different analysis choices.\nWe will look at data like these, for analyses involving the linear model, in our classes on this method.\n\n\n\n\n\n\nTip\n\n\n\n\nDo you want to check the impact of different analysis choices: check, do you need and have access to a choice of variables?\nCan you think of some reasons to justify using a different choice of variables in your analysis.\n\n\n\n\n\n\n\n6.2.3 Summary: working with data associated with a published analysis\nHere’s a quick summary of the advice we have discussed so far.\n\nAt the start of your work, you will need to (1.) locate then (2.) access data for analysis, and then you will need to (3.) check that the data are usable.\nOnce you have confirmed you have found interesting data you can use, you should plan your analysis.\nStudents do a variety of kinds of analysis. Whatever your interest, you first will want to first make sure you can identify exactly what the authors of the original study did, how they did it, and why they did it.\nIf you are interested in completing a reanalysis, attempting a methods reproducibility test (can you repeat a result, given shared data?) you will perhaps benefit from focusing on a result that is both substantive and straightforward.\nIf you are interested in doing an alternate or multiverse analysis, you can critically evaluate the data processing and the data analysis choices that the original study authors made. You can consider whether other choices would be appropriate, and might sensibly motivate a (limited) investigation of the impact of different analysis choices on the results.\n\nWhat if you access interesting data that were shared but that are not associated with a published analysis? We talk about that situation, next."
  },
  {
    "objectID": "how.html#sec-noanalysis",
    "href": "how.html#sec-noanalysis",
    "title": "6  How you can do it",
    "section": "6.3 Working with data that are not associated with a published analysis",
    "text": "6.3 Working with data that are not associated with a published analysis\nA number of data-sets have been published online with information about the data but with no analysis. You can look for data that may be interest you in a number of different places, now, but I would focus on one. I talk about that next. Then I offer some guidance on how you might approach analyzing such data Section 6.3.2.\n\n6.3.1 Looking for open data\nWicherts and colleagues set up the Journal of Open Psychology Data (JOPD) to make it easier for Psychologists to share experimental data. A link to the journal webpage is here) Usually, a data paper reports a study and provides a link to a downloadable data-set.\nSome data-sets that I have looked at in JOPD and other places include the following. I identify these examples because they present interesting, rich, and readily accessible data-sets that could be used in a variety of different kinds of analyses.\n\n6.3.1.1 Wicherts intelligence and personality data\nWicherts did what he recommended and put a large data-set online here\nYou can analyse these data in a number of different interesting ways. You can explore relationships between gender, intelligence and personality differences.\nThe data file and an explanatory document are located at the end of the article. Read the article, it’s worth your time. Wicherts reports:\n\nThe file includes data from our freshman-testing program called “Testweek” (Busato et al., 2000, Smits et al., 2011 and Wicherts and Vorst, 2010) in which 537 students (age: M = 21.0, SD = 4.3) took the Advanced Progressive Matrices ( Raven, Court, & Raven, 1996), a test of Arithmetic, a Number Series test, a Hidden Figures Test, a test of Vocabulary, a test of Verbal Analogies, and a Logical Reasoning test (Elshout, 1976).\nAlso included are data from a Dutch big five personality inventory (Elshout & Akkerman, 1975), the NEO-PI-R (Hoekstra, Ormel, & Fruyt, 1996), scales of social desirability and impression management (based on work by Paulhus, 1984 and Wicherts, 2002), sex of the participants, and grade point averages of the freshmen’s first trimester that may act as outcome variable.\n\n\n\n6.3.1.2 Smits personality data\nSmits and colleagues (including Wicherts) put an even larger data-set online at the Journal of Open Psychology Data here)\nYou will need to register to be able to download the data but the process is simple.\nThe Smits data-set includes Big-5 personality scores for several thousand individuals recorded over a series of years. You can analyse these data in interesting ways including examining changes in personality scores among students over different years.\n\n\n6.3.1.3 Embodied terror management\nTjew A Sin and colleagues shared a data-set at the Journal of Open Psychology Data on an interesting study they did to test the idea that interpersonal touch or simulated interpersonal touch can relieve existential concerns (fear of death) among individuals with low self-esteem. The data can be found here)\nThe Tjew A Sin can be downloaded from a link to a repository location, given at the end of the article. You will likely need to register to download the data. Note that the spreadsheets holding the study data include 999 values to code for missing data. Note also that the data spreadsheets include (in different columns) scores per participant for various measures e.g. mortality anxiety or self-esteem. The measures are explained in the paper. To use the data, you will need to work out the simple process of how to sum the scores across items to get e.g. a measure of self-esteem for each person.\n\n\n6.3.1.4 Demographic influences on disgust\nBerger and Anaki shared data on the disgust sensitivity of a large sample of individuals. The data are from the administration of the Disgust Scale to a set of Hebrew speakers. They can be found here)\nThe experimenters collected data on participants’ characteristics so that analyses of the way in which sensitivity varies in relation to demographic attributes is possible. You will see that the disgust scale is explained in the paper. The different disgust scores, for each item in the disgust scale, can be found in different columns. The disgust scores, for person, are calculated overall as values: Mean_general_ds, Mean_core, Mean_Animal_reminder, Mean_Contamination\nWhen you download the data-set, you may need to change the file name — adding a suffix: .txt (for the tab delimited file), to be opened in Excel, or .sav (for the SPSS data file), to be opened in SPSS — to the file name to allow you to open it in the appropriate application.\n\n\n\n6.3.2 Thinking about analyses of open data\nThe availability of rich, curated, clearly usable data-sets with many variables can make it challenging to decide what to do.\nI would advise beginning with an exploratory analysis of the data you have accessed. You will want to begin by using the data visualization skills we have taught you to examine:\n\nThe distributions of the variables that interest you using histograms, density plots or bar charts.\nThe potential relationship between variables using scatterplots.\n\nIn such Exploratory Data analyses, you are interested in what the data visualization tells you about the nature of the data-set you have accessed. The papers associated with the data-sets can sometimes offer only outline information: how the data were collected, coded, and processed. You may need to satisfy yourself that there is nothing odd or surprising about the distributions of scores. This stage can help you to identify problems like survey responses with implausible scores.\nThe work you do in exploring, and summarizing, the data variables that interest you will often constitute a substantial element of the work you can do and present for your report. You may discuss, for advice, what parts of this work will be interesting or useful to present.\nThen, our advice is simple.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen working with open data-sets, consider keeping the analysis simple.\n\n\n\nNote that simple is relative. Do what interests you. Work with the methods you have learned or will learn (the linear model).\nIn practice, you will find that part of the challenge is located not in using the data or in running an analysis like a linear model, it is in (1.) justifying or motivating the analysis and (2.) explaining the implications of your findings.\nWorking on the thinking you must develop to motivate an analysis or to explain implications requires you to do some (limited) reading of relevant research. (Relevant sources will be cited in data papers, as part of their outline of the background for their data collection.) If you consider the advice we discussed in the graduate class on developing writing skills, you will see that there I talked about how you might extract data from a set of relevant sources (papers) to get an understanding of the questions people ask, the assumptions they make. That is the kind of process you can follow to develop your thinking around the analysis you will do. What you are looking for is information you can use so that you can say something brief about, for example, why it might be interesting to analyse, say, whether personality (measured using the Big-5) varies given differences in gender or differences between population cohorts. The reading and the conceptual development should be fairly limited, not extensive, but should be sufficient that you can write something sensible when you introduce and then when you discuss your analysis results."
  },
  {
    "objectID": "how.html#sec-how-summary",
    "href": "how.html#sec-how-summary",
    "title": "6  How you can do it",
    "section": "6.4 Summary: how",
    "text": "6.4 Summary: how\nIn this chapter, I have outlined some advice on how you might approach the task of locating, accessing, and analyzing previously collected data.\n\n\n\n\n\n\nTip\n\n\n\nThe main advice is to think about your workflow in stages, then progress through the work one step at a time.\n\n\nYou will need to begin by assuring yourself that you can find a data-set that interests you, and that you can access and use the data. The usability of data will require clear, understandable, descriptions in the published article (if any) about the research question and hypothesis, the study design, the data collection methods, the data processing steps, and the data analysis (if any). Sometimes, useful information about data processing and data analysis can be found in detail in repository documentation (e.g., in guides to materials) but only referenced in the text of the article.\nIf you know you can locate, access and have checked data as usable, you will want to think about what analysis you want to do the data. The approach you take depending on what aims you would like to pursue.\nIf you are interested in attempting a methods reproducibility test (i.e. checking if you can repeat presented results, given shared data), then you will first need to identify a substantive and straightforward result to try to reproduce. If you identify a primary result to examine, you will want to check that you can work with the data that have been shared, and then that you can use the analysis methods you have learned to reproduce some or all of the result that interests you.\nIf you are interested in doing an alternate or a different analysis (from what may be presented), you may need to consider the information you can locate on data processing and on data analysis choices. Did the original study authors process the data before sharing it, how? are the raw data available? What analyses did the authors do and why? When you consider this information, you may critically evaluate the choices made. In the context of this critical evaluation, you may find good reasons to justify doing a different analysis, whether to examine the impact of making different data processing choices, or to examine the impact of using a different analysis method, or of applying the same method differently (e.g., by including different variables).\nIn considering an analysis of data shared without a published set of results, you may want to keep your approach simple. Focus on what analysis you can do using the methods you have learned. And think about the understanding you will need to develop, to justify the analysis you do, and to make sense, in the discussion of your report of the analysis results you will present.\nIt is always a good idea to explore your data using visualization techniques throughout your workflow.\n\n\n\n\n\n\nTip\n\n\n\n\nYou can always get advice, do not hesitate to ask.\nWe are happy to discuss your thinking, especially in class.\n\n\n\n\n\n\n\nBrosowsky, N., Parshina, O., Locicero, A., & Crump, M. (n.d.). Teaching undergraduate students to read empirical articles: An evaluation and revision of the QALMRI method. https://doi.org/10.31234/osf.io/p39sc\n\n\nDavies, R. A. I., Birchenough, J. M. H., Arnell, R., Grimmond, D., & Houlson, S. (2017). Reading through the life span: Individual differences in psycholinguistic effects. Journal of Experimental Psychology: Learning Memory and Cognition, 43(8). https://doi.org/10.1037/xlm0000366\n\n\nDavies, R., Barbón, A., & Cuetos, F. (2013). Lexical and semantic age-of-acquisition effects on word naming in spanish. Memory and Cognition, 41(2), 297–311. https://doi.org/10.3758/s13421-012-0263-8\n\n\nHardwicke, T. E., Bohn, M., MacDonald, K., Hembacher, E., Nuijten, M. B., Peloquin, B. N., deMayo, B. E., Long, B., Yoon, E. J., & Frank, M. C. (n.d.). Analytic reproducibility in articles receiving open data badges at the journal psychological science: An observational study. Royal Society Open Science, 8(1), 201494. https://doi.org/10.1098/rsos.201494\n\n\nHardwicke, T. E., Mathur, M. B., MacDonald, K., Nilsonne, G., Banks, G. C., Kidwell, M. C., Hofelich Mohr, A., Clayton, E., Yoon, E. J., Henry Tessler, M., Lenne, R. L., Altman, S., Long, B., & Frank, M. C. (2018). Data availability, reusability, and analytic reproducibility: evaluating the impact of a mandatory open data policy at the journal Cognition. Royal Society Open Science, 5(8), 180448. https://doi.org/10.1098/rsos.180448\n\n\nKosslyn, S. M., & Rosenberg, R. S. (2005). Fundamentals of psychology: The brain, the person, the world, 2nd ed. Pearson Education New Zealand.\n\n\nMeteyard, L., & Davies, R. A. I. (2020). Best practice guidance for linear mixed-effects models in psychological science. Journal of Memory and Language, 112. https://doi.org/10.1016/j.jml.2020.104092\n\n\nMinocher, R., Atmaca, S., Bavero, C., McElreath, R., & Beheim, B. (n.d.). Estimating the reproducibility of social learning research published between 1955 and 2018. Royal Society Open Science, 8(9), 210450. https://doi.org/10.1098/rsos.210450\n\n\nPatel, C. J., Burford, B., & Ioannidis, J. P. A. (2015). Assessment of vibration of effects due to model specification can demonstrate the instability of observational associations. Journal of Clinical Epidemiology, 68(9), 1046–1058. https://doi.org/10.1016/j.jclinepi.2015.05.029\n\n\nRicketts, J., Dawson, N., & Davies, R. (2021). The hidden depths of new word knowledge: Using graded measures of orthographic and semantic learning to measure vocabulary acquisition. Learning and Instruction, 74, 101468. https://doi.org/10.1016/j.learninstruc.2021.101468\n\n\nRodríguez-Ferreiro, J., Aguilera, M., & Davies, R. (2020). Semantic priming and schizotypal personality: reassessing the link between thought disorder and enhanced spreading of semantic activation. PeerJ, 8, e9511. https://doi.org/10.7717/peerj.9511"
  },
  {
    "objectID": "knowledge-ecosystem.html",
    "href": "knowledge-ecosystem.html",
    "title": "7  The R knowledge ecosystem and how to help yourself",
    "section": "",
    "text": "Warning\n\n\n\nUnder construction"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Summary",
    "section": "",
    "text": "To complete when book is completed."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aarts, E., Dolan, C. V., Verhage, M., & Van der Sluis, S. (2015).\nMultilevel analysis quantifies variation in the experimental effect\nwhile optimizing power and preventing false positives. BMC\nNeuroscience, 16(1), 1–15. https://doi.org/10.1186/s12868-015-0228-5\n\n\nAczel, B., Szaszi, B., Nilsonne, G., Akker, O. R. van den, Albers, C.\nJ., Assen, M. A. van, Bastiaansen, J. A., Benjamin, D., Boehm, U.,\nBotvinik-Nezer, R., Bringmann, L. F., Busch, N. A., Caruyer, E.,\nCataldo, A. M., Cowan, N., Delios, A., Dongen, N. N. van, Donkin, C.,\nDoorn, J. B. van, … Wagenmakers, E.-J. (2021). Consensus-based guidance\nfor conducting and reporting multi-analyst studies. eLife,\n10, e72185. https://doi.org/10.7554/eLife.72185\n\n\nArtner, R., Verliefde, T., Steegen, S., Gomes, S., Traets, F.,\nTuerlinckx, F., & Vanpaemel, W. (2021). The reproducibility of\nstatistical results in psychological research: An investigation using\nunpublished raw data. Psychological Methods, 26(5),\n527–546. https://doi.org/10.1037/met0000365\n\n\nAuspurg, K., & Brüderl, J. (2021). Has the Credibility of the Social\nSciences Been Credibly Destroyed? Reanalyzing the “Many\nAnalysts, One Data Set” Project. Socius,\n7, 23780231211024421. https://doi.org/10.1177/23780231211024421\n\n\nBastiaansen, J. A., Kunkels, Y. K., Blaauw, F. J., Boker, S. M.,\nCeulemans, E., Chen, M., Chow, S.-M., Jonge, P. de, Emerencia, A. C.,\nEpskamp, S., Fisher, A. J., Hamaker, E. L., Kuppens, P., Lutz, W.,\nMeyer, M. J., Moulder, R., Oravecz, Z., Riese, H., Rubel, J., …\nBringmann, L. F. (2020). Time to get personal? The impact of researchers\nchoices on the selection of treatment targets using the experience\nsampling methodology. Journal of Psychosomatic Research,\n137, 110211. https://doi.org/10.1016/j.jpsychores.2020.110211\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting\nlinear mixed-effects models using lme4.\nJournal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBelenky, G., Wesensten, N. J., Thorne, D. R., Thomas, M. L., Sing, H.\nC., Redmond, D. P., Russo, M. B., & Balkin, T. J. (2003). Patterns\nof performance degradation and restoration during sleep restriction and\nsubsequent recovery: a sleep dose-response study. Journal of Sleep\nResearch, 12(1), 1–12. https://doi.org/10.1046/j.1365-2869.2003.00337.x\n\n\nBornstein, M. H., Jager, J., & Putnick, D. L. (2013). Sampling in\ndevelopmental science: Situations, shortcomings, solutions, and\nstandards. Developmental Review, 33(4), 357–370. https://doi.org/10.1016/j.dr.2013.08.003\n\n\nBotvinik-Nezer, R., Holzmeister, F., Camerer, C. F., Dreber, A., Huber,\nJ., Johannesson, M., Kirchler, M., Iwanir, R., Mumford, J. A., Adcock,\nR. A., Avesani, P., Baczkowski, B. M., Bajracharya, A., Bakst, L., Ball,\nS., Barilari, M., Bault, N., Beaton, D., Beitner, J., … Schonberg, T.\n(2020). Variability in the analysis of a single neuroimaging dataset by\nmany teams. Nature, 582(7810), 84–88. https://doi.org/10.1038/s41586-020-2314-9\n\n\nBourdieu, P. (2004). Science of Science and Reflexivity.\nPolity.\n\n\nBreznau, N., Rinke, E. M., Wuttke, A., Nguyen, H. H. V., Adem, M.,\nAdriaans, J., Alvarez-Benjumea, A., Andersen, H. K., Auer, D., Azevedo,\nF., Bahnsen, O., Balzer, D., Bauer, G., Bauer, P. C., Baumann, M.,\nBaute, S., Benoit, V., Bernauer, J., Berning, C., … Żółtak, T. (2022).\nObserving many researchers using the same data and hypothesis reveals a\nhidden universe of uncertainty. Proceedings of the National Academy\nof Sciences, 119(44), e2203150119. https://doi.org/10.1073/pnas.2203150119\n\n\nBrosowsky, N., Parshina, O., Locicero, A., & Crump, M. (n.d.).\nTeaching undergraduate students to read empirical articles: An\nevaluation and revision of the QALMRI method. https://doi.org/10.31234/osf.io/p39sc\n\n\nButton, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint,\nJ., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: Why\nsmall sample size undermines the reliability of neuroscience. Nature\nReviews Neuroscience, 14(5), 365–376.\n\n\nCarp, J. (2012a). On the plurality of (methodological) worlds:\nEstimating the analytic flexibility of FMRI experiments. Frontiers\nin Neuroscience, 6, 149.\n\n\nCarp, J. (2012b). The secret lives of experiments: Methods reporting in\nthe fMRI literature. Neuroimage, 63(1), 289–300.\n\n\nChang, W. (2013). R graphics cookbook. o’Reilly Media.\n\n\nCohen, J. (1962). The statistical power of abnormal-social psychological\nresearch: A review. Journal of Abnormal and Social Psychology,\n65(3), 145–153. https://doi.org/10.1037/h0045186\n\n\nCrüwell, S., Apthorp, D., Baker, B. J., Colling, L., Elson, M., Geiger,\nS. J., Lobentanzer, S., Monéger, J., Patterson, A., Schwarzkopf, D. S.,\nZaneva, M., & Brown, N. J. L. (n.d.). What’s in a\nbadge? A computational reproducibility investigation of the open data\nbadge policy in one issue of psychological science. https://doi.org/10.31234/osf.io/729qt\n\n\nDavies, R. A. I., Birchenough, J. M. H., Arnell, R., Grimmond, D., &\nHoulson, S. (2017). Reading through the life span: Individual\ndifferences in psycholinguistic effects. Journal of Experimental\nPsychology: Learning Memory and Cognition, 43(8). https://doi.org/10.1037/xlm0000366\n\n\nDavies, R., Barbón, A., & Cuetos, F. (2013). Lexical and semantic\nage-of-acquisition effects on word naming in spanish. Memory and\nCognition, 41(2), 297–311. https://doi.org/10.3758/s13421-012-0263-8\n\n\nDel Giudice, M., & Gangestad, S. W. (2021). A\nTraveler’s Guide to the Multiverse: Promises, Pitfalls, and\na Framework for the Evaluation of Analytic Decisions. Advances in\nMethods and Practices in Psychological Science, 4(1),\n2515245920954925. https://doi.org/10.1177/2515245920954925\n\n\nDutilh, G., Annis, J., Brown, S. D., Cassey, P., Evans, N. J., Grasman,\nR. P. P. P., Hawkins, G. E., Heathcote, A., Holmes, W. R., Krypotos,\nA.-M., Kupitz, C. N., Leite, F. P., Lerche, V., Lin, Y.-S., Logan, G.\nD., Palmeri, T. J., Starns, J. J., Trueblood, J. S., Maanen, L. van, …\nDonkin, C. (2019). The Quality of Response Time Data Inference: A\nBlinded, Collaborative Assessment of the Validity of Cognitive Models.\nPsychonomic Bulletin & Review, 26(4), 1051–1069.\nhttps://doi.org/10.3758/s13423-017-1417-2\n\n\nFederer, L. M. (2022). Long-term availability of data associated with\narticles in PLOS ONE. PLOS ONE, 17(8), e0272845. https://doi.org/10.1371/journal.pone.0272845\n\n\nFillard, P., Descoteaux, M., Goh, A., Gouttard, S., Jeurissen, B.,\nMalcolm, J., Ramirez-Manzanares, A., Reisert, M., Sakaie, K., Tensaouti,\nF., Yo, T., Mangin, J.-F., & Poupon, C. (2011). Quantitative\nevaluation of 10 tractography algorithms on a realistic diffusion MR\nphantom. NeuroImage, 56(1), 220–234. https://doi.org/10.1016/j.neuroimage.2011.01.032\n\n\nFlake, J. K., & Fried, E. I. (2020). Measurement Schmeasurement:\nQuestionable Measurement Practices and How to Avoid Them. Advances\nin Methods and Practices in Psychological Science, 3(4),\n456–465. https://doi.org/10.1177/2515245920952393\n\n\nFranconeri, S. L., Padilla, L. M., Shah, P., Zacks, J. M., &\nHullman, J. (2021). The Science of Visual Data Communication: What\nWorks. Psychological Science in the Public Interest,\n22(3), 110–161. https://doi.org/10.1177/15291006211051956\n\n\nGabelica, M., Bojčić, R., & Puljak, L. (2022). Many researchers were\nnot compliant with their published data sharing statement: a\nmixed-methods study. Journal of Clinical Epidemiology,\n150, 33–41. https://doi.org/10.1016/j.jclinepi.2022.05.019\n\n\nGelman, a. (2015). The connection between varying treatment effects and\nthe crisis of unreplicable research: A bayesian perspective. Journal\nof Management, 41(2), 632–643. https://doi.org/10.1177/0149206314525208\n\n\nGelman, A., & Loken, E. (2014a). The garden of forking paths: Why\nmultiple comparisons can be a problem, even when there is no\n“fishing expedition” or\n“p-hacking” and the research hypothesis was\nposited ahead of time. Psychological Bulletin, 140(5),\n1272–1280.\n\n\nGelman, A., & Loken, E. (2014b). The statistical crisis in science.\nAmerican Scientist, 102(6), 460–465. https://doi.org/10.1511/2014.111.460\n\n\nGelman, A., & Unwin, A. (2013). Infovis and Statistical Graphics:\nDifferent Goals, Different Looks. Journal of Computational and\nGraphical Statistics, 22(1), 2–28. https://doi.org/10.1080/10618600.2012.761137\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power.\nAmerican Scientist, 97(4), 310–316. https://doi.org/10.1511/2009.79.310\n\n\nGilmore, R. O., Diaz, M. T., Wyble, B. A., & Yarkoni, T. (2017).\nProgress toward openness, transparency, and reproducibility in cognitive\nneuroscience. Annals of the New York Academy of Sciences,\n1396, 5–18. https://doi.org/10.1111/nyas.13325\n\n\nGoodman, S. N., Fanelli, D., & Ioannidis, J. P. A. (2016). What does\nresearch reproducibility mean? Science Translational Medicine,\n8(341).\n\n\nHardwicke, T. E., Bohn, M., MacDonald, K., Hembacher, E., Nuijten, M.\nB., Peloquin, B. N., deMayo, B. E., Long, B., Yoon, E. J., & Frank,\nM. C. (n.d.). Analytic reproducibility in articles receiving open data\nbadges at the journal psychological science: An observational study.\nRoyal Society Open Science, 8(1), 201494. https://doi.org/10.1098/rsos.201494\n\n\nHardwicke, T. E., Mathur, M. B., MacDonald, K., Nilsonne, G., Banks, G.\nC., Kidwell, M. C., Hofelich Mohr, A., Clayton, E., Yoon, E. J., Henry\nTessler, M., Lenne, R. L., Altman, S., Long, B., & Frank, M. C.\n(2018). Data availability, reusability, and analytic reproducibility:\nevaluating the impact of a mandatory open data policy at the journal\nCognition. Royal Society Open Science, 5(8), 180448.\nhttps://doi.org/10.1098/rsos.180448\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010). The weirdest\npeople in the world? The Behavioral and Brain Sciences,\n33(2-3). https://doi.org/10.1017/S0140525X0999152X\n\n\nHerndon, T., Ash, M., & Pollin, R. (2014). Does high public debt\nconsistently stifle economic growth? A critique of Reinhart and Rogoff.\nCambridge Journal of Economics, 38(2), 257–279. https://doi.org/10.1093/cje/bet075\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157–1164.\nhttps://doi.org/10.3758/s13423-013-0572-3\n\n\nHoffmann, S., Schönbrodt, F., Elsas, R., Wilson, R., Strasser, U., &\nBoulesteix, A.-L. (n.d.). The multiplicity of analysis strategies\njeopardizes replicability: Lessons learned across disciplines. Royal\nSociety Open Science, 8(4), 201925. https://doi.org/10.1098/rsos.201925\n\n\nIoannidis, J. P. a. (2005). Why most published research findings are\nfalse. PLoS Medicine, 2(8), 0696–0701. https://doi.org/10.1371/journal.pmed.0020124\n\n\nJohn, L. K., Loewenstein, G., & Prelec, D. (2012). Measuring the\nprevalence of questionable research practices with incentives for truth\ntelling. Psychological Science, 23(5), 524–532. https://doi.org/10.1177/0956797611430953\n\n\nKidwell, M. C., Lazarević, L. B., Baranski, E., Hardwicke, T. E.,\nPiechowski, S., Falkenberg, L. S., Kennett, C., Slowik, A., Sonnleitner,\nC., Hess-Holden, C., Errington, T. M., Fiedler, S., & Nosek, B. A.\n(2016). Badges to acknowledge open practices: A simple, low-cost,\neffective method for increasing transparency. PLoS Biology,\n14(5), 1–15. https://doi.org/10.1371/journal.pbio.1002456\n\n\nKlau, S., Hoffmann, S., Patel, C. J., Ioannidis, J. P., &\nBoulesteix, A.-L. (2021). Examining the robustness of observational\nassociations to model, measurement and sampling uncertainty with the\nvibration of effects framework. International Journal of\nEpidemiology, 50(1), 266–278. https://doi.org/10.1093/ije/dyaa164\n\n\nKlau, S., Schönbrodt, F., Patel, C. J., Ioannidis, J., Boulesteix,\nA.-L., & Hoffmann, S. (n.d.). Comparing the vibration of effects\ndue to model, data pre-processing and sampling uncertainty on a large\ndata set in personality psychology. https://doi.org/10.31234/osf.io/c7v8b\n\n\nKosslyn, S. M., & Rosenberg, R. S. (2005). Fundamentals of\npsychology: The brain, the person, the world, 2nd ed. Pearson\nEducation New Zealand.\n\n\nKuhn, T. S. (1970). The structure of scientific revolutions\n([2d ed., enl). University of Chicago Press.\n\n\nLandy, J. F., Jia, M. L., Ding, I. L., Viganola, D., Tierney, W.,\nDreber, A., Johannesson, M., Pfeiffer, T., Ebersole, C. R., Gronau, Q.\nF., Ly, A., Bergh, D. van den, Marsman, M., Derks, K., Wagenmakers,\nE.-J., Proctor, A., Bartels, D. M., Bauman, C. W., Brady, W. J., …\nUhlmann, E. L. (2020). Crowdsourcing hypothesis tests: Making\ntransparent how design choices shape research results. Psychological\nBulletin, 146(5), 451–479. https://doi.org/10.1037/bul0000220\n\n\nLaurinavichyute, A., Yadav, H., & Vasishth, S. (2022). Share the\ncode, not just the data: A case study of the reproducibility of articles\npublished in the Journal of Memory and Language under the open data\npolicy. Journal of Memory and Language, 125, 104332.\nhttps://doi.org/10.1016/j.jml.2022.104332\n\n\nLubega, N., Anderson, A., & Nelson, N. (n.d.). Experience of\nirreproducibility as a risk factor for poor mental health in biomedical\nscience doctoral students: A survey and interview-based study. https://doi.org/10.31222/osf.io/h37kw\n\n\nMaier-Hein, K. H., Neher, P. F., Houde, J.-C., Côté, M.-A.,\nGaryfallidis, E., Zhong, J., Chamberland, M., Yeh, F.-C., Lin, Y.-C.,\nJi, Q., Reddick, W. E., Glass, J. O., Chen, D. Q., Feng, Y., Gao, C.,\nWu, Y., Ma, J., He, R., Li, Q., … Descoteaux, M. (2017). The challenge\nof mapping the human connectome based on diffusion tractography.\nNature Communications, 8(1), 1349. https://doi.org/10.1038/s41467-017-01285-x\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A\nmethodological paradox. Philosophy of Science, 34(2),\n103–115.\n\n\nMeehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir\nkarl, sir ronald, and the slow progress of soft psychology.\n46(September 1976), 806–834.\n\n\nMeteyard, L., & Davies, R. A. I. (2020). Best practice guidance for\nlinear mixed-effects models in psychological science. Journal of\nMemory and Language, 112. https://doi.org/10.1016/j.jml.2020.104092\n\n\nMinocher, R., Atmaca, S., Bavero, C., McElreath, R., & Beheim, B.\n(n.d.). Estimating the reproducibility of social learning research\npublished between 1955 and 2018. Royal Society Open Science,\n8(9), 210450. https://doi.org/10.1098/rsos.210450\n\n\nMunafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers,\nC. D., Percie Du Sert, N., Simonsohn, U., Wagenmakers, E. J., Ware, J.\nJ., & Ioannidis, J. P. A. (2017). A manifesto for reproducible\nscience. Nature Human Behaviour, 1(1), 1–9. https://doi.org/10.1038/s41562-016-0021\n\n\nNosek, B. A., Beck, E. D., Campbell, L., Flake, J. K., Hardwicke, T. E.,\nMellor, D. T., van?t Veer, A. E., & Vazire, S. (2019).\nPreregistration is hard, and worthwhile. Trends in Cognitive\nSciences, 23(10), 815–818.\n\n\nNosek, B. A., Ebersole, C. R., DeHaven, A. C., & Mellor, D. T.\n(2018). The preregistration revolution. Proceedings of the National\nAcademy of Sciences, 115(11), 2600–2606.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S.,\nDreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B.,\nRohrer, J. M., Romero, F., Scheel, A. M., Scherer, L. D., Schönbrodt, F.\nD., & Vazire, S. (2022). Replicability, Robustness, and\nReproducibility in Psychological Science. Annual Review of\nPsychology, 73, 719–748. https://doi.org/10.1146/annurev-psych-020821-114157\n\n\nNosek, B. A., & Lakens, D. (2014). Registered reports: A method to\nincrease the credibility of published results. Social\nPsychology, 45(3), 137–141. https://doi.org/10.1027/1864-9335/a000192\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A.\n(2020). Analysis of open data and computational reproducibility in\nregistered reports in psychology. Advances in Methods and Practices\nin Psychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nParsons, S. (n.d.). Exploring reliability heterogeneity with\nmultiverse analyses: Data processing decisions unpredictably influence\nmeasurement reliability. https://doi.org/10.31234/osf.io/y6tcz\n\n\nPashler, H., & Harris, C. (2012). Is the replicability crisis\noverblown? Three arguments examined. Perspectives on Psychological\nScience, 7(6), 531–536. https://doi.org/10.1177/1745691612463401\n\n\nPashler, H., & Wagenmakers, E. J. (2012). Editors’ introduction to\nthe special section on replicability in psychological science: A crisis\nof confidence? Perspectives on Psychological Science,\n7(6), 528–530. https://doi.org/10.1177/1745691612465253\n\n\nPatel, C. J., Burford, B., & Ioannidis, J. P. A. (2015). Assessment\nof vibration of effects due to model specification can demonstrate the\ninstability of observational associations. Journal of Clinical\nEpidemiology, 68(9), 1046–1058. https://doi.org/10.1016/j.jclinepi.2015.05.029\n\n\nPinheiro, J. C., & Bates, D. M. (2000). Mixed-effects models in\ns and s-plus (statistics and computing). Springer.\n\n\nPoline, J.-B., Strother, S. C., Dehaene-Lambertz, G., Egan, G. F., &\nLancaster, J. L. (2006). Motivation and synthesis of the FIAC\nexperiment: Reproducibility of fMRI results across expert analyses.\nHuman Brain Mapping, 27(5), 351–359. https://doi.org/10.1002/hbm.20268\n\n\nRicketts, J., Dawson, N., & Davies, R. (2021). The hidden depths of\nnew word knowledge: Using graded measures of orthographic and semantic\nlearning to measure vocabulary acquisition. Learning and\nInstruction, 74, 101468. https://doi.org/10.1016/j.learninstruc.2021.101468\n\n\nRoche, D. G., Kruuk, L. E. B., Lanfear, R., & Binning, S. A. (2015).\nPublic data archiving in ecology and evolution: How well are we doing?\nPLoS Biology, 13(11), 1–12. https://doi.org/10.1371/journal.pbio.1002295\n\n\nRodríguez-Ferreiro, J., Aguilera, M., & Davies, R. (2020). Semantic\npriming and schizotypal personality: reassessing the link between\nthought disorder and enhanced spreading of semantic activation.\nPeerJ, 8, e9511. https://doi.org/10.7717/peerj.9511\n\n\nSalganik, M. J., Lundberg, I., Kindel, A. T., Ahearn, C. E., Al-Ghoneim,\nK., Almaatouq, A., Altschul, D. M., Brand, J. E., Carnegie, N. B.,\nCompton, R. J., Datta, D., Davidson, T., Filippova, A., Gilroy, C.,\nGoode, B. J., Jahani, E., Kashyap, R., Kirchner, A., McKay, S., …\nMcLanahan, S. (2020). Measuring the predictability of life outcomes with\na scientific mass collaboration. Proceedings of the National Academy\nof Sciences, 117(15), 8398–8403. https://doi.org/10.1073/pnas.1915006117\n\n\nScheel, A. M. (2022). Why most psychological research findings are not\neven wrong. Infant and Child Development, 31(1),\ne2295. https://doi.org/10.1002/icd.2295\n\n\nScheel, A. M., Tiokhin, L., Isager, P. M., & Lakens, D. (2021). Why\nHypothesis Testers Should Spend Less Time Testing Hypotheses.\nPerspectives on Psychological Science, 16(4), 744–755.\nhttps://doi.org/10.1177/1745691620966795\n\n\nSchweinsberg, M., Feldman, M., Staub, N., Akker, O. R. van den, Aert, R.\nC. M. van, Assen, M. A. L. M. van, Liu, Y., Althoff, T., Heer, J., Kale,\nA., Mohamed, Z., Amireh, H., Venkatesh Prasad, V., Bernstein, A.,\nRobinson, E., Snellman, K., Amy Sommer, S., Otner, S. M. G., Robinson,\nD., … Luis Uhlmann, E. (2021). Same data, different conclusions: Radical\ndispersion in empirical results when independent analysts operationalize\nand test the same hypothesis. Organizational Behavior and Human\nDecision Processes, 165, 228–249. https://doi.org/10.1016/j.obhdp.2021.02.003\n\n\nSedlmeier, P., & Gigerenzer, G. (1989). Statistical power studies.\nPsychological Bulletin, 105(2), 309–316.\n\n\nSilberzahn, R., & Uhlmann, E. L. (2015). Crowdsourced research: Many\nhands make tight work. Nature, 526(7572), 189–191. https://doi.org/10.1038/526189a\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F.,\nAwtrey, E., Bahník, Š., Bai, F., Bannard, C., Bonnier, E., Carlsson, R.,\nCheung, F., Christensen, G., Clay, R., Craig, M., Dalla Rosa, A., Dam,\nL., Evans, M., Flores Cervantes, I., … Nosek, B. (2017). Many analysts,\none dataset: Making transparent how variations in analytical choices\naffect results. Advances in Methods and Practices in Psychological\nScience. https://doi.org/10.31234/osf.io/qkwst\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011a).\nFalse-positive psychology: Undisclosed flexibility in data collection\nand analysis allows presenting anything as significant.\nPsychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011b).\nFalse-positive psychology: Undisclosed flexibility in data collection\nand analysis allows presenting anything as significant.\nPsychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nStarns, J. J., Cataldo, A. M., Rotello, C. M., Annis, J., Aschenbrenner,\nA., Bröder, A., Cox, G., Criss, A., Curl, R. A., Dobbins, I. G., Dunn,\nJ., Enam, T., Evans, N. J., Farrell, S., Fraundorf, S. H., Gronlund, S.\nD., Heathcote, A., Heck, D. W., Hicks, J. L., … Wilson, J. (2019).\nAssessing Theoretical Conclusions With Blinded Inference to Investigate\na Potential Inference Crisis. Advances in Methods and Practices in\nPsychological Science, 2(4), 335–349. https://doi.org/10.1177/2515245919869583\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016a).\nIncreasing transparency through a multiverse analysis. Perspectives\non Psychological Science, 11(5), 702–712.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016b).\nIncreasing transparency through a multiverse analysis. Perspectives\non Psychological Science, 11(5), 702–712.\n\n\nTedersoo, L., Küngas, R., Oras, E., Köster, K., Eenmaa, H., Leijen, Ä.,\nPedaste, M., Raju, M., Astapova, A., Lukner, H., Kogermann, K., &\nSepp, T. (2021). Data sharing practices and data availability upon\nrequest differ across scientific disciplines. Scientific Data,\n8(1), 192. https://doi.org/10.1038/s41597-021-00981-0\n\n\nTowse, J. N., Ellis, D. A., & Towse, A. S. (2021). Opening Pandora’s\nBox: Peeking inside Psychology’s data sharing practices, and seven\nrecommendations for change. Behavior Research Methods,\n53(4), 1455–1468. https://doi.org/10.3758/s13428-020-01486-1\n\n\nUlrich, R., & Miller, J. (1994). Effects of truncation on reaction\ntime analysis. Journal of Experimental Psychology: General,\n123, 34–80.\n\n\nVankov, I., Bowers, J., & Munafò, M. R. (2014). On the persistence\nof low power in psychological science. Quarterly Journal of\nExperimental Psychology, 67(5), 1037–1040. https://doi.org/10.1080/17470218.2014.885986\n\n\nVasishth, S., & Gelman, A. (2021). How to embrace variation and\naccept uncertainty in linguistic and psycholinguistic data analysis.\nLinguistics, 59(5), 1311–1342. https://doi.org/10.1515/ling-2019-0051\n\n\nVazire, S. (2018). Implications of the Credibility Revolution for\nProductivity, Creativity, and Progress. Perspectives on\nPsychological Science, 13(4), 411–417. https://doi.org/10.1177/1745691617751884\n\n\nWagenmakers, E.-J., Sarafoglou, A., & Aczel, B. (2022). One\nstatistical analysis must not rule them all. Nature,\n605(7910), 423–425. https://doi.org/10.1038/d41586-022-01332-8\n\n\nWagenmakers, E.-J., Wetzels, R., Borsboom, D., & Maas, H. L. J. van\nder. (2011). Why psychologists must change the way they analyze their\ndata: The case of psi: Comment on bem (2011). Journal of Personality\nand Social Psychology, 100(3), 426–432. https://doi.org/10.1037/a0022790\n\n\nWessel, I., Albers, C., Zandstra, A. R. E., & Heininga, V. E.\n(2020). A multiverse analysis of early attempts to replicate memory\nsuppression with the think/no-think task.\n\n\nWicherts, J. M., Borsboom, D., Kats, J., & Molenaar, D. (2006). The\npoor availability of psychological research data for reanalysis.\nAmerican Psychologist, 61(7), 726–728. https://doi.org/10.1037/0003-066X.61.7.726\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data\nanalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2017). Tidyverse: Easily install and load the\n’tidyverse’. https://cran.r-project.org/package=tidyverse\n\n\nWickham, H., & Grolemund, G. (2016). R for data science: Import,\ntidy, transform, visualize, and model data. \" O’Reilly\nMedia, Inc.\".\n\n\nWild, H., Kyröläinen, A.-J., & Kuperman, V. (2022). How\nrepresentative are student convenience samples? A study of literacy and\nnumeracy skills in 32 countries. PLOS ONE, 17(7),\ne0271191. https://doi.org/10.1371/journal.pone.0271191\n\n\nWilke, C. O. (n.d.). Fundamentals of data visualization. https://clauswilke.com/dataviz/\n\n\nWilkinson, L. (2013). The Grammar of Graphics. Springer Science\n& Business Media.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and\nBrain Sciences, 45, e1. https://doi.org/10.1017/S0140525X20001685\n\n\nYoung, C. (2018). Model uncertainty and the crisis in science.\nSocius, 4, 2378023117737206.\n\n\nYoung, C., & Holsteen, K. (2017). Model Uncertainty and Robustness:\nA Computational Framework for Multimodel Analysis. Sociological\nMethods & Research, 46(1), 3–40. https://doi.org/10.1177/0049124115610347"
  },
  {
    "objectID": "report-preface.html#sec-report-intro-chapters",
    "href": "report-preface.html#sec-report-intro-chapters",
    "title": "3  The research report assignment: Outline introduction",
    "section": "3.1 Chapters with information on why, what and how",
    "text": "3.1 Chapters with information on why, what and how\nWe have written a series of chapters to support your learning in depth. The chapters are oriented around our answers to three questions that students might ask themselves.\n\nWhy: what will you learn about, what is our motivation?\nWhat do we expect students to do?\nHow can the assignment be done?\n\nYou can read the chapters in whatever order you like.\nSome may wish to start with our information on what we expect students to do in Chapter 4 and on how the work can be done in Chapter 5. It may then be useful to come back to our information on the context and the motivations for the exercise in Chapter 4. Of course, you can also start with our explanation for the motivations."
  },
  {
    "objectID": "report-preface.html#sec-report-intro-lecture",
    "href": "report-preface.html#sec-report-intro-lecture",
    "title": "3  The research report assignment: Outline introduction",
    "section": "3.2 Lecture recordings",
    "text": "3.2 Lecture recordings\nThe lecture material is presented in three short parts.\n\n3.2.1 Lecture recordings\nClick on a link and your browser should open a tab showing the Panopto video for the lecture part. You should be able to access the videos anywhere; you should not need to be on campus or logged on to the university VPN to view the videos.\nPart 1 of 3; about 15 minutes\nPart 2 of 3; about 20 minutes\nPart 3 of 3; about 20 minutes\n\n\n3.2.2 Lecture recordings\nYou can download the lecture slides in two different forms.\n\nYou can download the slides as a .html file: 401-research-report.html. This can be opened in a browser and presents the slides as they are delivered.\nYou can download the slides as a Word .docx file: 401-research-report-printable.docx. This can be opened in Microsoft Word. You can edit the file to write your own notes. And you can print the document.\n\nThere will be some slight variation in how the images appear in the .html and .docx versions. This is because I wrote the slides in {Quarto}, in R-Studio, and {Quarto} is designed to render natively to .html (so that images look nice in a browser)."
  },
  {
    "objectID": "hypotheses-associations.html",
    "href": "hypotheses-associations.html",
    "title": "1  Hypotheses and associations",
    "section": "",
    "text": "Warning\n\n\n\nUnder construction"
  },
  {
    "objectID": "hypotheses-associations.html#sec-hypotheses-associations-intro",
    "href": "hypotheses-associations.html#sec-hypotheses-associations-intro",
    "title": "1  Hypotheses and associations",
    "section": "1.1 Overview",
    "text": "1.1 Overview\nWelcome to your overview of the materials and guidance you will work with in PSYC401 Week 16.\nWe will complete four classes in weeks 16-19. These classes are designed to help students to revise and put into practice some of the key ideas and skills you have been developing in the first year research methods modules PSYC121, PSYC123 and PSYC124.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly understood project.\nOur focus will be on what makes it easy or difficult for people to understand written health information. We encounter written health information all the time: in warnings signs, on medication labels, in clinics when we go to see the doctor, and online when we research things we are worried about. It is not always easy to understand this information. The problem is that it is unclear how health information should be communicated. As psychologists, we can help to improve health communication.\nIn these classes, we will complete a research project to answer the research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe will present our PSYC122 lessons in the context of this research project because we think that this context will help you to make sense of the data, and to see why we ask you to practice the skills we are teaching.\nWe will be revisiting some of the ideas and techniques you have seen introduced in previous classes. This is to give you the opportunity to revise and consolidate your learning. We will be extending your development with some new ideas, to strengthen your skills.\nUltimately, we aim to contribute new findings from the data we will collect together. These new findings will, we hope, help to make the provision of health advice a bit more useful in future."
  },
  {
    "objectID": "hypotheses-associations.html#our-learning-goals",
    "href": "hypotheses-associations.html#our-learning-goals",
    "title": "1  Hypotheses and associations",
    "section": "1.2 Our learning goals",
    "text": "1.2 Our learning goals\nIn Week 16, we will ask you to do two things.\nFirst, we will ask you to do a pre-lab activity that involves completing a survey. Completing the survey will help you to make sense of the numbers you will be working with in the activities. Completing the pre-lab activity will help to teach you about the challenges of measurement, a key aspect of the scientific thinking skills we will help you grow:\n\nScientific thinking: from concerns to questions to results and critical evaluation\n\nSecond, we wil ask you to do a set of practical tasks in the lab activity that are designed to consolidate your learning on data visualization. We will focus on the visualization of data distributions. We will be:\n\nUsing histograms to examine the distributions of variables;\nAnd learning to edit the histograms so they are more effective.\n\n\n\n\n\n\nHow-to guide example of a histogram showing observed mean accuracy of understanding of health information"
  },
  {
    "objectID": "hypotheses-associations.html#resources-for-you",
    "href": "hypotheses-associations.html#resources-for-you",
    "title": "1  Hypotheses and associations",
    "section": "1.3 Resources for you",
    "text": "1.3 Resources for you\nYou will see – below – links to the lectures, information about the data we will analyze, and an explanation of the activities.\nAll the links to the lectures, and everything you need for your practical work class can also be found in the Week 16 files folder on Moodle, here:\nLink to Moodle"
  },
  {
    "objectID": "hypotheses-associations.html#lectures-video-recordings",
    "href": "hypotheses-associations.html#lectures-video-recordings",
    "title": "1  Hypotheses and associations",
    "section": "1.4 Lectures: video recordings",
    "text": "1.4 Lectures: video recordings\nThe lecture material for this week is presented in three parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part. (You will need to be on campus or logged in to the university VPN to get access to the videos.)\nPart 1 of 3\nPart 2 of 3\nPart 3 of 3"
  },
  {
    "objectID": "hypotheses-associations.html#readings",
    "href": "hypotheses-associations.html#readings",
    "title": "1  Hypotheses and associations",
    "section": "1.5 Readings",
    "text": "1.5 Readings\nWe do not provide further reading but you may find it helpful to take another look at the readings provided, previously, for your classes in weeks 11-13."
  },
  {
    "objectID": "hypotheses-associations.html#pre-lab-activity-1",
    "href": "hypotheses-associations.html#pre-lab-activity-1",
    "title": "1  Hypotheses and associations",
    "section": "1.6 Pre-lab activity 1",
    "text": "1.6 Pre-lab activity 1\nIn weeks 16-19, we will be working together on a research project to investigate how people vary in their response to health advice. Completing the project involves collecting responses from PSYC122 students. In our class activities, we can then analyze the data we collect.\nTo enter your responses, we invite you to complete a short survey. You can complete the survey here (just click on the web address to get started):\nComplete the survey\n\n1.6.1 Survey information\nThe survey asks you to:\n\ncomplete some questions about who you are;\nand then answer some questions about what you know about some English words, about what you know about health matters, and about how you approach reading.\n\nThe survey then asks you to:\n\nread five short extracts from patient information leaflets about different kinds of health issue;\nrespond to some multiple choice questions about each extract;\nand rate how well you think you understand the advice.\n\nThe survey should take about 20 minutes to complete. Some people will take less time, and some people might take a little more time.\nTaking part in the survey is completely voluntary. You can stop at any time without completing the survey if you do not want to finish it. If you do not want to do the survey, you can do an alternative activity (see below).\nAll responses will be recorded completely anonymously."
  },
  {
    "objectID": "hypotheses-associations.html#pre-lab-activity-1-alternative",
    "href": "hypotheses-associations.html#pre-lab-activity-1-alternative",
    "title": "1  Hypotheses and associations",
    "section": "1.7 Pre-lab activity 1 alternative",
    "text": "1.7 Pre-lab activity 1 alternative\nIf you do not want to complete the survey, we invite you to read the pre-registered research plan for the PSYC122 health advice research project.\nRead the project pre-registration"
  },
  {
    "objectID": "hypotheses-associations.html#pre-lab-activity-2-getting-ready-for-the-lab-class",
    "href": "hypotheses-associations.html#pre-lab-activity-2-getting-ready-for-the-lab-class",
    "title": "1  Hypotheses and associations",
    "section": "1.4 Pre-lab activity 2: Getting ready for the lab class",
    "text": "1.4 Pre-lab activity 2: Getting ready for the lab class\n\n1.4.1 Get your files ready\nDownload the PSYC401_week6_materials.zip files you need and upload them to your RStudio Server.\nThe folder includes data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand code files:\n\n401-associations-how-to.R\n401-associations-workbook.R\n\nYou will use these files for your practical learning.\n\n\n1.4.2 Review the how-to guide\nWe show you how to do everything you need to do in the lab activity (see the next section) in the how-to guide.\nThe guide comprises an .R file 401-associations-how-to.R with code and advice. The code in the .R file was written to work with the data file study-one-general-participants.csv.\n\n\n\n\n\n\n1.4.3 Workbook\nIn the workbook .R file:\n\n401-associations-workbook.R\n\nyou will work with data from a study about how people respond to guidance about a variety of health topics (general topics)\n\nstudy-two-general-participants.csv\n\nIf you have not downloaded them already, the workbook .R file and the data .csv file can be downloaded from:\nPSYC401_week6_materials.zip\nOr you can download them from the module Moodle page for PSYC401\n\n1.4.3.1 What is in the workbook .R file?\nWe will take things step-by-step. We will split .R scripts into parts, tasks and questions:\n\ndifferent parts for different phases of the analysis workflow;\ndifferent tasks for different steps in each phase;\ndifferent questions to examine different ideas or coding steps.\n\n\n\n1.4.3.2 Tasks\nWe are going to work through the following tasks:\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\nChange the type classification of a variable in the data – using as.factor()\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\nDraw scatterplots to examine the association between pairs of variables – using ggplot() and geom_point()\nEstimate and test the correlations between pairs of variables – using cor.test()\n\nThe activity 401-associations-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check in the how-to guide: look at the advice in 401-associations-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the dataset or the variables to complete the tasks in the activity.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\n\n1.4.4 What is in the data files\nEach of the data files we will work with has a similar structure.\n\nhead(study.two.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;fct&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER &lt;fct&gt;, EDUCATION &lt;fct&gt;, ETHNICITY &lt;fct&gt;\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy varianble coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code"
  },
  {
    "objectID": "hypotheses-associations.html#lab-activity",
    "href": "hypotheses-associations.html#lab-activity",
    "title": "1  Hypotheses and associations",
    "section": "1.9 Lab activity",
    "text": "1.9 Lab activity\nIn the lab activity .R file 2021-22-PSYC122-w16-activity.R, you will work with data from a study about how people respond to guidance about a variety of health topics (general topics):\n\nstudy-two-general-participants.csv\n\nThe data are similar in format to the response data we are collecting as part of the PSYC122 project.\nThe activity .R file and the data .csv file can be downloaded from:\n122_week16_forStudents.zip\nOr you can download it from the module Moodle page for PSYC122:\nLink to Moodle\n\n1.9.1 What is in the activity .R file?\nWe will take things step-by-step. We will split .R scripts into parts, tasks and questions:\n\ndifferent parts for different phases of the analysis workflow;\ndifferent tasks for different steps in each phase;\ndifferent questions to examine different ideas or coding steps.\n\n\n\n1.9.2 Tasks\nIn the activity, we are going to work through the following tasks.\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\nChange the type classification of a variable in the data – using as.factor()\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\nEdit the appearance of one variable histogram plot step-by-step\n\nThe activity 2021-22-PSYC122-w16-activity.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check in the how-to guide: look at the advice in 2021-22-PSYC122-w16-how-to.R or watch the accompanying video.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the dataset or the variables to complete the tasks in the activity.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\n1.9.3 What is in the data files\nEach of the data files we will work with has a similar structure.\n\nhead(study.two.gen)\n\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  &lt;fct&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER &lt;fct&gt;, EDUCATION &lt;fct&gt;, ETHNICITY &lt;fct&gt;\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy varianble coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n1.9.4 Answers\nYou can download the answers version of the activity .R file 2021-22-PSYC122-w16-activity-answers.R\nThe answers version will present my answers for questions, and some extra information where that is helpful."
  },
  {
    "objectID": "hypotheses-associations.html#sec-associations-intro",
    "href": "hypotheses-associations.html#sec-associations-intro",
    "title": "1  Hypotheses and associations",
    "section": "1.1 Overview",
    "text": "1.1 Overview\nWelcome to your overview of the materials you will work with in PSYC401 Week 6. We will complete five classes in weeks 6-10. These classes are designed to help students to learn, consolidate and revise some core psychological data analysis methods. We will do this in the context of a live research project with potential real world impacts: the Clearly understood project.\nOur focus will be on what makes it easy or difficult for people to understand written health information. We encounter written health information all the time: in warnings signs, on medication labels, in clinics when we go to see the doctor, and online when we research things we are worried about. It is not always easy to understand this information. The problem is that it is unclear how health information should be communicated.\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nWe will present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data, and to see why we ask you to practice the skills we are teaching.\nWe will be revisiting some of the ideas and techniques you have seen introduced in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas, to strengthen your skills."
  },
  {
    "objectID": "hypotheses-associations.html#sec-associations-learning-goals",
    "href": "hypotheses-associations.html#sec-associations-learning-goals",
    "title": "1  Hypotheses and associations",
    "section": "1.2 Our learning goals",
    "text": "1.2 Our learning goals\n\n1.2.1 Learning targets for this week\n\nCritical thinking: hypotheses\n\n\nConcepts: begin with critical thinking\nSkills: developing hypotheses\n\n\nData analysis: associations\n\n\nConcepts – associations: correlations, estimates and hypothesis tests\nSkills – visualizing variation and covariation\nSkills – writing the code\nSkills – estimating correlations\nSkills – hypothesis tests for correlations\nSkills – interpreting and reporting correlations"
  },
  {
    "objectID": "hypotheses-associations.html#sec-associations-resources",
    "href": "hypotheses-associations.html#sec-associations-resources",
    "title": "1  Hypotheses and associations",
    "section": "1.3 Learning resources",
    "text": "1.3 Learning resources\nYou will see next links to the lectures we created to explain the concepts behind the critical thinking and analysis skills we want you to develop (Section 1.3.1), then information about the practical materials we have provided to help you to practise your skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 7 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points. We do this here because we can share the code we used to generate the plots we use in some of the slides 1\n\n1.3.1 Lectures\nThe lecture material for this week is presented in five short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 5\nPart 2 of 5\nPart 3 of 5\nPart 4 of 5\nPart 5 of 5\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.3.2 Practical materials\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-associations-how-to.R\n401-associations-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n1.3.2.1 The how-to guide\nIn the how-to guide:\n\n401-associations-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-associations-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n1.3.3 The workbook\nIn the workbook:\n\n401-associations-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions:\n\ndifferent parts for different phases of the analysis workflow;\ndifferent tasks for different steps in each phase;\ndifferent questions to examine different ideas or coding steps.\n\nIn the week 7 workbook, we are going to work through the following workflow steps:\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\nChange the type classification of a variable in the data – using as.factor()\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\nDraw scatterplots to examine the association between pairs of variables – using ggplot() and geom_point()\nEstimate and test the correlations between pairs of variables – using cor.test()\n\nThe activity 401-associations-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-associations-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\n1.3.4 The data files\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study.two.gen looks like:\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n1.3.5 The answers\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful."
  },
  {
    "objectID": "hypotheses-associations.html#sec-associations-overview",
    "href": "hypotheses-associations.html#sec-associations-overview",
    "title": "1  Hypotheses and associations",
    "section": "1.1 Overview",
    "text": "1.1 Overview\nWelcome to our overview of the materials you will work with in our data analysis class in the PSYC401 module, Week 7.\nWe are completing five classes together in weeks 6-10. These classes are designed to help students to learn about some very common and powerful psychological data analysis methods. We will focus on methods that allow us to visualize and make sense of evidence for associations between variables. Our materials are designed to help you to think about what you are doing, to understand the aims of the practical steps.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly understood project. We will present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data, and to see why we ask you to practise the skills we are teaching.\nWe encounter written health information all the time: on medication labels, in letters from doctors, and online when we research things we are worried about. It is not always easy to understand this information.\nIt is unclear how to make health communication more effective. The problem is that we are not sure how health information should be communicated so that everyone can understand it. This is why we ask the research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills."
  },
  {
    "objectID": "hypotheses-associations.html#sec-associations-goals",
    "href": "hypotheses-associations.html#sec-associations-goals",
    "title": "1  Hypotheses and associations",
    "section": "1.2 Our learning goals",
    "text": "1.2 Our learning goals\nThis week, we focus on both developing your critical thinking and strengthening your practical skills in data analysis.\n1. Critical thinking\n\nConcepts: begin with critical thinking\nSkills: developing hypotheses\n\n2. Practical skills\n\nConcepts – associations: correlations, estimates and hypothesis tests\nSkills – visualizing variation and covariation\nSkills – writing the code\nSkills – estimating correlations\nSkills – hypothesis tests for correlations\nSkills – interpreting and reporting correlations"
  },
  {
    "objectID": "hypotheses-associations.html#sec-associations-notes",
    "href": "hypotheses-associations.html#sec-associations-notes",
    "title": "1  Hypotheses and associations",
    "section": "1.4 Lecture notes",
    "text": "1.4 Lecture notes\nSome people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\nTip\n\n\n\nIn these notes, I provide notes on the code steps that result in the plot.\n\nClick on the Notes tab to see them.\n\n\n\n\n1.4.1 Better methods can’t make up for mediocre theory\n\nPreviously – in week 6: I talked about improving science through open reproducible methods but we cannot make progress without better theory and data (Smaldino, 2019)\nWe want open reproducible findings but we do not just want reproducibility\nWe want to make sense of people in useful ways\n\n\n\n1.4.2 Open, reproducible, methods are not enough\n\nNow: we need to think causally about predictions and about measurement\nWe discuss health comprehension project to demonstrate critical self-reflection\n\n\nFor useful hypotheses, we need better theory so we can build clear testable predictions from explicit assumptions\nAnd with better models, we need better measurement because if we cannot reliably measure something then it is hard to build a theory about it\n\n\n\n1.4.3 Critical thinking and you\n\nStudents and colleagues almost never have problems coding analyses in R\nThe challenges are almost always located in the critical reflection you must do in order to develop sensible analysis, and to interpret the analysis results\nSo we need to start by highlighting the work of critical reflection in data analysis\n\n\n\n1.4.4 Why most psychological research findings are not even wrong\n\nAs you will know, it is often difficult to identify a claim in an article (Scheel, 2022)\nHere are some questions you can ask to decide if a claim you read or make is clear:\n\n\nIs the claim stated unambiguously: can the claim support or contradict (or is it uncertain about) a prediction?\nCan you understand how we get back from the claim to the data, given assumptions about measurement, sampling and procedure?\n\n\n\n1.4.5 Why hypothesis testers should spend less time testing hypotheses\n\nThe response to crisis has been to teach and use better methods\nThis improvement reveals a core problem (Scheel et al., 2021): we often work to test hypotheses but our hypotheses are often undeveloped\nWe train hypothesis testing but we also need to train hypothesising:\nhow to measure, operationalize, and how to decide if hypothesis is corroborated or not\n\n\n\n\n\n\n\nTip\n\n\n\nWe want to be capable of being wrong\n\n\n\n\n1.4.6 Statistical rituals largely eliminate critical statistical thinking\n\nTraditionally, students learn statistical tests, and learn to identify if a test statistic is significance or not\nIf we do not also talk about what is actually observed, and whether or how – or why – it is or is not compatible with theory based predictions then we do ritual not science (Gigerenzer, 2004)\nThis is a problem: the focus on anything-but-null allows us to build or accommodate vague theories that can never be wrong\n\n\n\n1.4.7 We need to think about the derivation chain\n\n\n\n\n\n\n\n\nQ\n\n \n\ncluster_R\n\n   \n\nnd_1_l\n\n Concept formation   \n\nnd_1_r\n\n Causal model   \n\nnd_2_l\n\n Measurement   \n\nnd_1_l-&gt;nd_2_l\n\n    \n\nnd_3\n\n Statistical predictions   \n\nnd_2_l-&gt;nd_3\n\n    \n\nnd_2_r\n\n Auxiliary assumptions   \n\nnd_2_r-&gt;nd_3\n\n    \n\nnd_4\n\n Testing hypotheses   \n\nnd_3-&gt;nd_4\n\n   \n\n\nFigure 1.1: The derivation chain\n\n\n\n\n\n\n1.4.8 Here’s a toolkit for thinking productively about your hypotheses\n\n\n\n\n\n\n\nThe derivation chain (Meehl, 1990; Scheel et al., 2021)\n\nDevelop your theory: the concepts, and the assumptions about causality\nSpecify how psychological concepts will be measured\nIdentify auxiliary assumptions about how we get from theoretical concepts to observable data\nIdentify theoretical predictions\nLink theoretical predictions to specific statistical tests that may support or contradict them\n\n\n\n1.4.9 Valid measures\n\nWe often teach and learn about different kinds of validity but the key idea is simple (Borsboom et al., 2004)\n\n\na test is valid for measuring an attribute if and only if (a) the attribute exists and (b) variations in the attribute causally produce variations in the outcomes of the measurement procedure\n\n\nWe want to work with valid measures but validity requires explaining: (Q.1) Does the thing exist in the world? (Q.2) Is variation in that thing be reflected in variation in our measurement?\n\n\n\n1.4.10 Summary: our critical thinking checklist\n\nWhat is our (causal) theory?\nWhat measures are we using, why?\nWhat is our specific prediction, why?\nDoes the prediction relate to sign and to magnitude?\nWhat analysis can test this prediction, why?\nHow will our results affect our beliefs, why?\n\n\n\n1.4.11 Case study: the health comprehension project\n\nBecause the important questions concern how psychologists ask and answer research questions\nWe will work in the context of a live research project: What makes it easy or difficult to understand written health information?\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\nWhy this? We don’t really know what makes it easy or difficult to understand advice about health\n\n\n1.4.12 Health comprehension project: impacts\n\nWe are working to help improve communication\nWith partners at Vienna Business University, Kantar Public, and the London School of Economics\nOur work has implications for: business communication; understanding reading development; marketing communication\n\n\n\n1.4.13 Health comprehension project: questions and analyses\n\nOur research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nThese kinds of research questions can be answered using methods like correlation, linear models\n\n\n\n1.4.14 Health comprehension project – relevance: methods you will use in your professional work\n\nWe got funding to collect data online using online Qualtrics questionnaire surveys\nWe tested people on a range of dimensions using standardized ability and our own knowledge tests\nMany of you will go on to work with online surveys, and with data from standardized ability measures\n\n\n\n1.4.15 Health comprehension project: samples\n\nWe collected data in two studies in 2020: using the online Prolific platform to recruit participants\nWe did several replication studies in student-led projects: we analyze the data in class\n\n\n\n1.4.16 Health comprehension project: why it is a case study\n\nThe health project has strengths and limitations\nWe show how to identify and critically evaluate this project so you can do the same for your work\n\n\n\n\nExtract from Qualtrics survey\n\n\n\n\n\n1.4.17 Cognitive process theory of comprehension success\n\nWhen skilled adult readers read and try to understand written text (Kintsch, 1994)\nThey must recognize and access the meanings of words\nThen use knowledge and reasoning to build an interpretation of what is in the text\nBased on connecting the information in the text with what they already know\n\n\n\n1.4.18 Individual differences theory of comprehension success\n\nSuccessfully understanding text depends on (1.) language experience and (2.) reasoning ability (Freed et al., 2017)\n\n\n\n\n\n\n\n\n\nQ\n\n  \n\nnd_1_l\n\n Language experience   \n\nnd_2\n\n Comprehension outcome   \n\nnd_1_l-&gt;nd_2\n\n    \n\nnd_1_r\n\n Reasoning capacity   \n\nnd_1_r-&gt;nd_2\n\n   \n\n\nFigure 1.2: Factors influencing comprehension success\n\n\n\n\n\n\n\n1.4.19 Where the data come from: our measures\n\nWe measure reading comprehension: asking people to read text and then answer multiple choice questions\nWe measure background knowledge: vocabulary knowledge (Shipley); health literacy (HLVA)\nWe ask people to rate their own understanding of each text\n\n\n\n1.4.20 Example critical evaluation questions\n\nAre multiple choice questions good ways to probe understanding? – What alternatives are there?\nAre tests like the Shipley good measures of language knowledge? – What do we miss?\nCan a person accurately evaluate their own understanding? – Can we rely on subjective judgments?\n\n\n\n1.4.21 Relevance to you\n\nEven very good students sometimes do not question the validity of measures:\nNot asking questions like this has a real impact on the value of the interpretation of results\nHere, we are looking ahead to the critical thinking you will need to do for your dissertations\n\n\n\n1.4.22 Talking about the relationships between variables\n\nPsychologists and people who work in related fields often want to know about associations\nIs variation in observed values on one dimension (e.g., comprehension) related to variation in another dimension (e.g., vocabulary)?\nDo values on both dimensions vary together?\n\n\n\n1.4.23 The language in this area can vary: we will be consistent but you need to be aware of the different terms\n\nOutcome \\(=\\) response \\(=\\) criterion \\(=\\) dependent variable\nPredictor \\(=\\) covariate \\(=\\) independent variable \\(=\\) factor\nLinear model \\(=\\) regression analysis \\(=\\) regression model \\(=\\) multiple regression\n\n\n\n1.4.24 Let’s look at the data we will use\n\nFirst, we need to read the data into R\n\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")\n\n\nNext, we should take a look at the data: you can open the data-set in Excel or you can use the head command to show the first few rows in\nThe person in row 1 has ETHNICITY White, is AGE 34 years, scored 33 on Shipley vocabulary, scored 7 on HLVA health literacy and, on average, self-rated their understanding of health information as 7.96 (so 8/9, mean.self) while scoring 0.49 accuracy in tests of understanding (49% mean.acc)\n\n\nstudy.one.gen %&gt;%\n    select(mean.acc, mean.self, HLVA, SHIPLEY, AGE, ETHNICITY) %&gt;%\n    head(n = 4)\n\n# A tibble: 4 × 6\n  mean.acc mean.self  HLVA SHIPLEY   AGE ETHNICITY\n     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n1     0.49      7.96     7      33    34 White    \n2     0.85      7.28     7      33    25 White    \n3     0.82      7.36     8      40    43 White    \n4     0.94      7.88    11      33    46 White    \n\n\n\n\n1.4.25 Destination correlation: where the correlation number comes from\n\nCovariance\n\n\\[COV_{xy} = \\frac{\\sum(x - \\bar{x})(y - \\bar{y})}{n -1}\\]\n\nIf we want to estimate the correlation between two sets of numbers: \\(x\\) and \\(y\\)\nWe want to know if variation in \\(x\\) (given by \\(x - \\bar{x}\\))\nVaries together with variation in \\(y\\) (given by \\(y - \\bar{y}\\))\n\n\n\n1.4.26 Destination correlation: where the correlation number comes from\n\nCovariance divided by standard deviations\n\n\\[r = \\frac{COV_{xy}}{s_xs_y}\\]\n\nBecause the two sets of numbers can be on different scales: e.g., SHIPLEY out of 40; mean.acc (proportion, out of 1)\nAnd because covariance values depend on the scales\nTo correlations easier to compare, we need to remove scale by dividing by the variables standard deviations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.27 Let’s think about an example correlation\n\nResearch question: Can people accurately evaluate whether they correctly understand written health information?\nMeasurement: Someone with higher scores on tested accuracy of understanding will also present higher scores on their ratings of their own understanding\nStatistical prediction: We predict that mean.acc and mean.self scores will be associated\nTest: If the prediction is correct, mean.acc and mean.self scores will be correlated\n\n\n\n1.4.28 Distributions: How do scores vary?\n\nPlotNotes\n\n\n\n\n\n\n\nFigure 1.3: Histograms showing the distribution of mean accuracy and mean self-rated accuracy scores in the ‘study.one.gen’ data-set: means calculated for each participant over all their responses\n\n\n\n\n\n\n\nlibrary(patchwork)\nlibrary(tidyverse)\n\np.acc &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.acc)) + \n           geom_histogram(binwidth = .1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.acc),\n                      size = 1.5, colour = \"red\") +\n           xlab(\"mean accuracy\") +\n           xlim(0, 1.1) +\n           theme_bw()\n\np.self &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.self)) + \n           geom_histogram(binwidth = 1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.self),\n                      size = 1.5, colour = \"red\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) +\n           theme_bw()\n\np.acc + p.self\n\nLet’s go through the code step-by-step.\n\n\n\n\n\n\nTip\n\n\n\n\nHere the code is broken down, line by line, and each line is numbered.\nThis presentation style is done to make it easier for you to see what each step is doing.\nNotice that when we use p.acc &lt;- study.one.gen we tell R to first create the plot (giving it the name p.acc) but to not show it yet.\n\n\n\n\nlibrary(patchwork) and library(tidyverse): We need to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid showing the plots next to each other. We use the library() function to get these libraries.\nWe construct two plots. We call the plots p.acc and p.self. Each plot is constructed in a similar way so we explain the main steps for one plot. The plots are constructed but not shown until the last line of code is run.\np.acc &lt;- ... creates a plot called p.acc, using the processes that are specified in the next lines of code that follow.\n... &lt;- study.one.gen tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is called the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(aes(x = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = .1) + tells R to produce a histogram then add a step, next.\ngeom_vline(...) + tells R we want to draw a vertical line.\nxintercept = mean(study.one.gen$mean.acc), ... tells R to draw the vertical line at the mean value of the variable mean.acc in the study.one.gen data-set.\nsize = 1.5, colour = \"red\" tells R we want the vertical line to be red, and 1.5 times the usual size.\nxlab(\"mean accuracy\") + tells R we want the x-axis label to say that the plot is of \"mean accuracy\".\nxlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy values shown in the plot.\ntheme_bw() lastly, we change the theme.\nThen we have code to construct the second plot p.self.\np.acc + p.self: tells R to put the two plots together so they appear side-by-side in a grid for easy comparison.\n\nIn using pipes in the code, I am structuring the code so that it works — and is presented — in a sequence of steps. There are different ways to write code but I find this way easier to work with and to read and I think you will too.\nWhat you can see is that each line ending in a %&gt; pipe passes something on to the next line. A following line takes the output of the process coded in the preceding line, and works with it.\nEach step is executed in turn, in strict sequence. This means that if I delete the line study.one.gen %&gt;% then the following lines cannot work because the ggplot() function will be looking for a variable average that does not yet exist.\n\n\n\n\n\n\nTip\n\n\n\n\nYou can see that in the data processing part of the code, successive steps in data processing end in a pipe %&gt;%.\nIn contrast, successive steps of the plotting code add ggplot elements line by line with each line (except the last) ending in a +.\n\n\n\nNotice that none of the processing steps actually changes the dataset called study.one.gen. The results of the process exist and can be used only within the sequence of steps coded to produce the plots.\n\nYou can read a clear explanation of pipes here.\nYou can read about the new geom_vline() here.\n\n\n\n\n\n\n1.4.29 A histogram is a useful way to show the distribution of values\n\nWe have a sample of accuracy scores:\nMean accuracy scores vary between 0.0 and 1.0\nWe draw the plot by grouping together similar values in bins\nHeights of bars represent numbers of cases with similar values in same bin\n\n\nPlotNotes\n\n\n\n\n\n\n\nFigure 1.4: Distribution of mean accuracy\n\n\n\n\n\n\n\nstudy.one.gen %&gt;%\n           ggplot(aes(x = mean.acc)) + \n           geom_histogram(binwidth = .1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.acc),\n                      size = 1.5, colour = \"red\") +\n           annotate(\"text\", x = 0.6, y = 60,\n                    colour = \"red\",\n                    label = \"average value\\nshown in red\") +\n           xlab(\"mean accuracy\") +\n           xlim(0, 1.1) +\n           theme_bw()\n\nWe go through the code line by line. It will be useful to identify some differences between this chunk of code and the previous chunk of code.\n\nWe are going to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid. I assume you have already run the library() function to get these libraries. We do not need to do it again in the same R session.\nWe construct one plot here. We do not give it a name. Run the code and R will show the plot in the plot window immediately.\nstudy.one.gen %&gt;% tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(aes(x = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = .1) + tells R to produce a histogram then add a step, next.\ngeom_vline(...) + tells R we want to draw a vertical line.\nxintercept = mean(study.one.gen$mean.acc), ... tells R to draw the vertical line at the mean value of the variable mean.acc in the study.one.gen data-set.\nsize = 1.5, colour = \"red\" tells R we want the vertical line to be red, and 1.5 times the usual size.\nannotate(\"text\", ...** tells R to write some text.\nx = 0.6, y = 60** tells R where to write the text.\ncolour = \"red\"** tells R what colour to write the text.\nlabel = \"average value\\nshown in red\"** tells R what text to write.\nxlab(\"mean accuracy\") + tells R we want the x-axis label to say that the plot is about \"mean accuracy\".\nxlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy values shown in the plot.\ntheme_bw() lastly, we change the theme.\n\n\nYou can read about the new annotate() function here.\n\n\n\n\n\n\n1.4.30 When we talk about variance we are talking about how values vary in relation to the mean for the sample\n\nThe average of these mean accuracy scores is marked with a red line where \\(\\bar{x} =\\) 0.8\nThe accuracy score for the person in row 1 is located at \\(x = .49\\), marked in blue\n\n\n\n\n\n\nFigure 1.5: Distribution of mean accuracy\n\n\n\n\n\n\n1.4.31 We are talking about how values vary in relation to the mean for the sample\n\nIn comparison, the mean accuracy score for the person in row 4 is located at \\(x = .94\\), marked in blue\n\n\n\n\n\n\nFigure 1.6: Distribution of mean accuracy\n\n\n\n\n\n\n1.4.32 The basic question when we examine covariance: do values vary together?\n\nIf the person at row 1 has a mean.accuracy score of .49, lower than the average\nAnd the person at row 4 has a mean.accuracy score of .94, higher than the average\nWhat will their mean.self scores be: will they be higher or lower than the average mean.self score?\n\n\n\n1.4.33 We can use scatterplots to examine associations\n\nIs variation in the mean accuracy of understanding (of health information) associated with variation in mean self-rated accuracy of understanding?\n\n\nPlotNotes\n\n\n\n\n\n\n\nFigure 1.7: Scatterplots showing whether values on mean accuracy (mean.acc) vary together with values on mean self-rated accuracy (mean.self) for the participants in this sample\n\n\n\n\n\n\n\np.acc &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.self, y = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           ylab(\"mean accuracy\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) + ylim(0, 1.1) +\n           theme_bw()\n\np.self &lt;- study.one.gen %&gt;%\n           ggplot(aes(y = mean.self, x = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           xlab(\"mean accuracy\") +\n           ylab(\"mean self-rated accuracy\") +\n           ylim(0, 10) + xlim(0, 1.1) +\n           theme_bw()\n\np.acc + p.self\n\n\nWe are going to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid. I assume you have already run the library() function to get these libraries. We do not need to do it again in the same R session.\nWe construct two plots. We call the plots p.acc and p.self again. Each plot is constructed in a similar way so we explain the main steps for one plot. The plots are constructed but not shown until the last line of code is run.\np.acc &lt;- ... creates a plot called p.acc, using the processes that are specified in the next lines of code that follow.\n... &lt;- study.one.gen tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is called the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(...) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.self, ...) tells R that in the plot we want it to show the mean.self variable values as horizontal (left to right) locations on the x-axis: this is one aesthetic mapping.\naes(... , y = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as vertical (low to high) locations on the y-axis: this is the second aesthetic mapping.\naes(x = mean.self, y = mean.acc) thus encodes two aesthetic mappings, telling R the position of the things it will draw (it will draw points, next): the vertical height, and the horizontal left-to-right position.\ngeom_point(...) tells R to produce a scatterplot, representing data values as points.\nsize = 2, alpha = .5 tells R we want the points to be 2 times the usual size with size = 2, and half the usual level of opacity (i.e. how solid the colour is) with alpha = .5.\nylab(\"mean accuracy\") + tells R we want the y-axis label to say that the plot is of \"mean accuracy\".\nxlab(\"mean self-rated accuracy\") + tells R we want the y-axis label to say that the plot is of \"mean self-rated accuracy\".\nylim(0, 10) + xlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy and mean self-rated accuracy values shown in the plot.\ntheme_bw() changes the theme.\nThen we have code to construct the second plot p.self.\np.acc + p.self: tells R to put the two plots together so they appear side-by-side in a grid for easy comparison.\n\n\nYou can read about the geom_point() function here.\n\n\n\n\n\n\n1.4.34 A scatterplot is a useful way to examine if the values of two or more variables vary together\n\nMean accuracy scores vary between 0.0 and 1.0\n\n\nThe height of each point shows the observed value of accuracy on the y-axis\n\n\nSelf-rated accuracy scores vary between 1 and 9\n\n\nThe horizontal position of each point shows the observed value of self-rated accuracy on the x-axis\n\n\nPlotNotes\n\n\n\n\n\n\n\nFigure 1.8: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\nstudy.one.gen %&gt;%\n           ggplot(aes(x = mean.self, y = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           ylab(\"mean accuracy\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) + ylim(0, 1.1) +\n           theme_bw()\n\nWe use mostly the same code to draw Figure 1.8, compared to the code we used to draw Figure 1.7, but there is one difference. I do not walk through every line of code, here, but highlight the difference.\n\nWe construct one plot here. We do not give it a name. Run the code and R will show the plot in the plot window immediately.\nstudy.one.gen %&gt;% tells R that we are working with the data-set study.one.gen that we read in earlier.\nggplot(aes(x = mean.self, y = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.self, y = mean.acc) thus encodes two aesthetic mappings, telling R the position of the things it will draw (it will draw points, next): the vertical height, and the horizontal left-to-right position.\n\n\n\n\nWe can focus in one point, showing the data for one person.\n\nWe have a sample of 170 people\nFor each person, we have a value for the mean accuracy and a paired value for the mean self-rated accuracy\nEach point shows the paired data values for a person\nIn red: someone scored 3.48 on mean self-rated accuracy, 0.57 on mean accuracy\n\n\n\n\n\n\nFigure 1.9: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n1.4.35 The R code for a correlation test, bit by bit\n\ncor.test(study.one.gen$mean.acc,\n         study.one.gen$mean.self,\n         method = \"pearson\")\n\n\nWe specify the cor.test function, and name one variable study.one.gen$mean.acc\nThen we name the second variable study.one.gen$mean.self\nLast we specify the correlation method = \"pearson\" because we have a choice (we can apply other methods to estimate the correlation, e.g., Spearmans)\n\n\n\n1.4.36 Identifying the key information in the results from one correlation test\n\nWe look at the value of the correlation (here, cor) and the p-value\nWe can see that the correlation statistic is positive cor = .4863771 which we round to \\(cor = .49\\)\nAnd p-value = 2.026e-11 indicating that the correlation is significant \\(p &lt; .001\\)\n\n\ncor.test(study.one.gen$mean.acc,\n         study.one.gen$mean.self,\n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one.gen$mean.acc and study.one.gen$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\n\n1.4.37 Reporting a correlation\n\nUsually, we report a correlation like this:\n\n\nMean accuracy and mean self-rated accuracy were significantly correlated (\\(r (167 \\text{ df}) = .49, p &lt; .001\\)). Higher mean accuracy scores are associated with higher mean self-rated accuracy scores.\n\n\n\n1.4.38 Interpreting correlations with the help of visualization\n\nThe correlation statistic is positive in sign and moderate in size, about \\(r = .49\\)\nWe can see that higher mean accuracy (mean.acc) scores are associated with higher mean self-rated accuracy (mean.self) scores\n\n\n\n\n\n\nFigure 1.10: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n1.4.39 What will different kinds of correlations look like?\nWe can simulate data to demonstrate [what scatterplots look like if]: (left) the correlation is positive, \\(r = .5\\); (right) the correlation is negative, \\(r = -.5\\)\n\n\n\n\n\nFigure 1.11: Scatterplots showing how simulated data values on mean accuracy and mean self-rated accuracy could vary together given positive or negative correlations\n\n\n\n\n\n\n1.4.40 We can also imagine – again with simulated data – what correlations of increasing size might look like\n\nNotice how, as you compare the plots, going from left to right\nAs the correlation increases, the points cluster together more closely\n\n\n\n\n\n\nFigure 1.12: Scatterplots showing how simulated data values on mean accuracy and mean self-rated accuracy could vary together given positive correlations of increasing size"
  },
  {
    "objectID": "hypotheses-associations.html#why-hypothesis-testers-should-spend-less-time-testing-hypotheses",
    "href": "hypotheses-associations.html#why-hypothesis-testers-should-spend-less-time-testing-hypotheses",
    "title": "1  Hypotheses and associations",
    "section": "1.5 Why Hypothesis Testers Should Spend Less Time Testing Hypotheses",
    "text": "1.5 Why Hypothesis Testers Should Spend Less Time Testing Hypotheses\n\nThe response to crisis has been to teach and use better methods\nThis improvement reveals a core problem (Scheel et al., 2021): we often work to test hypotheses but our hypotheses are often undeveloped\nWe train hypothesis testing but we also need to train hypothesising:\nhow to measure, operationalize, and how to decide if hypothesis is corroborated or not\n\nWe want to be capable of being wrong"
  },
  {
    "objectID": "hypotheses-associations.html#statistical-rituals-largely-eliminate-critical-statistical-thinking",
    "href": "hypotheses-associations.html#statistical-rituals-largely-eliminate-critical-statistical-thinking",
    "title": "1  Hypotheses and associations",
    "section": "1.6 Statistical rituals largely eliminate critical statistical thinking",
    "text": "1.6 Statistical rituals largely eliminate critical statistical thinking\n\nTraditionally, students learn statistical tests, and learn to identify if a test statistic is significance or not\nIf we do not also talk about what is actually observed, and whether or how – or why – it is or is not compatible with theory based predictions then we do ritual not science (Gigerenzer2004?)\nThis is a problem: the focus on anything-but-null allows us to build or accommodate vague theories that can never be wrong"
  },
  {
    "objectID": "hypotheses-associations.html#we-need-to-think-about-the-derivation-chain",
    "href": "hypotheses-associations.html#we-need-to-think-about-the-derivation-chain",
    "title": "1  Hypotheses and associations",
    "section": "1.7 We need to think about the derivation chain",
    "text": "1.7 We need to think about the derivation chain\n\n\n\n\n\n\n\n\nQ\n\n \n\ncluster_R\n\n   \n\nnd_1_l\n\n Concept formation   \n\nnd_1_r\n\n Causal model   \n\nnd_2_l\n\n Measurement   \n\nnd_1_l-&gt;nd_2_l\n\n    \n\nnd_3\n\n Statistical predictions   \n\nnd_2_l-&gt;nd_3\n\n    \n\nnd_2_r\n\n Auxiliary assumptions   \n\nnd_2_r-&gt;nd_3\n\n    \n\nnd_4\n\n Testing hypotheses   \n\nnd_3-&gt;nd_4\n\n   \n\n\nFigure 1.1: The derivation chain"
  },
  {
    "objectID": "hypotheses-associations.html#heres-a-toolkit-for-thinking-productively-about-your-hypotheses",
    "href": "hypotheses-associations.html#heres-a-toolkit-for-thinking-productively-about-your-hypotheses",
    "title": "1  Hypotheses and associations",
    "section": "1.8 Here’s a toolkit for thinking productively about your hypotheses",
    "text": "1.8 Here’s a toolkit for thinking productively about your hypotheses\n\n\n\n\n\n\n\nThe derivation chain (Scheel et al., 2021; meehl1990?)\n\nDevelop your theory: the concepts, and the assumptions about causality\nSpecify how psychological concepts will be measured\nIdentify auxiliary assumptions about how we get from theoretical concepts to observable data\nIdentify theoretical predictions\nLink theoretical predictions to specific statistical tests that may support or contradict them"
  },
  {
    "objectID": "hypotheses-associations.html#valid-measures",
    "href": "hypotheses-associations.html#valid-measures",
    "title": "1  Hypotheses and associations",
    "section": "1.9 Valid measures",
    "text": "1.9 Valid measures\n\nWe often teach and learn about different kinds of validity but the key idea is simple (borsboom2004?):\n\na test is valid for measuring an attribute if and only if (a) the attribute exists and (b) variations in the attribute causally produce variations in the outcomes of the measurement procedure\n\nWe want to work with valid measures but validity requires explaining: (Q.1) Does the thing exist in the world? (Q.2) Is variation in that thing be reflected in variation in our measurement?"
  },
  {
    "objectID": "hypotheses-associations.html#summary-our-critical-thinking-checklist",
    "href": "hypotheses-associations.html#summary-our-critical-thinking-checklist",
    "title": "1  Hypotheses and associations",
    "section": "1.10 Summary: our critical thinking checklist",
    "text": "1.10 Summary: our critical thinking checklist\n\nWhat is our (causal) theory?\nWhat measures are we using, why?\nWhat is our specific prediction, why?\nDoes the prediction relate to sign and to magnitude?\nWhat analysis can test this prediction, why?\nHow will our results affect our beliefs, why?\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;  –&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScheel, A. M. (2022). Why most psychological research findings are not even wrong. Infant and Child Development, 31(1), e2295. https://doi.org/10.1002/icd.2295\n\n\nScheel, A. M., Tiokhin, L., Isager, P. M., & Lakens, D. (2021). Why Hypothesis Testers Should Spend Less Time Testing Hypotheses. Perspectives on Psychological Science, 16(4), 744–755. https://doi.org/10.1177/1745691620966795"
  },
  {
    "objectID": "hypotheses-associations.html#footnotes",
    "href": "hypotheses-associations.html#footnotes",
    "title": "1  Hypotheses and associations",
    "section": "",
    "text": "We write the slides and this book in Quarto in R-Studio. Quarto scripts can be rendered as .html to share web-books like this one, or to share slides like those we use in presenting the lecture. One advantage of using Quarto is that we can share a plot and the code we used to generate the plot in the same page.↩︎"
  },
  {
    "objectID": "hypotheses-associations.html#summary",
    "href": "hypotheses-associations.html#summary",
    "title": "1  Hypotheses and associations",
    "section": "1.5 Summary",
    "text": "1.5 Summary\n\nWe are often interested in whether or how variation in the values of two variables are associated\nWe can visualize the distribution of values in any one variable using histograms\nWe visualize the association of values in two variables using scatterplots\nWe conduct correlation tests to examine the sign (positive or negative) and the strength of the association\nBut we always need to think about our research questions, about where our data come from and about whether our measures are any good\n\n\n1.5.1 Look ahead: growing in independence\n\nEvery problem you ever have: someone has had it before, solved it, and written a blog (or tweet or toot) about it\n\n\n\n1.5.2 Look ahead: the revolution in knowledge and you\n\nR is free open statistical software: everything you use is contributed, discussed and taught by a community of R users online, in open forums\nLearning to navigate this knowledge is an introduction to the future of knowledge sharing\n\n\n\n\n\nBorsboom, D., Mellenbergh, G. J., & Heerden, J. van. (2004). The concept of validity. Psychological Review, 111(4), 1061–1071. https://doi.org/10.1037/0033-295X.111.4.1061\n\n\nFreed, E. M., Hamilton, S. T., & Long, D. L. (2017). Comprehension in proficient readers: The nature of individual variation. Journal of Memory and Language, 97, 135–153. https://doi.org/10.1016/j.jml.2017.07.008\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of Socio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nKintsch, W. (1994). Text comprehension, memory, and learning. American Psychologist, 49(4), 294–303. https://doi.org/10.1037/0003-066x.49.4.294\n\n\nMeehl, P. E. (1990). Why summaries of research on psychological theories are often uninterpretable. Psychological Reports, 66(1), 195–244. https://doi.org/10.2466/pr0.1990.66.1.195\n\n\nScheel, A. M. (2022). Why most psychological research findings are not even wrong. Infant and Child Development, 31(1), e2295. https://doi.org/10.1002/icd.2295\n\n\nScheel, A. M., Tiokhin, L., Isager, P. M., & Lakens, D. (2021). Why Hypothesis Testers Should Spend Less Time Testing Hypotheses. Perspectives on Psychological Science, 16(4), 744–755. https://doi.org/10.1177/1745691620966795\n\n\nSmaldino, P. (2019). Better methods can’t make up for mediocre theory. Nature, 575(7781), 9."
  }
]